{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import neat\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from explaneat.core.backprop import NeatNet\n",
    "from explaneat.core import backprop\n",
    "from explaneat.core.backproppop import BackpropPopulation\n",
    "from explaneat.visualization import visualize\n",
    "from explaneat.core.experiment import ExperimentReporter\n",
    "from explaneat.core.utility import one_hot_encode\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import gzip\n",
    "try:\n",
    "    import cPickle as pickle  # pylint: disable=import-error\n",
    "except ImportError:\n",
    "    import pickle  # pylint: disable=import-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = False\n",
    "device = torch.device(\"cuda:1\" if USE_CUDA else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Experiment\n",
    "\n",
    "This experiment (a) test the experimental environment, but is also to evaluate the efficacy of the ExplaNEAT algorithm. Speed is a critical factor, as well as stability of results on population size. Total run time will also be measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to set a random seed and a total stopping point in the number of generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_random_seed = 42\n",
    "random.seed(my_random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vals):\n",
    "    width = max(vals)\n",
    "    newVals = []\n",
    "    for val in vals:\n",
    "        blank = [0. for _ in range(width + 1)]\n",
    "        blank[val] = 1.\n",
    "        newVals.append(blank)\n",
    "    return np.asarray(newVals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We are going to work with the Iris dataset, which will be loaded from `sklearn`. We want to characterise the efficacy of the algorithm with regards to a mostly untransformed dataset, so we will only normalise the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/mike/dev-mtm/phd-neat-experiments/data/breast-cancer/breast-cancer.data', header=None)\n",
    "data.columns = ['Class',\n",
    "'age',\n",
    "'menopause',\n",
    "'tumor-size',\n",
    "'inv-nodes',\n",
    "'node-caps',\n",
    "'deg-malig',\n",
    "'breast',\n",
    "'breast-quad',\n",
    "'irradiat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "defs = {\n",
    "    'Class': ['no-recurrence-events', 'recurrence-events'], \n",
    "    'age': ['10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90-99'],\n",
    "    'menopause': ['lt40', 'ge40', 'premeno'], \n",
    "    'tumor-size': ['0-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59'], \n",
    "    'inv-nodes': ['0-2', '3-5', '6-8', '9-11', '12-14', '15-17', '18-20', '21-23', '24-26', '27-29', '30-32', '33-35', '36-39'],\n",
    "    'node-caps': ['yes', 'no', '?'], \n",
    "#     'deg-malig': ['0', '1', '2', '3', '?'],\n",
    "    'breast': ['left', 'right'],\n",
    "    'breast-quad': ['left_up', 'left_low', 'right_up', 'right_low', 'central', '?'],\n",
    "    'irradiat': ['yes', 'no']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in defs:\n",
    "    try:\n",
    "        data[category] = data[category].apply(lambda x: defs[category].index(x))\n",
    "    except ValueError:\n",
    "        print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['age',\n",
    "'menopause',\n",
    "'tumor-size',\n",
    "'inv-nodes',\n",
    "'node-caps',\n",
    "'deg-malig',\n",
    "'breast',\n",
    "'breast-quad',\n",
    "'irradiat']\n",
    "y_col = 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits = datasets.load_digits()\n",
    "# xs_raw = digits.data[:, :]\n",
    "xs_raw = np.array(data[x_cols]).astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(xs_raw)\n",
    "xs = scaler.transform(xs_raw)\n",
    "# ys = iris.target\n",
    "ys = np.array(data[y_col]).astype(np.float32)\n",
    "ys = np.array([[y] for y in ys])\n",
    "# ys_onehot = one_hot_encode(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(286, 9)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs = torch.from_numpy(xs).to(device)\n",
    "# ys = torch.from_numpy(ys).to(device)\n",
    "X_train = torch.from_numpy(X_train).to(device)\n",
    "X_test = torch.from_numpy(X_test).to(device)\n",
    "y_train = torch.from_numpy(y_train).to(device)\n",
    "y_test = torch.from_numpy(y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.647779  ,  0.91447103,  0.53223157, -0.45661306,  0.37947333,\n         1.2905643 , -0.9389244 , -0.14681807,  0.55850387],\n       [-0.65772694,  0.91447103, -0.41913235, -0.45661306,  0.37947333,\n        -0.0664261 ,  1.0650485 ,  0.6765147 ,  0.55850387],\n       [-0.65772694,  0.91447103, -0.41913235, -0.45661306,  0.37947333,\n        -0.0664261 , -0.9389244 , -0.14681807,  0.55850387],\n       [ 1.3223774 , -0.91447103, -0.8948143 , -0.45661306,  0.37947333,\n        -0.0664261 ,  1.0650485 , -0.9701508 ,  0.55850387],\n       [-0.65772694,  0.91447103, -2.32186   , -0.45661306,  0.37947333,\n        -0.0664261 ,  1.0650485 ,  1.4998473 ,  0.55850387]],\n      dtype=float32)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]], dtype=float32)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metric\n",
    "\n",
    "The NEAT implementation on which ExplaNEAT extends uses a single function call for evaluating fitness. Although this might be reworked for ExplaNEAT to be able to get consistency between the genome-evaluation and the backprop loss function, that can be reviewed later.\n",
    "\n",
    "This use `CrossEntropyLoss` from `PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    loss = nn.BCELoss()\n",
    "    loss = loss.to(device)\n",
    "    for genome_id, genome in genomes.items():\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        preds = []\n",
    "        for xi in xs:\n",
    "            preds.append(net.activate(xi))\n",
    "        genome.fitness = float(1./loss(torch.tensor(preds).to(device), torch.tensor(ys)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base configuration\n",
    "\n",
    "We are going to create the base configuration according to an external configuration file. Per experiment, we will adjust this, later, but this defines the defaults across all runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config-bchard\"\n",
    "base_config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to put a hard limit on how long this can go on for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNGenerations = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a method to manage the instantiation of a population on the basis of a specific config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_population(config, xs, ys, saveLocation):\n",
    "\n",
    "    if not os.path.exists(saveLocation):\n",
    "        os.makedirs(saveLocation)\n",
    "        \n",
    "    config.save(os.path.join(saveLocation, 'config.conf'))\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    p = BackpropPopulation(config, \n",
    "                            xs, \n",
    "                            ys, \n",
    "                            criterion=nn.BCELoss())\n",
    "\n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5, filename_prefix=str(saveLocation) + \"checkpoint-\" ))\n",
    "    bpReporter = backprop.BackpropReporter(True)\n",
    "    p.add_reporter(bpReporter)\n",
    "    p.add_reporter(ExperimentReporter(saveLocation))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Vary population size\n",
    "\n",
    "The first experiment is going to examine the difference in run time different population sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_points = [10, 25, 50, 100, 150]\n",
    "# epoch_points = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "50"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_config.pop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveLocationTemplate = './../../data/experiments/bchard/experiment-newalgo-{}-{}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.647779  ,  0.91447103,  0.53223157, ..., -0.9389244 ,\n        -0.14681807,  0.55850387],\n       [-0.65772694,  0.91447103, -0.41913235, ...,  1.0650485 ,\n         0.6765147 ,  0.55850387],\n       [-0.65772694,  0.91447103, -0.41913235, ..., -0.9389244 ,\n        -0.14681807,  0.55850387],\n       ...,\n       [ 1.3223774 , -0.91447103, -0.41913235, ...,  1.0650485 ,\n        -0.9701508 ,  0.55850387],\n       [-0.65772694, -0.91447103,  0.53223157, ..., -0.9389244 ,\n        -0.14681807,  0.55850387],\n       [ 0.3323252 , -0.91447103,  0.53223157, ..., -0.9389244 ,\n        -0.14681807,  0.55850387]], dtype=float32)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "################################################\n",
      "Starting epochs 10 iteration 0\n",
      "Started at 03/27/2022, 18:11:25\n",
      "################################################\n",
      "################################################\n",
      "The function - generationStart - has just started at 1648357885.6070862\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "The function - generationStart - took 0.00014472007751464844 seconds to complete\n",
      "The function - pre_backprop - has just started at 1648357885.607241\n",
      "The function - pre_backprop - took 5.412101745605469e-05 seconds to complete\n",
      "The function - backprop - has just started at 1648357885.607309\n",
      "about to start backprop with 10 epochs\n",
      "expected scalar type Float but found Double\n",
      "layer id: 1\n",
      "layer input: 1\n",
      "{'training': True, '_parameters': OrderedDict([('weight_1', Parameter containing:\n",
      "tensor([[ 0.6889],\n",
      "        [ 0.8759],\n",
      "        [-0.8388],\n",
      "        [-1.5640],\n",
      "        [-1.1240],\n",
      "        [ 0.3405],\n",
      "        [ 1.0566],\n",
      "        [ 0.1278],\n",
      "        [-1.3599]], dtype=torch.float64, requires_grad=True)), ('weight_0', Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64,\n",
      "       requires_grad=True)), ('bias_1', Parameter containing:\n",
      "tensor([1.4986], dtype=torch.float64, requires_grad=True)), ('bias_0', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64,\n",
      "       requires_grad=True))]), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('criterion', BCEWithLogitsLoss())]), 'genome': <neat.genome.DefaultGenome object at 0x7fd5f83b03d0>, 'config': <neat.config.Config object at 0x7fd6037f6760>, 'node_mapping': <explaneat.core.neuralneat.NodeMapping object at 0x7fd6038311c0>, 'valid': True, 'layers': {1: {'nodes': {0: {'depth': 1, 'output_ids': [], 'input_ids': [-1, -2, -3, -4, -5, -6, -7, -8, -9], 'depths': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'on_path_to_output': True, 'on_path_to_input': False, 'is_input': False, 'is_output': True, 'is_valid': True, 'output_layers': [], 'input_layers': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'skips_in': False, 'skips_out': False, 'layer': 1, 'layer_index': 0}}, 'is_output_layer': True, 'is_input_layer': False, 'layer_type': 'OUTPUT', 'layer_activation': 'Sigmoid', 'input_layers': [0], 'input_shape': 9, 'output_shape': 1, 'weights_shape': (9, 1), 'input_map': {}, 'input_weights': array([[ 0.68887864],\n",
      "       [ 0.87591054],\n",
      "       [-0.83883703],\n",
      "       [-1.56395481],\n",
      "       [-1.12404149],\n",
      "       [ 0.34047896],\n",
      "       [ 1.05655401],\n",
      "       [ 0.1277927 ],\n",
      "       [-1.35993087]]), 'shape': (9, 1), 'bias': array([1.49860845])}, 0: {'nodes': {-1: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 0}, -2: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 1}, -3: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 2}, -4: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 3}, -5: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 4}, -6: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 5}, -7: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 6}, -8: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 7}, -9: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 8}}, 'is_output_layer': False, 'is_input_layer': True, 'layer_type': 'INPUT', 'layer_activation': 'Input', 'input_layers': [], 'input_shape': 0, 'output_shape': 9, 'weights_shape': (0, 9), 'input_map': {}, 'input_weights': array([[1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'shape': (0, 9), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0.])}}, 'node_tracker': {0: {'depth': 1, 'output_ids': [], 'input_ids': [-1, -2, -3, -4, -5, -6, -7, -8, -9], 'depths': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'on_path_to_output': True, 'on_path_to_input': False, 'is_input': False, 'is_output': True, 'is_valid': True, 'output_layers': [], 'input_layers': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'skips_in': False, 'skips_out': False, 'layer': 1, 'layer_index': 0}, -1: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 0}, -2: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 1}, -3: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 2}, -4: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 3}, -5: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 4}, -6: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 5}, -7: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 6}, -8: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 7}, -9: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 8}}, 'weights': {1: Parameter containing:\n",
      "tensor([[ 0.6889],\n",
      "        [ 0.8759],\n",
      "        [-0.8388],\n",
      "        [-1.5640],\n",
      "        [-1.1240],\n",
      "        [ 0.3405],\n",
      "        [ 1.0566],\n",
      "        [ 0.1278],\n",
      "        [-1.3599]], dtype=torch.float64, requires_grad=True), 0: Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64,\n",
      "       requires_grad=True)}, 'biases': {1: Parameter containing:\n",
      "tensor([1.4986], dtype=torch.float64, requires_grad=True), 0: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64,\n",
      "       requires_grad=True)}, 'layer_types': {1: 'OUTPUT', 0: 'INPUT'}, 'layer_inputs': {1: [0], 0: []}, 'n_layers': 2, '_outputs': {0: tensor([[ 0.3323,  0.9145,  1.0079,  ...,  1.0650, -0.9702,  0.5585],\n",
      "        [-0.6577,  0.9145,  0.5322,  ...,  1.0650,  0.6765, -1.7905],\n",
      "        [-1.6478,  0.9145,  0.0565,  ..., -0.9389,  2.3232,  0.5585],\n",
      "        ...,\n",
      "        [-0.6577,  0.9145, -0.4191,  ..., -0.9389, -0.9702,  0.5585],\n",
      "        [ 0.3323, -0.9145,  0.5322,  ..., -0.9389,  1.4998,  0.5585],\n",
      "        [ 0.3323,  0.9145,  0.0565,  ...,  1.0650,  1.4998,  0.5585]])}, 'optimiser': <class 'torch.optim.adadelta.Adadelta'>, 'optimizer': <class 'torch.optim.adadelta.Adadelta'>}\n",
      "======================\n",
      "{1: {'nodes': {0: {'depth': 1, 'output_ids': [], 'input_ids': [-1, -2, -3, -4, -5, -6, -7, -8, -9], 'depths': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'on_path_to_output': True, 'on_path_to_input': False, 'is_input': False, 'is_output': True, 'is_valid': True, 'output_layers': [], 'input_layers': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'skips_in': False, 'skips_out': False, 'layer': 1, 'layer_index': 0}}, 'is_output_layer': True, 'is_input_layer': False, 'layer_type': 'OUTPUT', 'layer_activation': 'Sigmoid', 'input_layers': [0], 'input_shape': 9, 'output_shape': 1, 'weights_shape': (9, 1), 'input_map': {}, 'input_weights': array([[ 0.68887864],\n",
      "       [ 0.87591054],\n",
      "       [-0.83883703],\n",
      "       [-1.56395481],\n",
      "       [-1.12404149],\n",
      "       [ 0.34047896],\n",
      "       [ 1.05655401],\n",
      "       [ 0.1277927 ],\n",
      "       [-1.35993087]]), 'shape': (9, 1), 'bias': array([1.49860845])}, 0: {'nodes': {-1: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 0}, -2: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 1}, -3: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 2}, -4: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 3}, -5: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 4}, -6: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 5}, -7: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 6}, -8: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 7}, -9: {'depth': 0, 'output_ids': [0], 'input_ids': [], 'depths': [], 'on_path_to_output': False, 'on_path_to_input': True, 'is_input': True, 'is_output': False, 'is_valid': True, 'output_layers': [1], 'input_layers': [], 'skips_in': False, 'skips_out': False, 'layer': 0, 'layer_index': 8}}, 'is_output_layer': False, 'is_input_layer': True, 'layer_type': 'INPUT', 'layer_activation': 'Input', 'input_layers': [], 'input_shape': 0, 'output_shape': 9, 'weights_shape': (0, 9), 'input_map': {}, 'input_weights': array([[1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'shape': (0, 9), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0.])}}\n",
      "Key: 1\n",
      "Fitness: None\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=1.498608451040871, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-9, 0), weight=-1.3599308660532954, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-8, 0), weight=0.12779269935267695, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-7, 0), weight=1.0565540055337268, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-6, 0), weight=0.3404789598915912, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-5, 0), weight=-1.1240414901176743, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-4, 0), weight=-1.5639548119470097, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-3, 0), weight=-0.838837032899822, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.8759105400831801, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.6888786433775906, enabled=True)\n",
      "the reached nodes are\n",
      "[-1, -2, -3, -4, -5, -6, -7, -8, -9, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "the reached nodes are\n",
      "[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\n",
      "True\n",
      "---===---===---===\n",
      "The function - backprop - took 0.02225208282470703 seconds to complete\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-787cdef4dabd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstantiate_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Run for up to nGenerations generations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_genomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxNGenerations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_genome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev-mtm/phd-neat-experiments/explaneat/core/backproppop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fitness_function, n, nEpochs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mMethodTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backprop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mMethodTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post_backprop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev-mtm/phd-neat-experiments/explaneat/core/backproppop.py\u001b[0m in \u001b[0;36mbackpropagate\u001b[0;34m(self, xs, ys, nEpochs)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mpreBPLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev-mtm/phd-neat-experiments/explaneat/core/neuralneat.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLAYER_TYPE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "for epochs in epoch_points:\n",
    "    for iteration_no in range(20):\n",
    "        my_random_seed += 1\n",
    "        random.seed(my_random_seed)\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        print(\"################################################\")\n",
    "        print(\"################################################\")\n",
    "        print(\"Starting epochs {} iteration {}\".format(epochs, iteration_no))\n",
    "        print(\"Started at {}\".format(start_time.strftime(\"%m/%d/%Y, %H:%M:%S\")))\n",
    "        print(\"################################################\")\n",
    "        print(\"################################################\")\n",
    "        \n",
    "        \n",
    "        config = deepcopy(base_config)\n",
    "#         config.pop_size = pop_size\n",
    "        \n",
    "        saveLocation = saveLocationTemplate.format(epochs, iteration_no)\n",
    "        \n",
    "        p = instantiate_population(config, X_train, y_train, saveLocation)\n",
    "        # Run for up to nGenerations generations.\n",
    "        winner = p.run(eval_genomes, maxNGenerations, nEpochs = epochs)\n",
    "        \n",
    "        g = p.best_genome\n",
    "\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        p.reporters.reporters[2].save_checkpoint(p.config, p.population, p.species, str(p.generation) + \"-final\")  \n",
    "        \n",
    "        winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "        results = []\n",
    "        for xi, xo in zip(xs, ys):\n",
    "            output = winner_net.activate(xi)\n",
    "            results.append([xi, xo, output])\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv(os.path.join(saveLocation, 'results.csv'))\n",
    "        \n",
    "        ancestry = p.reporters.reporters[3].trace_ancestry_of_species(g.key, p.reproduction.ancestors) \n",
    "\n",
    "        ancestors = {\n",
    "            k: v['genome'] for k, v in p.reporters.reporters[3].ancestry.items()\n",
    "        }\n",
    "        \n",
    "    \n",
    "        \n",
    "        ## Save all of these to disc\n",
    "        filename = 'fullStatus.xplnt'\n",
    "        print(\"Saving checkpoint to {0}\".format(filename))\n",
    "\n",
    "        with gzip.open(os.path.join(saveLocation, filename), 'w', compresslevel=5) as f:\n",
    "            data = (p, g, ancestry, ancestors, random.getstate())\n",
    "            pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            \n",
    "        with gzip.open(os.path.join(saveLocation, 'train_test_data.pkl'), 'w', compresslevel=5) as f:\n",
    "            train_Test = (X_train, X_test, y_train, y_test)\n",
    "            pickle.dump(train_Test, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#         visualize.create_ancestry_video(p.config, \n",
    "#                                         g, \n",
    "#                                         ancestry, \n",
    "#                                         ancestors, \n",
    "#                                         p.reporters.reporters[1], \n",
    "#                                         pathname=saveLocation)\n",
    "        print(\"################################################\")\n",
    "        print(\"################################################\")\n",
    "        print(\"Have finished epochs {} iteration {}\".format(epochs, iteration_no))\n",
    "        print(\"Started at {}\".format(start_time.strftime(\"%m/%d/%Y, %H:%M:%S\")))\n",
    "        print(\"The time is {}\".format(end_time.strftime(\"%m/%d/%Y, %H:%M:%S\")))\n",
    "        print(\"################################################\")\n",
    "        print(\"################################################\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}