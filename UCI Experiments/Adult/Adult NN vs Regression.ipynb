{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the appropriate datasets, a subset of candidate datasets with appropriate characteristics will be chosen. The draft characteristics are:\n",
    "* Over 10,000 data points\n",
    "* Binary classification problem\n",
    "* Over 10 data fields in the dataset\n",
    "\n",
    "For each dataset, the following protocol will be applied:\n",
    "* Divide the dataset into 10 equal, randomly allocated folds\n",
    "* For each fold:\n",
    "\t* Train the model with the fold being the test set\n",
    "\t\t* N.B. optionally, with the other 9 folds, one can be explicitly held out as a validation step for hyper-parameter management\n",
    "\t* Record the AUC (with full details)\n",
    "\t* Record secondary performance measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get general systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import gzip\n",
    "try:\n",
    "    import cPickle as pickle  # pylint: disable=import-error\n",
    "except ImportError:\n",
    "    import pickle  # pylint: disable=import-error    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data management and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:1\" if USE_CUDA else \"cpu\")\n",
    "cuda_device = torch.device(\"cuda:1\")\n",
    "\n",
    "assert device.type == 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.preprocessing import StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED      = 42\n",
    "NUMBER_OF_SPLITS = 10\n",
    "SAVE_FILE_NAME   = './../../../data/uci/processed/results/adult/results_{}.csv'.format(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset\n",
    "\n",
    "The dataset is Adult UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_columns = [\n",
    "    \"age\", \n",
    "    \"workclass\",\n",
    "    \"fnlwgt\", \n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"gt50k\"]\n",
    "y_cols = 'gt50k'\n",
    "\n",
    "\n",
    "data = pd.read_csv('./../../../data/uci/processed/data/adult/adult.data',\n",
    "                   names=adult_columns,\n",
    "                  index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Xs and ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = data.columns.values.tolist()\n",
    "x_cols.remove(y_cols)\n",
    "\n",
    "xs_raw = data[x_cols]\n",
    "ys_raw = data[y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_mask = xs_raw.dtypes==object\n",
    "numerical_feature_mask = xs_raw.dtypes==\"int64\"\n",
    "\n",
    "categorical_cols = xs_raw.columns[categorical_feature_mask].tolist()\n",
    "numerical_cols = xs_raw.columns[numerical_feature_mask].tolist()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xs = xs_raw.copy()\n",
    "\n",
    "# OHE categoricals\n",
    "onehotencoded = pd.get_dummies(xs_raw[categorical_cols])\n",
    "xs[onehotencoded.columns] = onehotencoded\n",
    "xs = xs.drop(categorical_cols, axis=1)\n",
    "\n",
    "## Linear scaling\n",
    "numericals = xs_raw[numerical_cols].values #returns a numpy array\n",
    "scaler = StandardScaler()\n",
    "numericals = scaler.fit_transform(xs_raw[numerical_cols].values)\n",
    "xs[numerical_cols] = pd.DataFrame(numericals)\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "## Adjust outcome var\n",
    "ys = data['gt50k'] == ' >50K'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are going to have:\n",
    "* What type of model\n",
    "* What random seed\n",
    "* What cross fold\n",
    "* What performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_result(model_name, random_seed, cross_fold_index, predictions, AUC_score):\n",
    "    return {\n",
    "        'modelName': model_name,\n",
    "        'randomSeed': random_seed,\n",
    "        'crossFoldIndex': cross_fold_index,\n",
    "        'predictions': list(predictions),\n",
    "        'auc':AUC_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = NUMBER_OF_SPLITS, \n",
    "           random_state = RANDOM_SEED,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_width=128):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_width) \n",
    "        self.fc2 = nn.Linear(hidden_width, hidden_width)\n",
    "        self.fc3 = nn.Linear(hidden_width, hidden_width)\n",
    "        self.fc4 = nn.Linear(hidden_width, hidden_width)\n",
    "        self.fc5 = nn.Linear(hidden_width, hidden_width)\n",
    "        self.fc6 = nn.Linear(hidden_width, output_size)  \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc5(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc6(out)\n",
    "        return out\n",
    "class TabularDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, xs, ys):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs.iloc[idx].to_numpy()\n",
    "        y = 1 if self.ys.iloc[idx] else 0\n",
    "        return (x, y)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training 0\n",
      "Epoch [1/10], Step [29/29], Loss: 0.5393\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3511\n",
      "Epoch [3/10], Step [29/29], Loss: 0.3365\n",
      "Epoch [4/10], Step [29/29], Loss: 0.2726\n",
      "Epoch [5/10], Step [29/29], Loss: 0.3091\n",
      "Epoch [6/10], Step [29/29], Loss: 0.2711\n",
      "Epoch [7/10], Step [29/29], Loss: 0.2737\n",
      "Epoch [8/10], Step [29/29], Loss: 0.3165\n",
      "Epoch [9/10], Step [29/29], Loss: 0.2864\n",
      "Epoch [10/10], Step [29/29], Loss: 0.3264\n",
      "0.9212603748571614\n",
      "Currently training 1\n",
      "Epoch [1/10], Step [29/29], Loss: 0.5104\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3733\n",
      "Epoch [3/10], Step [29/29], Loss: 0.3155\n",
      "Epoch [4/10], Step [29/29], Loss: 0.2965\n",
      "Epoch [5/10], Step [29/29], Loss: 0.2799\n",
      "Epoch [6/10], Step [29/29], Loss: 0.3170\n",
      "Epoch [7/10], Step [29/29], Loss: 0.3297\n",
      "Epoch [8/10], Step [29/29], Loss: 0.2800\n",
      "Epoch [9/10], Step [29/29], Loss: 0.3157\n",
      "Epoch [10/10], Step [29/29], Loss: 0.2996\n",
      "0.9099884025869547\n",
      "Currently training 2\n",
      "Epoch [1/10], Step [29/29], Loss: 0.5471\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3858\n",
      "Epoch [3/10], Step [29/29], Loss: 0.2998\n",
      "Epoch [4/10], Step [29/29], Loss: 0.3220\n",
      "Epoch [5/10], Step [29/29], Loss: 0.3569\n",
      "Epoch [6/10], Step [29/29], Loss: 0.3301\n",
      "Epoch [7/10], Step [29/29], Loss: 0.2889\n",
      "Epoch [8/10], Step [29/29], Loss: 0.3277\n",
      "Epoch [9/10], Step [29/29], Loss: 0.3065\n",
      "Epoch [10/10], Step [29/29], Loss: 0.3046\n",
      "0.9031469735571528\n",
      "Currently training 3\n",
      "Epoch [1/10], Step [29/29], Loss: 0.5343\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3788\n",
      "Epoch [3/10], Step [29/29], Loss: 0.2951\n",
      "Epoch [4/10], Step [29/29], Loss: 0.3061\n",
      "Epoch [5/10], Step [29/29], Loss: 0.3172\n",
      "Epoch [6/10], Step [29/29], Loss: 0.3115\n",
      "Epoch [7/10], Step [29/29], Loss: 0.2942\n",
      "Epoch [8/10], Step [29/29], Loss: 0.3477\n",
      "Epoch [9/10], Step [29/29], Loss: 0.2777\n",
      "Epoch [10/10], Step [29/29], Loss: 0.3520\n",
      "0.9115366843458694\n",
      "Currently training 4\n",
      "Epoch [1/10], Step [29/29], Loss: 0.5128\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3779\n",
      "Epoch [3/10], Step [29/29], Loss: 0.3552\n",
      "Epoch [4/10], Step [29/29], Loss: 0.3079\n",
      "Epoch [5/10], Step [29/29], Loss: 0.2884\n",
      "Epoch [6/10], Step [29/29], Loss: 0.3270\n",
      "Epoch [7/10], Step [29/29], Loss: 0.3029\n",
      "Epoch [8/10], Step [29/29], Loss: 0.3274\n",
      "Epoch [9/10], Step [29/29], Loss: 0.2728\n",
      "Epoch [10/10], Step [29/29], Loss: 0.3341\n",
      "0.9136276862450453\n",
      "Currently training 5\n",
      "Epoch [1/10], Step [29/29], Loss: 0.4946\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3833\n",
      "Epoch [3/10], Step [29/29], Loss: 0.3461\n",
      "Epoch [4/10], Step [29/29], Loss: 0.2874\n",
      "Epoch [5/10], Step [29/29], Loss: 0.3318\n",
      "Epoch [6/10], Step [29/29], Loss: 0.2612\n",
      "Epoch [7/10], Step [29/29], Loss: 0.2954\n",
      "Epoch [8/10], Step [29/29], Loss: 0.2841\n",
      "Epoch [9/10], Step [29/29], Loss: 0.3460\n",
      "Epoch [10/10], Step [29/29], Loss: 0.2824\n",
      "0.9135982377449972\n",
      "Currently training 6\n",
      "Epoch [1/10], Step [29/29], Loss: 0.5627\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3636\n",
      "Epoch [3/10], Step [29/29], Loss: 0.3151\n",
      "Epoch [4/10], Step [29/29], Loss: 0.3079\n",
      "Epoch [5/10], Step [29/29], Loss: 0.2788\n",
      "Epoch [6/10], Step [29/29], Loss: 0.3291\n",
      "Epoch [7/10], Step [29/29], Loss: 0.2806\n",
      "Epoch [8/10], Step [29/29], Loss: 0.3238\n",
      "Epoch [9/10], Step [29/29], Loss: 0.2773\n",
      "Epoch [10/10], Step [29/29], Loss: 0.3097\n",
      "0.9125562301425021\n",
      "Currently training 7\n",
      "Epoch [1/10], Step [29/29], Loss: 0.5123\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3603\n",
      "Epoch [3/10], Step [29/29], Loss: 0.3442\n",
      "Epoch [4/10], Step [29/29], Loss: 0.3109\n",
      "Epoch [5/10], Step [29/29], Loss: 0.3048\n",
      "Epoch [6/10], Step [29/29], Loss: 0.2940\n",
      "Epoch [7/10], Step [29/29], Loss: 0.3000\n",
      "Epoch [8/10], Step [29/29], Loss: 0.3102\n",
      "Epoch [9/10], Step [29/29], Loss: 0.3399\n",
      "Epoch [10/10], Step [29/29], Loss: 0.3387\n",
      "0.9165492621574916\n",
      "Currently training 8\n",
      "Epoch [1/10], Step [29/29], Loss: 0.5147\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3770\n",
      "Epoch [3/10], Step [29/29], Loss: 0.3366\n",
      "Epoch [4/10], Step [29/29], Loss: 0.3349\n",
      "Epoch [5/10], Step [29/29], Loss: 0.2911\n",
      "Epoch [6/10], Step [29/29], Loss: 0.2896\n",
      "Epoch [7/10], Step [29/29], Loss: 0.3327\n",
      "Epoch [8/10], Step [29/29], Loss: 0.3143\n",
      "Epoch [9/10], Step [29/29], Loss: 0.2639\n",
      "Epoch [10/10], Step [29/29], Loss: 0.3213\n",
      "0.9164275443958246\n",
      "Currently training 9\n",
      "Epoch [1/10], Step [29/29], Loss: 0.5107\n",
      "Epoch [2/10], Step [29/29], Loss: 0.3874\n",
      "Epoch [3/10], Step [29/29], Loss: 0.3377\n",
      "Epoch [4/10], Step [29/29], Loss: 0.3181\n",
      "Epoch [5/10], Step [29/29], Loss: 0.3122\n",
      "Epoch [6/10], Step [29/29], Loss: 0.3321\n",
      "Epoch [7/10], Step [29/29], Loss: 0.3248\n",
      "Epoch [8/10], Step [29/29], Loss: 0.3058\n",
      "Epoch [9/10], Step [29/29], Loss: 0.3209\n",
      "Epoch [10/10], Step [29/29], Loss: 0.3113\n",
      "0.9150795117394027\n"
     ]
    }
   ],
   "source": [
    "for index, (train_index, test_index) in enumerate(kf.split(xs)):\n",
    "    print(\"Currently training {}\".format(index))\n",
    "    X_train, X_test = xs.iloc[train_index], xs.iloc[test_index]\n",
    "    y_train, y_test = ys[train_index], ys[test_index]\n",
    "    \n",
    "    batch_size = 1024\n",
    "    learning_rate = 0.0005\n",
    "    num_epochs = 10\n",
    "\n",
    "    train_data = TabularDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_data, \n",
    "                               batch_size=batch_size, \n",
    "                               shuffle=True)\n",
    "\n",
    "    validate_data = TabularDataset(X_test.reset_index(drop=True), y_test.reset_index(drop=True))\n",
    "    validate_loader = DataLoader(dataset = validate_data,\n",
    "                                 batch_size=batch_size, \n",
    "                                 shuffle=False)\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "\n",
    "    my_random_seed = 42\n",
    "    random.seed(my_random_seed)\n",
    "    nn_model = NeuralNet(108, 1).to(cuda_device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss().to(cuda_device)\n",
    "    optimizer = torch.optim.Adam(nn_model.parameters(), lr=learning_rate)  \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (xsnn, ysnn) in enumerate(train_loader):  \n",
    "            # Move tensors to the configured device\n",
    "            xsnn = xsnn.float().to(cuda_device)\n",
    "            ysnn = ysnn.view(-1, 1).float().to(cuda_device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = nn_model(xsnn)\n",
    "            train_loss = criterion(outputs, ysnn)\n",
    "\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, train_loss.item()))\n",
    "\n",
    "            \n",
    "    nn_preds = torch.sigmoid( nn_model.forward(torch.from_numpy(X_test.to_numpy()).float().to(cuda_device)).to(device)).detach().cpu().numpy()\n",
    "    nn_preds = nn_preds.reshape(nn_preds.shape[0])\n",
    "    auc = roc_auc_score(y_test, nn_preds)\n",
    "    print(auc)\n",
    "    results.append(mark_result('NN', RANDOM_SEED, index, nn_preds, auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_preds = torch.sigmoid( nn_model.forward(torch.from_numpy(X_test.to_numpy()).float().to(cuda_device)).to(device)).detach().cpu().numpy()\n",
    "# nn_preds = nn_preds.reshape(nn_preds.shape[0])\n",
    "# auc = roc_auc_score(y_test, nn_preds)\n",
    "# results.append(mark_result('NN', RANDOM_SEED, index, nn_preds, auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training 0\n",
      "Currently training 1\n",
      "Currently training 2\n",
      "Currently training 3\n",
      "Currently training 4\n",
      "Currently training 5\n",
      "Currently training 6\n",
      "Currently training 7\n",
      "Currently training 8\n",
      "Currently training 9\n"
     ]
    }
   ],
   "source": [
    "for index, (train_index, test_index) in enumerate(kf.split(xs)):\n",
    "    print(\"Currently training {}\".format(index))\n",
    "    X_train, X_test = xs.iloc[train_index], xs.iloc[test_index]\n",
    "    y_train, y_test = ys[train_index], ys[test_index]\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train)\n",
    "    # Use the forest's predict method on the test data\n",
    "    rf_preds = rf.predict(X_test)\n",
    "    # Calculate the absolute errors\n",
    "    errors = abs(rf_preds - y_test)\n",
    "    auc = roc_auc_score(y_test, rf_preds)\n",
    "    results.append(mark_result('Random Forest', RANDOM_SEED, index, rf_preds, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training 0\n",
      "Currently training 1\n",
      "Currently training 2\n",
      "Currently training 3\n",
      "Currently training 4\n",
      "Currently training 5\n",
      "Currently training 6\n",
      "Currently training 7\n",
      "Currently training 8\n",
      "Currently training 9\n"
     ]
    }
   ],
   "source": [
    "for index, (train_index, test_index) in enumerate(kf.split(xs)):\n",
    "    print(\"Currently training {}\".format(index))\n",
    "    X_train, X_test = xs.iloc[train_index], xs.iloc[test_index]\n",
    "    y_train, y_test = ys[train_index], ys[test_index]\n",
    "    \n",
    "    svm_model=SVC()\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    svm_preds=svm_model.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, svm_preds)\n",
    "\n",
    "    results.append(mark_result('SVM', RANDOM_SEED, index, svm_preds, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training 0\n",
      "Currently training 1\n",
      "Currently training 2\n",
      "Currently training 3\n",
      "Currently training 4\n",
      "Currently training 5\n",
      "Currently training 6\n",
      "Currently training 7\n",
      "Currently training 8\n",
      "Currently training 9\n"
     ]
    }
   ],
   "source": [
    "for index, (train_index, test_index) in enumerate(kf.split(xs)):\n",
    "    print(\"Currently training {}\".format(index))\n",
    "    X_train, X_test = xs.iloc[train_index], xs.iloc[test_index]\n",
    "    y_train, y_test = ys[train_index], ys[test_index]\n",
    "    \n",
    "    regression_model=LinearRegression()\n",
    "    regression_model.fit(X_train, y_train)\n",
    "    regression_preds=regression_model.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, regression_preds)\n",
    "\n",
    "    results.append(mark_result('Regression', RANDOM_SEED, index, regression_preds, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'float32' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-da6f36f4cabc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./../../../data/uci/processed/results/adult'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_FILE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'float32' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./../../../data/uci/processed/results/adult'):\n",
    "    os.makedirs('./../../../data/uci/processed/results/adult')\n",
    "# with open(SAVE_FILE_NAME, 'w') as fp:\n",
    "#     json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv(SAVE_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelName</th>\n",
       "      <th>randomSeed</th>\n",
       "      <th>crossFoldIndex</th>\n",
       "      <th>predictions</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0010204839, 0.008771328, 0.3439927, 0.51231...</td>\n",
       "      <td>0.921260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9502995, 0.039839633, 0.11851892, 0.0078300...</td>\n",
       "      <td>0.909988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.07941426, 0.6614282, 0.3906917, 0.007087681...</td>\n",
       "      <td>0.903147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.002846464, 0.58251214, 0.50455076, 0.481285...</td>\n",
       "      <td>0.911537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.09773602, 0.24416648, 0.22646031, 0.0692157...</td>\n",
       "      <td>0.913628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.9039755, 0.29497188, 0.022892816, 0.8812705...</td>\n",
       "      <td>0.913598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.016023064, 0.67839915, 0.0015975306, 0.0011...</td>\n",
       "      <td>0.912556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.3468296, 0.29618916, 0.33501324, 0.01263161...</td>\n",
       "      <td>0.916549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0013912838, 0.03490331, 0.6030983, 0.048054...</td>\n",
       "      <td>0.916428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NN</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.92544305, 0.31013364, 0.060395785, 0.626230...</td>\n",
       "      <td>0.915080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.02, 0.71, 0.27, 0.0, 1.0, 0.13, 0.12, ...</td>\n",
       "      <td>0.916148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.1, 0.54, 0.06, 0.0, 1.0, 0.0, 0.5, 0.9...</td>\n",
       "      <td>0.901823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.08, 0.64, 0.42, 0.03, 0.03, 0.89, 0.0, 0.08...</td>\n",
       "      <td>0.892295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.49, 0.23, 0.4, 0.46, 0.86, 0.4, 0.5, 0...</td>\n",
       "      <td>0.901618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.24, 0.22, 0.05, 0.14, 0.01, 0.44, 1.0,...</td>\n",
       "      <td>0.902935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.88, 0.3, 0.03, 0.88, 0.25, 0.0, 0.53, 0.15,...</td>\n",
       "      <td>0.905753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.46, 0.0, 0.0, 0.36, 0.44, 0.0, 0.3, 0....</td>\n",
       "      <td>0.904932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.16, 0.27, 0.23, 0.0, 0.26, 0.67, 0.01, 0.33...</td>\n",
       "      <td>0.910119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.11, 0.52, 0.0, 0.57, 0.17, 0.04, 0.42,...</td>\n",
       "      <td>0.904693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>[1.0, 0.56, 0.15, 0.51, 0.62, 0.01, 0.63, 1.0,...</td>\n",
       "      <td>0.899809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>0.783527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>[True, False, False, False, False, True, False...</td>\n",
       "      <td>0.763740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True, False, False, False, False, Fals...</td>\n",
       "      <td>0.753542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>[False, True, True, False, True, True, False, ...</td>\n",
       "      <td>0.766028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.759607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>[True, False, False, True, False, False, False...</td>\n",
       "      <td>0.760911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>[False, True, False, False, False, False, Fals...</td>\n",
       "      <td>0.756934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>[False, False, False, False, False, True, Fals...</td>\n",
       "      <td>0.778977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>[False, False, True, False, False, False, Fals...</td>\n",
       "      <td>0.763749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>[True, True, False, True, True, False, False, ...</td>\n",
       "      <td>0.762298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.147735595703125, 0.17681503295898438, 0.29...</td>\n",
       "      <td>0.899715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.4004364013671875, 0.1406707763671875, 0.283...</td>\n",
       "      <td>0.887120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.2696208953857422, 0.5722923278808594, 0.434...</td>\n",
       "      <td>0.888005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.09877777099609375, 0.51019287109375, 0.5473...</td>\n",
       "      <td>0.893228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.16033172607421875, 0.34597015380859375, 0.3...</td>\n",
       "      <td>0.890159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.745330810546875, 0.312713623046875, 0.07952...</td>\n",
       "      <td>0.893751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>[-0.01409149169921875, 0.5918502807617188, 0.0...</td>\n",
       "      <td>0.893882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.4793701171875, 0.36578369140625, 0.32397460...</td>\n",
       "      <td>0.891435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>[-0.1538372039794922, 0.10849952697753906, 0.5...</td>\n",
       "      <td>0.897223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Regression</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.6554718017578125, 0.413360595703125, 0.1330...</td>\n",
       "      <td>0.892945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        modelName  randomSeed  crossFoldIndex  \\\n",
       "0              NN          42               0   \n",
       "1              NN          42               1   \n",
       "2              NN          42               2   \n",
       "3              NN          42               3   \n",
       "4              NN          42               4   \n",
       "5              NN          42               5   \n",
       "6              NN          42               6   \n",
       "7              NN          42               7   \n",
       "8              NN          42               8   \n",
       "9              NN          42               9   \n",
       "10  Random Forest          42               0   \n",
       "11  Random Forest          42               1   \n",
       "12  Random Forest          42               2   \n",
       "13  Random Forest          42               3   \n",
       "14  Random Forest          42               4   \n",
       "15  Random Forest          42               5   \n",
       "16  Random Forest          42               6   \n",
       "17  Random Forest          42               7   \n",
       "18  Random Forest          42               8   \n",
       "19  Random Forest          42               9   \n",
       "20            SVM          42               0   \n",
       "21            SVM          42               1   \n",
       "22            SVM          42               2   \n",
       "23            SVM          42               3   \n",
       "24            SVM          42               4   \n",
       "25            SVM          42               5   \n",
       "26            SVM          42               6   \n",
       "27            SVM          42               7   \n",
       "28            SVM          42               8   \n",
       "29            SVM          42               9   \n",
       "30     Regression          42               0   \n",
       "31     Regression          42               1   \n",
       "32     Regression          42               2   \n",
       "33     Regression          42               3   \n",
       "34     Regression          42               4   \n",
       "35     Regression          42               5   \n",
       "36     Regression          42               6   \n",
       "37     Regression          42               7   \n",
       "38     Regression          42               8   \n",
       "39     Regression          42               9   \n",
       "\n",
       "                                          predictions       auc  \n",
       "0   [0.0010204839, 0.008771328, 0.3439927, 0.51231...  0.921260  \n",
       "1   [0.9502995, 0.039839633, 0.11851892, 0.0078300...  0.909988  \n",
       "2   [0.07941426, 0.6614282, 0.3906917, 0.007087681...  0.903147  \n",
       "3   [0.002846464, 0.58251214, 0.50455076, 0.481285...  0.911537  \n",
       "4   [0.09773602, 0.24416648, 0.22646031, 0.0692157...  0.913628  \n",
       "5   [0.9039755, 0.29497188, 0.022892816, 0.8812705...  0.913598  \n",
       "6   [0.016023064, 0.67839915, 0.0015975306, 0.0011...  0.912556  \n",
       "7   [0.3468296, 0.29618916, 0.33501324, 0.01263161...  0.916549  \n",
       "8   [0.0013912838, 0.03490331, 0.6030983, 0.048054...  0.916428  \n",
       "9   [0.92544305, 0.31013364, 0.060395785, 0.626230...  0.915080  \n",
       "10  [0.0, 0.02, 0.71, 0.27, 0.0, 1.0, 0.13, 0.12, ...  0.916148  \n",
       "11  [1.0, 0.1, 0.54, 0.06, 0.0, 1.0, 0.0, 0.5, 0.9...  0.901823  \n",
       "12  [0.08, 0.64, 0.42, 0.03, 0.03, 0.89, 0.0, 0.08...  0.892295  \n",
       "13  [0.0, 0.49, 0.23, 0.4, 0.46, 0.86, 0.4, 0.5, 0...  0.901618  \n",
       "14  [0.0, 0.24, 0.22, 0.05, 0.14, 0.01, 0.44, 1.0,...  0.902935  \n",
       "15  [0.88, 0.3, 0.03, 0.88, 0.25, 0.0, 0.53, 0.15,...  0.905753  \n",
       "16  [0.0, 0.46, 0.0, 0.0, 0.36, 0.44, 0.0, 0.3, 0....  0.904932  \n",
       "17  [0.16, 0.27, 0.23, 0.0, 0.26, 0.67, 0.01, 0.33...  0.910119  \n",
       "18  [0.0, 0.11, 0.52, 0.0, 0.57, 0.17, 0.04, 0.42,...  0.904693  \n",
       "19  [1.0, 0.56, 0.15, 0.51, 0.62, 0.01, 0.63, 1.0,...  0.899809  \n",
       "20  [False, False, False, False, False, True, Fals...  0.783527  \n",
       "21  [True, False, False, False, False, True, False...  0.763740  \n",
       "22  [False, True, False, False, False, False, Fals...  0.753542  \n",
       "23  [False, True, True, False, True, True, False, ...  0.766028  \n",
       "24  [False, False, False, False, False, False, Fal...  0.759607  \n",
       "25  [True, False, False, True, False, False, False...  0.760911  \n",
       "26  [False, True, False, False, False, False, Fals...  0.756934  \n",
       "27  [False, False, False, False, False, True, Fals...  0.778977  \n",
       "28  [False, False, True, False, False, False, Fals...  0.763749  \n",
       "29  [True, True, False, True, True, False, False, ...  0.762298  \n",
       "30  [-0.147735595703125, 0.17681503295898438, 0.29...  0.899715  \n",
       "31  [0.4004364013671875, 0.1406707763671875, 0.283...  0.887120  \n",
       "32  [0.2696208953857422, 0.5722923278808594, 0.434...  0.888005  \n",
       "33  [0.09877777099609375, 0.51019287109375, 0.5473...  0.893228  \n",
       "34  [0.16033172607421875, 0.34597015380859375, 0.3...  0.890159  \n",
       "35  [0.745330810546875, 0.312713623046875, 0.07952...  0.893751  \n",
       "36  [-0.01409149169921875, 0.5918502807617188, 0.0...  0.893882  \n",
       "37  [0.4793701171875, 0.36578369140625, 0.32397460...  0.891435  \n",
       "38  [-0.1538372039794922, 0.10849952697753906, 0.5...  0.897223  \n",
       "39  [0.6554718017578125, 0.413360595703125, 0.1330...  0.892945  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">randomSeed</th>\n",
       "      <th colspan=\"2\" halign=\"left\">crossFoldIndex</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modelName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.02765</td>\n",
       "      <td>0.913377</td>\n",
       "      <td>0.004769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.02765</td>\n",
       "      <td>0.904013</td>\n",
       "      <td>0.006286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regression</th>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.02765</td>\n",
       "      <td>0.892746</td>\n",
       "      <td>0.003855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.02765</td>\n",
       "      <td>0.764931</td>\n",
       "      <td>0.009382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              randomSeed      crossFoldIndex                auc          \n",
       "                    mean  std           mean      std      mean       std\n",
       "modelName                                                                \n",
       "NN                    42  0.0            4.5  3.02765  0.913377  0.004769\n",
       "Random Forest         42  0.0            4.5  3.02765  0.904013  0.006286\n",
       "Regression            42  0.0            4.5  3.02765  0.892746  0.003855\n",
       "SVM                   42  0.0            4.5  3.02765  0.764931  0.009382"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.groupby('modelName').aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training 0\n",
      "[    6    34    46 ... 32552 32556 32558]\n",
      "Currently training 1\n",
      "[    8    30    33 ... 32544 32546 32560]\n",
      "Currently training 2\n",
      "[    3     4     7 ... 32540 32541 32547]\n",
      "Currently training 3\n",
      "[   31    41    42 ... 32516 32518 32549]\n",
      "Currently training 4\n",
      "[    0    19    47 ... 32501 32532 32539]\n",
      "Currently training 5\n",
      "[    5    14    15 ... 32545 32551 32554]\n",
      "Currently training 6\n",
      "[    2    10    12 ... 32536 32553 32555]\n",
      "Currently training 7\n",
      "[    1    18    48 ... 32506 32508 32525]\n",
      "Currently training 8\n",
      "[   16    24    25 ... 32523 32530 32548]\n",
      "Currently training 9\n",
      "[    9    11    13 ... 32538 32557 32559]\n"
     ]
    }
   ],
   "source": [
    "for index, (train_index, test_index) in enumerate(kf.split(xs)):\n",
    "    print(\"Currently training {}\".format(index))\n",
    "    print(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
