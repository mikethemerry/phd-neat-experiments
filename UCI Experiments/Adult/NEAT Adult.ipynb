{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import neat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from explaneat.core.backprop import NeatNet\n",
    "from explaneat.core import backprop\n",
    "from explaneat.core.backproppop import BackpropPopulation\n",
    "# from explaneat.visualization import visualize\n",
    "from explaneat.core.experiment import ExperimentReporter\n",
    "from explaneat.core.utility import one_hot_encode\n",
    "\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.preprocessing import StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vals):\n",
    "    width = max(vals)\n",
    "    newVals = []\n",
    "    for val in vals:\n",
    "        blank = [0. for _ in range(width + 1)]\n",
    "        blank[val] = 1.\n",
    "        newVals.append(blank)\n",
    "    return np.asarray(newVals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED      = 42\n",
    "NUMBER_OF_SPLITS = 10\n",
    "SAVE_FILE_NAME   = './../../../data/uci/processed/results/adult/results_NEAT_{}.csv'.format(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_columns = [\n",
    "    \"age\", \n",
    "    \"workclass\",\n",
    "    \"fnlwgt\", \n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"gt50k\"]\n",
    "y_cols = 'gt50k'\n",
    "\n",
    "\n",
    "# data = pd.read_csv('./../../../data/uci/processed/data/adult/adult.data',\n",
    "data = pd.read_csv('./../../data/processed/adult.data',\n",
    "                   names=adult_columns,\n",
    "                  index_col=False)\n",
    "\n",
    "x_cols = data.columns.values.tolist()\n",
    "x_cols.remove(y_cols)\n",
    "\n",
    "xs_raw = data[x_cols]\n",
    "ys_raw = data[y_cols]\n",
    "\n",
    "categorical_feature_mask = xs_raw.dtypes==object\n",
    "numerical_feature_mask = xs_raw.dtypes==\"int64\"\n",
    "\n",
    "categorical_cols = xs_raw.columns[categorical_feature_mask].tolist()\n",
    "numerical_cols = xs_raw.columns[numerical_feature_mask].tolist()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xs = xs_raw.copy()\n",
    "\n",
    "# OHE categoricals\n",
    "onehotencoded = pd.get_dummies(xs_raw[categorical_cols])\n",
    "xs[onehotencoded.columns] = onehotencoded\n",
    "xs = xs.drop(categorical_cols, axis=1)\n",
    "\n",
    "## Linear scaling\n",
    "numericals = xs_raw[numerical_cols].values #returns a numpy array\n",
    "scaler = StandardScaler()\n",
    "numericals = scaler.fit_transform(xs_raw[numerical_cols].values)\n",
    "xs[numerical_cols] = pd.DataFrame(numericals)\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "## Adjust outcome var\n",
    "ys = data['gt50k'] == ' >50K'\n",
    "ys = ys.apply(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_result(model_name, random_seed, cross_fold_index, predictions, AUC_score):\n",
    "    return {\n",
    "        'modelName': model_name,\n",
    "        'randomSeed': random_seed,\n",
    "        'crossFoldIndex': cross_fold_index,\n",
    "        'predictions': list(predictions),\n",
    "        'auc':AUC_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = NUMBER_OF_SPLITS, \n",
    "           random_state = RANDOM_SEED,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config-iris\"\n",
    "base_config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_config.pop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNGenerations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_population(config, xs, ys, saveLocation):\n",
    "\n",
    "    if not os.path.exists(saveLocation):\n",
    "        os.makedirs(saveLocation)\n",
    "        \n",
    "    config.save(os.path.join(saveLocation, 'config.conf'))\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    p = BackpropPopulation(config, \n",
    "                            xs, \n",
    "                            ys, \n",
    "                            criterion=nn.BCEWithLogitsLoss())\n",
    "\n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5, filename_prefix=str(saveLocation) + \"checkpoint-\" ))\n",
    "    bpReporter = backprop.BackpropReporter(True)\n",
    "    p.add_reporter(bpReporter)\n",
    "    p.add_reporter(ExperimentReporter(saveLocation))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveLocationTemplate = './../../data/experiments/adult/NEAT-performance-{}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19336    0\n",
       "985      0\n",
       "12675    0\n",
       "15967    0\n",
       "32031    0\n",
       "        ..\n",
       "29802    0\n",
       "5390     0\n",
       "860      0\n",
       "15795    0\n",
       "23654    0\n",
       "Name: gt50k, Length: 27676, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reset_index(drop=True).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an ExplaNEAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training 0\n",
      "################################################\n",
      "################################################\n",
      "Starting iteration 0\n",
      "Started at 07/05/2020, 15:34:33\n",
      "################################################\n",
      "################################################\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (train_index, test_index) in enumerate(kf.split(xs)):\n",
    "    print(\"Currently training {}\".format(index))\n",
    "    X_train, X_test = xs.iloc[train_index], xs.iloc[test_index]\n",
    "    y_train, y_test = ys[train_index], ys[test_index]\n",
    "    \n",
    "    neat_x_train, neat_y_train = X_train.reset_index(drop=True).to_numpy(), y_train.reset_index(drop=True).to_numpy()\n",
    "\n",
    "    \n",
    "    def eval_genomes(genomes, config, ys):\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        for genome_id, genome in genomes:\n",
    "            net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "            preds = []\n",
    "            for xi in xs:\n",
    "                preds.append(net.activate(X_train))\n",
    "    #         genome.fitness = float(1./loss(torch.tensor(preds), torch.tensor(ys)))\n",
    "            roc_auc_score(y_train, preds)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "\n",
    "    print(\"################################################\")\n",
    "    print(\"################################################\")\n",
    "    print(\"Starting iteration {}\".format(index))\n",
    "    print(\"Started at {}\".format(start_time.strftime(\"%m/%d/%Y, %H:%M:%S\")))\n",
    "    print(\"################################################\")\n",
    "    print(\"################################################\")\n",
    "\n",
    "\n",
    "    config = deepcopy(base_config)\n",
    "\n",
    "    saveLocation = saveLocationTemplate.format(index)\n",
    "    \n",
    "    if not os.path.exists(saveLocation):\n",
    "        os.makedirs(saveLocation)\n",
    "\n",
    "    p = instantiate_population(config, neat_x_train, neat_y_train , saveLocation)\n",
    "    # Run for up to nGenerations generations.\n",
    "    winner = p.run(eval_genomes, maxNGenerations)\n",
    "\n",
    "    g = p.best_genome\n",
    "\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    p.reporters.reporters[2].save_checkpoint(p.config, p.population, p.species, str(p.generation) + \"-final\")  \n",
    "\n",
    "    winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "    results = []\n",
    "    for xi, xo in zip(xs, ys):\n",
    "        output = winner_net.activate(xi)\n",
    "        results.append([xi[0], xi[1], xo, output])\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(os.path.join(saveLocation, 'results.csv'))\n",
    "\n",
    "    ancestry = p.reporters.reporters[3].trace_ancestry_of_species(g.key, p.reproduction.ancestors) \n",
    "\n",
    "    ancestors = {\n",
    "        k: v['genome'] for k, v in p.reporters.reporters[3].ancestry.items()\n",
    "    }\n",
    "\n",
    "#         visualize.create_ancestry_video(p.config, \n",
    "#                                         g, \n",
    "#                                         ancestry, \n",
    "#                                         ancestors, \n",
    "#                                         p.reporters.reporters[1], \n",
    "#                                         pathname=saveLocation)\n",
    "    print(\"################################################\")\n",
    "    print(\"################################################\")\n",
    "    print(\"Have finished population {} iteration {}\".format(pop_size, iteration_no))\n",
    "    print(\"Started at {}\".format(start_time.strftime(\"%m/%d/%Y, %H:%M:%S\")))\n",
    "    print(\"The time is {}\".format(end_time.strftime(\"%m/%d/%Y, %H:%M:%S\")))\n",
    "    print(\"################################################\")\n",
    "    print(\"################################################\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Use the forest's predict method on the test data\n",
    "    rf_preds = rf.predict(X_test)\n",
    "    # Calculate the absolute errors\n",
    "    errors = abs(rf_preds - y_test)\n",
    "    auc = roc_auc_score(y_test, rf_preds)\n",
    "    results.append(mark_result('NEAT', RANDOM_SEED, index, rf_preds, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(SAVE_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
