{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import neat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from explaneat.core.backprop import NeatNet\n",
    "from explaneat.core import backprop\n",
    "from explaneat.core.backproppop import BackpropPopulation\n",
    "# from explaneat.visualization import visualize\n",
    "from explaneat.core.experiment import ExperimentReporter\n",
    "from explaneat.core.utility import one_hot_encode\n",
    "from explaneat.core.utility import MethodTimer\n",
    "\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.preprocessing import StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from explaneat.core.neuralneat import NeuralNeat as nneat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED      = 42\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = False\n",
    "device = torch.device(\"cuda:1\" if USE_CUDA else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xor(a, b, threshold = 0.5):\n",
    "    response = False\n",
    "    if a > threshold and b < threshold:\n",
    "        response = True\n",
    "    if a < threshold and b > threshold:\n",
    "        response = True\n",
    "    # return (1.0, 0.0) if response else (0.0, 1.0)\n",
    "    return 1.0 if response else 0.0\n",
    "    \n",
    "\n",
    "def create_n_points(n, size, min=0.0, max=1.0):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append([\n",
    "            random.uniform(min, max) for ii in range(size)\n",
    "        ])\n",
    "\n",
    "    return data\n",
    "\n",
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "def overUnder(val, threshold):\n",
    "    return 1. if val > threshold else 0\n",
    "\n",
    "xor_inputs = create_n_points(400, 2, -1, 1)\n",
    "\n",
    "xor_outputs = [\n",
    "    [xor(tup[0], tup[1], 0)] for tup in xor_inputs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[-0.08839266921885658, -0.3375986658394883],\n",
       " [-0.9585117636795317, -0.37022002011608346],\n",
       " [-0.28938596485268375, 0.24530099973869124],\n",
       " [0.7532001535603277, -0.7756349679726384],\n",
       " [0.7165699772199294, -0.7368569121478801]]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "xor_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.0], [0.0], [1.0], [1.0], [1.0]]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "xor_outputs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config_xor\"\n",
    "base_config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_population(config, xs, ys, saveLocation):\n",
    "\n",
    "    if not os.path.exists(saveLocation):\n",
    "        os.makedirs(saveLocation)\n",
    "        \n",
    "    config.save(os.path.join(saveLocation, 'config.conf'))\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    with MethodTimer(\"Backprop everything\"):\n",
    "        p = BackpropPopulation(config, \n",
    "                                xs, \n",
    "                                ys, \n",
    "                                criterion=nn.BCEWithLogitsLoss())\n",
    "\n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5, filename_prefix=str(saveLocation) + \"checkpoint-\" ))\n",
    "    bpReporter = backprop.BackpropReporter(True)\n",
    "    p.add_reporter(bpReporter)\n",
    "    p.add_reporter(ExperimentReporter(saveLocation))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    \n",
    "    print(genomes)\n",
    "    loss = nn.BCELoss()\n",
    "    loss = loss.to(device)\n",
    "    for genome_id, genome in genomes.items():\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        preds = []\n",
    "        for xi in xor_inputs:\n",
    "            preds.append(net.activate(xi))\n",
    "        genome.fitness = float(1./loss(torch.tensor(preds).to(device), torch.tensor(xor_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The function - Backprop everything - has just started at 1615094965.3835578\n",
      "The function - Backprop everything - took 0.0008959770202636719 seconds to complete\n",
      "The function - generationStart - has just started at 1615094965.3847558\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "The function - generationStart - took 0.00010132789611816406 seconds to complete\n",
      "The function - pre_backprop - has just started at 1615094965.384872\n",
      "The function - pre_backprop - took 2.8133392333984375e-05 seconds to complete\n",
      "The function - backprop - has just started at 1615094965.3849149\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: 0.0\n",
      "best improvement: tensor(0., grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.6943, grad_fn=<DivBackward0>)\n",
      "The function - backprop - took 2.054965019226074 seconds to complete\n",
      "The function - post_backprop - has just started at 1615094967.440008\n",
      "The function - post_backprop - took 2.7179718017578125e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1615094967.440093\n",
      "{1: <neat.genome.DefaultGenome object at 0x7fa150068550>, 2: <neat.genome.DefaultGenome object at 0x7fa1500680d0>, 3: <neat.genome.DefaultGenome object at 0x7fa150068040>, 4: <neat.genome.DefaultGenome object at 0x7fa16330a340>, 5: <neat.genome.DefaultGenome object at 0x7fa16330a580>}\n",
      "The function - evaluate fitness - took 0.005590915679931641 seconds to complete\n",
      "The function - post evaluate - has just started at 1615094967.445765\n",
      "Population's average fitness: 0.45912 stdev: 0.04506\n",
      "Best fitness: 0.52285 - size: (1, 2) - species 1 - id 4\n",
      "Key: 4\n",
      "Fitness: 0.522846519947052\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.26248064637184143, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=-1.2471665143966675, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.5761184096336365, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.00039696693420410156 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1615094967.446178\n",
      "The function - pre_reproduction - took 1.4066696166992188e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1615094967.446201\n",
      "Average adjusted fitness: 0.070\n",
      "The function - reproduction - took 0.00021791458129882812 seconds to complete\n",
      "The function - post reproduction - has just started at 1615094967.446431\n",
      "The function - post reproduction - took 1.52587890625e-05 seconds to complete\n",
      "The function - speciate - has just started at 1615094967.446456\n",
      "Mean genetic distance 1.139, standard deviation 0.509\n",
      "The function - speciate - took 7.200241088867188e-05 seconds to complete\n",
      "The function - end generation - has just started at 1615094967.4465358\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    0     5      0.5    0.070     0\n",
      "Total extinctions: 0\n",
      "Generation time: 2.062 sec\n",
      "The function - end generation - took 0.00010418891906738281 seconds to complete\n",
      "The function - generationStart - has just started at 1615094967.446653\n",
      "\n",
      " ****** Running generation 1 ****** \n",
      "\n",
      "The function - generationStart - took 1.621246337890625e-05 seconds to complete\n",
      "The function - pre_backprop - has just started at 1615094967.446679\n",
      "The function - pre_backprop - took 2.09808349609375e-05 seconds to complete\n",
      "The function - backprop - has just started at 1615094967.446709\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: 0.0\n",
      "best improvement: tensor(0., grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.6890, grad_fn=<DivBackward0>)\n",
      "The function - backprop - took 2.270841121673584 seconds to complete\n",
      "The function - post_backprop - has just started at 1615094969.71766\n",
      "The function - post_backprop - took 2.193450927734375e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1615094969.7177012\n",
      "{4: <neat.genome.DefaultGenome object at 0x7fa16330a340>, 1: <neat.genome.DefaultGenome object at 0x7fa150068550>, 6: <neat.genome.DefaultGenome object at 0x7fa1505b7070>, 7: <neat.genome.DefaultGenome object at 0x7fa1505b7310>, 8: <neat.genome.DefaultGenome object at 0x7fa1505b75b0>}\n",
      "The function - evaluate fitness - took 0.0064318180084228516 seconds to complete\n",
      "The function - post evaluate - has just started at 1615094969.724229\n",
      "Population's average fitness: 0.48345 stdev: 0.08930\n",
      "Best fitness: 0.62782 - size: (2, 3) - species 1 - id 6\n",
      "Key: 6\n",
      "Fitness: 0.627815306186676\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.26248064637184143, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=0.37959474325180054, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=-1.150395393371582, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=0.9563601016998291, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.09953140467405319, enabled=True)\n",
      "\tDefaultConnectionGene(key=(1, 0), weight=-0.490528404712677, enabled=True)\n",
      "\n",
      "\n",
      " SPECIES TOPOLOGY IMPROVEMENT\n",
      "\n",
      "\n",
      "{'genome': <neat.genome.DefaultGenome object at 0x7fa1505b5fd0>, 'fitness': 0.627815306186676, 'firstDerivatives': [0.0, 0.10496878623962402], 'secondDerivatives': [0.0, 0.10496878623962402]}\n",
      "Key: 6\n",
      "Fitness: 0.627815306186676\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.26248064637184143, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=0.37959474325180054, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=-1.150395393371582, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=0.9563601016998291, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.09953140467405319, enabled=True)\n",
      "\tDefaultConnectionGene(key=(1, 0), weight=-0.490528404712677, enabled=True)\n",
      "Nodes\n",
      "0    DefaultNodeGene(key=0, bias=-0.26248064637184143, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "1    DefaultNodeGene(key=1, bias=0.37959474325180054, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections\n",
      "(-1, 0)    DefaultConnectionGene(key=(-1, 0), weight=0.09953140467405319, enabled=True)\n",
      "(-2, 0)    DefaultConnectionGene(key=(-2, 0), weight=-1.150395393371582, enabled=False)\n",
      "(-2, 1)    DefaultConnectionGene(key=(-2, 1), weight=0.9563601016998291, enabled=True)\n",
      "(1, 0)    DefaultConnectionGene(key=(1, 0), weight=-0.490528404712677, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.0005860328674316406 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1615094969.724829\n",
      "The function - pre_reproduction - took 1.1920928955078125e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1615094969.724851\n",
      "Average adjusted fitness: 0.102\n",
      "The function - reproduction - took 0.0001621246337890625 seconds to complete\n",
      "The function - post reproduction - has just started at 1615094969.725025\n",
      "The function - post reproduction - took 8.106231689453125e-06 seconds to complete\n",
      "The function - speciate - has just started at 1615094969.725041\n",
      "Mean genetic distance 1.401, standard deviation 0.419\n",
      "The function - speciate - took 8.797645568847656e-05 seconds to complete\n",
      "The function - end generation - has just started at 1615094969.725137\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    1     5      0.6    0.102     0\n",
      "Total extinctions: 0\n",
      "Generation time: 2.279 sec (2.170 average)\n",
      "The function - end generation - took 5.698204040527344e-05 seconds to complete\n",
      "The function - generationStart - has just started at 1615094969.725203\n",
      "\n",
      " ****** Running generation 2 ****** \n",
      "\n",
      "The function - generationStart - took 1.5974044799804688e-05 seconds to complete\n",
      "The function - pre_backprop - has just started at 1615094969.725227\n",
      "The function - pre_backprop - took 1.9788742065429688e-05 seconds to complete\n",
      "The function - backprop - has just started at 1615094969.725255\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: 0.0\n",
      "best improvement: tensor(0., grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.6697, grad_fn=<DivBackward0>)\n",
      "The function - backprop - took 2.255157947540283 seconds to complete\n",
      "The function - post_backprop - has just started at 1615094971.980524\n",
      "The function - post_backprop - took 2.193450927734375e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1615094971.980566\n",
      "{6: <neat.genome.DefaultGenome object at 0x7fa1505b7070>, 4: <neat.genome.DefaultGenome object at 0x7fa16330a340>, 9: <neat.genome.DefaultGenome object at 0x7fa1505bcf10>, 10: <neat.genome.DefaultGenome object at 0x7fa1505bcfd0>, 11: <neat.genome.DefaultGenome object at 0x7fa1505c1250>}\n",
      "The function - evaluate fitness - took 0.0067119598388671875 seconds to complete\n",
      "The function - post evaluate - has just started at 1615094971.987328\n",
      "Population's average fitness: 0.72296 stdev: 0.21524\n",
      "Best fitness: 1.09719 - size: (2, 3) - species 1 - id 9\n",
      "Key: 9\n",
      "Fitness: 1.0971912145614624\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.4006558060646057, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=1.2642592191696167, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=0.5530250668525696, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=-0.1703117936849594, enabled=True)\n",
      "\tDefaultConnectionGene(key=(1, 0), weight=0.1489894688129425, enabled=True)\n",
      "\n",
      "\n",
      " SPECIES TOPOLOGY IMPROVEMENT\n",
      "\n",
      "\n",
      "{'genome': <neat.genome.DefaultGenome object at 0x7fa1505c1610>, 'fitness': 1.0971912145614624, 'firstDerivatives': [0.0, 0.10496878623962402, 0.4693759083747864], 'secondDerivatives': [0.0, 0.10496878623962402, 0.36440712213516235]}\n",
      "Key: 9\n",
      "Fitness: 1.0971912145614624\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.4006558060646057, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=1.2642592191696167, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=0.5530250668525696, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=-0.1703117936849594, enabled=True)\n",
      "\tDefaultConnectionGene(key=(1, 0), weight=0.1489894688129425, enabled=True)\n",
      "Nodes\n",
      "0    DefaultNodeGene(key=0, bias=-0.4006558060646057, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "1    DefaultNodeGene(key=1, bias=1.2642592191696167, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections\n",
      "(-1, 0)    DefaultConnectionGene(key=(-1, 0), weight=-0.1703117936849594, enabled=True)\n",
      "(-2, 1)    DefaultConnectionGene(key=(-2, 1), weight=0.5530250668525696, enabled=True)\n",
      "(1, 0)    DefaultConnectionGene(key=(1, 0), weight=0.1489894688129425, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.0005369186401367188 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1615094971.98788\n",
      "The function - pre_reproduction - took 1.3113021850585938e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1615094971.9879029\n",
      "Average adjusted fitness: 0.200\n",
      "The function - reproduction - took 0.00019097328186035156 seconds to complete\n",
      "The function - post reproduction - has just started at 1615094971.988106\n",
      "The function - post reproduction - took 1.1920928955078125e-05 seconds to complete\n",
      "The function - speciate - has just started at 1615094971.988126\n",
      "Mean genetic distance 1.405, standard deviation 0.311\n",
      "The function - speciate - took 0.00020694732666015625 seconds to complete\n",
      "The function - end generation - has just started at 1615094971.988343\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    2     5      1.1    0.200     0\n",
      "Total extinctions: 0\n",
      "Generation time: 2.263 sec (2.201 average)\n",
      "The function - end generation - took 5.984306335449219e-05 seconds to complete\n",
      "{0: {'generation': 0, 'generationStartTime': 1615094965.3848572, 'backpropStartTime': 1615094965.3848839, 'genomeNodeSizes': [1, 1, 1, 1, 1], 'genomeNodeSizesMean': 1.0, 'genomeNodeSizesSD': 0.0, 'genomeConnectionSizes': [2, 2, 2, 2, 2], 'genomeConnectionSizesMean': 2.0, 'genomeConnectionSizesSD': 0.0, 'backpropEndTime': 1615094967.440033, 'fitnesses': [0.4857117533683777, 0.3895120322704315, 0.46153345704078674, 0.522846519947052, 0.43600666522979736], 'fitnessMean': 0.4591220855712891, 'fitnessSD': 0.04506331292869274, 'reproductionStartTime': 1615094967.446191, 'reproductionEndTime': 1615094967.446445, 'generationEndTime': 1615094967.446639}, 1: {'generation': 1, 'generationStartTime': 1615094967.446669, 'backpropStartTime': 1615094967.446688, 'genomeNodeSizes': [1, 1, 2, 2, 1], 'genomeNodeSizesMean': 1.4, 'genomeNodeSizesSD': 0.4898979485566356, 'genomeConnectionSizes': [2, 2, 4, 4, 1], 'genomeConnectionSizesMean': 2.6, 'genomeConnectionSizesSD': 1.2, 'backpropEndTime': 1615094969.717681, 'fitnesses': [0.522846519947052, 0.4857117533683777, 0.627815306186676, 0.38114216923713684, 0.3997569978237152], 'fitnessMean': 0.4834545493125916, 'fitnessSD': 0.08929720453386164, 'reproductionStartTime': 1615094969.72484, 'reproductionEndTime': 1615094969.725033, 'generationEndTime': 1615094969.725193}, 2: {'generation': 2, 'generationStartTime': 1615094969.725219, 'backpropStartTime': 1615094969.725235, 'genomeNodeSizes': [2, 1, 2, 2, 1], 'genomeNodeSizesMean': 1.6, 'genomeNodeSizesSD': 0.4898979485566356, 'genomeConnectionSizes': [4, 2, 3, 3, 2], 'genomeConnectionSizesMean': 2.8, 'genomeConnectionSizesSD': 0.7483314773547882, 'backpropEndTime': 1615094971.980545, 'fitnesses': [0.627815306186676, 0.522846519947052, 1.0971912145614624, 0.8237760066986084, 0.5431821942329407], 'fitnessMean': 0.722962248325348, 'fitnessSD': 0.2152351487279332, 'reproductionStartTime': 1615094971.987892, 'reproductionEndTime': 1615094971.988118, 'generationEndTime': 1615094971.988402}}\n"
     ]
    }
   ],
   "source": [
    "config = base_config\n",
    "saveLocation = './'\n",
    "maxNGenerations = 3\n",
    "p = instantiate_population(config, xor_inputs, xor_outputs, saveLocation)\n",
    "# Run for up to nGenerations generations.\n",
    "winner = p.run(eval_genomes, maxNGenerations, nEpochs = 5)\n",
    "\n",
    "g = p.best_genome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.0971912145614624\nNodes:\n\t0 DefaultNodeGene(key=0, bias=-0.4006558060646057, response=1.0, activation=sigmoid, aggregation=sum)\n\t1 DefaultNodeGene(key=1, bias=1.2642592191696167, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 1), weight=0.5530250668525696, enabled=True)\n\tDefaultConnectionGene(key=(-1, 0), weight=-0.1703117936849594, enabled=True)\n\tDefaultConnectionGene(key=(1, 0), weight=0.1489894688129425, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = deepcopy(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.0971912145614624\nNodes:\n\t0 DefaultNodeGene(key=0, bias=-0.4006558060646057, response=1.0, activation=sigmoid, aggregation=sum)\n\t1 DefaultNodeGene(key=1, bias=1.2642592191696167, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 1), weight=0.5530250668525696, enabled=True)\n\tDefaultConnectionGene(key=(-1, 0), weight=-0.1703117936849594, enabled=True)\n\tDefaultConnectionGene(key=(1, 0), weight=0.1489894688129425, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.0971912145614624\nNodes:\n\t0 DefaultNodeGene(key=0, bias=-0.4006558060646057, response=1.0, activation=sigmoid, aggregation=sum)\n\t1 DefaultNodeGene(key=1, bias=1.2642592191696167, response=1.0, activation=sigmoid, aggregation=sum)\n\t4 DefaultNodeGene(key=4, bias=-0.8663857890656896, response=1.0, activation=sigmoid, aggregation=sum)\n\t5 DefaultNodeGene(key=5, bias=2.458661014796236, response=1.0, activation=sigmoid, aggregation=sum)\n\t6 DefaultNodeGene(key=6, bias=-1.1082741878131992, response=1.0, activation=sigmoid, aggregation=sum)\n\t7 DefaultNodeGene(key=7, bias=0.03375522113074291, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 1), weight=0.5530250668525696, enabled=False)\n\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-2, 5), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-1, 0), weight=-0.1703117936849594, enabled=True)\n\tDefaultConnectionGene(key=(-1, 4), weight=0.9151367334505461, enabled=True)\n\tDefaultConnectionGene(key=(1, 0), weight=0.1489894688129425, enabled=False)\n\tDefaultConnectionGene(key=(1, 6), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(4, 1), weight=0.5530250668525696, enabled=True)\n\tDefaultConnectionGene(key=(4, 6), weight=0.07014285931465711, enabled=True)\n\tDefaultConnectionGene(key=(4, 7), weight=0.5281321570057987, enabled=True)\n\tDefaultConnectionGene(key=(5, 1), weight=0.5530250668525696, enabled=True)\n\tDefaultConnectionGene(key=(6, 0), weight=0.1489894688129425, enabled=False)\n\tDefaultConnectionGene(key=(6, 7), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(7, 0), weight=0.1489894688129425, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.add_connection(p.config.genome_config, 16, 17, 0.2, True)\n",
    "# h.add_connection(p.config.genome_config, 17, 0, 0.2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.0971912145614624\nNodes:\n\t0 DefaultNodeGene(key=0, bias=-0.4006558060646057, response=1.0, activation=sigmoid, aggregation=sum)\n\t1 DefaultNodeGene(key=1, bias=1.2642592191696167, response=1.0, activation=sigmoid, aggregation=sum)\n\t4 DefaultNodeGene(key=4, bias=-0.8663857890656896, response=1.0, activation=sigmoid, aggregation=sum)\n\t5 DefaultNodeGene(key=5, bias=2.458661014796236, response=1.0, activation=sigmoid, aggregation=sum)\n\t6 DefaultNodeGene(key=6, bias=-1.1082741878131992, response=1.0, activation=sigmoid, aggregation=sum)\n\t7 DefaultNodeGene(key=7, bias=0.03375522113074291, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 1), weight=0.5530250668525696, enabled=False)\n\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-2, 5), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-1, 0), weight=-0.1703117936849594, enabled=True)\n\tDefaultConnectionGene(key=(-1, 4), weight=0.9151367334505461, enabled=True)\n\tDefaultConnectionGene(key=(1, 0), weight=0.1489894688129425, enabled=False)\n\tDefaultConnectionGene(key=(1, 6), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(4, 1), weight=0.5530250668525696, enabled=True)\n\tDefaultConnectionGene(key=(4, 6), weight=0.07014285931465711, enabled=True)\n\tDefaultConnectionGene(key=(4, 7), weight=0.5281321570057987, enabled=True)\n\tDefaultConnectionGene(key=(5, 1), weight=0.5530250668525696, enabled=True)\n\tDefaultConnectionGene(key=(6, 0), weight=0.1489894688129425, enabled=False)\n\tDefaultConnectionGene(key=(6, 7), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(7, 0), weight=0.1489894688129425, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "p.config.genome_config.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: <neat.genes.DefaultNodeGene at 0x7fa161909790>,\n",
       " 1: <neat.genes.DefaultNodeGene at 0x7fa161909eb0>,\n",
       " 4: <neat.genes.DefaultNodeGene at 0x7fa1505c3370>,\n",
       " 5: <neat.genes.DefaultNodeGene at 0x7fa1505c1a60>,\n",
       " 6: <neat.genes.DefaultNodeGene at 0x7fa1505c3730>,\n",
       " 7: <neat.genes.DefaultNodeGene at 0x7fa1505c3a30>}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "h.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_tracker = {node_id:{'depth':0, 'output_ids':[], 'input_ids':[]} for node_id in h.nodes}\n",
    "for node_id in p.config.genome_config.input_keys:\n",
    "    node_tracker[node_id] = {'depth':0, 'output_ids':[], 'input_ids':[]}\n",
    "trace_stack = [node_id for node_id in p.config.genome_config.input_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "trace_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 1: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 4: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 5: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 6: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 7: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " -1: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " -2: {'depth': 0, 'output_ids': [], 'input_ids': []}}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(-1, 0)\n(-2, 1)\n(1, 0)\n(-2, 4)\n(4, 1)\n(-2, 5)\n(5, 1)\n(1, 6)\n(6, 0)\n(6, 7)\n(7, 0)\n(-1, 4)\n(4, 7)\n(4, 6)\n"
     ]
    }
   ],
   "source": [
    "for connection in h.connections:\n",
    "    print(connection)\n",
    "    node_tracker[connection[0]]['output_ids'].append(connection[1])\n",
    "    node_tracker[connection[1]]['input_ids'].append(connection[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(trace_stack) > 0:\n",
    "    trace = trace_stack[0]\n",
    "    my_depth = node_tracker[trace]['depth']\n",
    "    next_depth = my_depth + 1\n",
    "    for output_id in node_tracker[trace]['output_ids']:\n",
    "        node_tracker[output_id]['depth'] = max(node_tracker[output_id]['depth'], next_depth)\n",
    "        trace_stack.append(output_id)\n",
    "    del(trace_stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'depth': 5, 'output_ids': [], 'input_ids': [-1, 1, 6, 7]},\n",
       " 1: {'depth': 2, 'output_ids': [0, 6], 'input_ids': [-2, 4, 5]},\n",
       " 4: {'depth': 1, 'output_ids': [1, 7, 6], 'input_ids': [-2, -1]},\n",
       " 5: {'depth': 1, 'output_ids': [1], 'input_ids': [-2]},\n",
       " 6: {'depth': 3, 'output_ids': [0, 7], 'input_ids': [1, 4]},\n",
       " 7: {'depth': 4, 'output_ids': [0], 'input_ids': [6, 4]},\n",
       " -1: {'depth': 0, 'output_ids': [0, 4], 'input_ids': []},\n",
       " -2: {'depth': 0, 'output_ids': [1, 4, 5], 'input_ids': []}}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['output_layers']=[]\n",
    "    node['needs_skip'] = False\n",
    "    node['id'] = node_id\n",
    "    for output_id in node['output_ids']:\n",
    "        node['output_layers'].append(node_tracker[output_id]['depth'])\n",
    "        if node_tracker[output_id]['depth'] > (node['depth']+1):\n",
    "            node['needs_skip'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['input_layers'] = []\n",
    "    node['skip_layer_input'] = False\n",
    "    for input_id in node['input_ids']:\n",
    "        node['input_layers'].append(node_tracker[input_id]['depth'])\n",
    "        if node_tracker[input_id]['depth'] < (node['depth']-1):\n",
    "            node['skip_layer_input'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'depth': 5,\n",
       "  'output_ids': [],\n",
       "  'input_ids': [-1, 1, 6, 7],\n",
       "  'output_layers': [],\n",
       "  'needs_skip': False,\n",
       "  'id': 0,\n",
       "  'input_layers': [0, 2, 3, 4],\n",
       "  'skip_layer_input': True},\n",
       " 1: {'depth': 2,\n",
       "  'output_ids': [0, 6],\n",
       "  'input_ids': [-2, 4, 5],\n",
       "  'output_layers': [5, 3],\n",
       "  'needs_skip': True,\n",
       "  'id': 1,\n",
       "  'input_layers': [0, 1, 1],\n",
       "  'skip_layer_input': True},\n",
       " 4: {'depth': 1,\n",
       "  'output_ids': [1, 7, 6],\n",
       "  'input_ids': [-2, -1],\n",
       "  'output_layers': [2, 4, 3],\n",
       "  'needs_skip': True,\n",
       "  'id': 4,\n",
       "  'input_layers': [0, 0],\n",
       "  'skip_layer_input': False},\n",
       " 5: {'depth': 1,\n",
       "  'output_ids': [1],\n",
       "  'input_ids': [-2],\n",
       "  'output_layers': [2],\n",
       "  'needs_skip': False,\n",
       "  'id': 5,\n",
       "  'input_layers': [0],\n",
       "  'skip_layer_input': False},\n",
       " 6: {'depth': 3,\n",
       "  'output_ids': [0, 7],\n",
       "  'input_ids': [1, 4],\n",
       "  'output_layers': [5, 4],\n",
       "  'needs_skip': True,\n",
       "  'id': 6,\n",
       "  'input_layers': [2, 1],\n",
       "  'skip_layer_input': True},\n",
       " 7: {'depth': 4,\n",
       "  'output_ids': [0],\n",
       "  'input_ids': [6, 4],\n",
       "  'output_layers': [5],\n",
       "  'needs_skip': False,\n",
       "  'id': 7,\n",
       "  'input_layers': [3, 1],\n",
       "  'skip_layer_input': True},\n",
       " -1: {'depth': 0,\n",
       "  'output_ids': [0, 4],\n",
       "  'input_ids': [],\n",
       "  'output_layers': [5, 1],\n",
       "  'needs_skip': True,\n",
       "  'id': -1,\n",
       "  'input_layers': [],\n",
       "  'skip_layer_input': False},\n",
       " -2: {'depth': 0,\n",
       "  'output_ids': [1, 4, 5],\n",
       "  'input_ids': [],\n",
       "  'output_layers': [2, 1, 1],\n",
       "  'needs_skip': True,\n",
       "  'id': -2,\n",
       "  'input_layers': [],\n",
       "  'skip_layer_input': False}}"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-1, 1, 6, 7],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 2, 3, 4],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 2: {'nodes': {1: {'depth': 2,\n",
       "    'output_ids': [0, 6],\n",
       "    'input_ids': [-2, 4, 5],\n",
       "    'output_layers': [5, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 1,\n",
       "    'input_layers': [0, 1, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 1: {'nodes': {4: {'depth': 1,\n",
       "    'output_ids': [1, 7, 6],\n",
       "    'input_ids': [-2, -1],\n",
       "    'output_layers': [2, 4, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   5: {'depth': 1,\n",
       "    'output_ids': [1],\n",
       "    'input_ids': [-2],\n",
       "    'output_layers': [2],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}}},\n",
       " 3: {'nodes': {6: {'depth': 3,\n",
       "    'output_ids': [0, 7],\n",
       "    'input_ids': [1, 4],\n",
       "    'output_layers': [5, 4],\n",
       "    'needs_skip': True,\n",
       "    'id': 6,\n",
       "    'input_layers': [2, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 4: {'nodes': {7: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [6, 4],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 7,\n",
       "    'input_layers': [3, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [0, 4],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [1, 4, 5],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [2, 1, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}}}}"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "layers = {}\n",
    "for node_id, node in node_tracker.items():\n",
    "    if not node['depth'] in layers:\n",
    "        layers[node['depth']] = {\n",
    "            'nodes':{node_id:node}\n",
    "        }\n",
    "    else:\n",
    "        layers[node['depth']]['nodes'][node_id] = node\n",
    "        \n",
    "# Ensure all nodes have a layer index\n",
    "for layer_id, layer in layers.items():\n",
    "    layer_index = 0\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "        \n",
    "        \n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "my layer id is 5\nDefaultConnectionGene(key=(-1, 0), weight=-0.1703117936849594, enabled=True)\n-0.1703117936849594\nlocation is\n(0, 0)\nDefaultConnectionGene(key=(1, 0), weight=0.1489894688129425, enabled=False)\nDefaultConnectionGene(key=(6, 0), weight=0.1489894688129425, enabled=False)\nDefaultConnectionGene(key=(7, 0), weight=0.1489894688129425, enabled=True)\n0.1489894688129425\nlocation is\n(0, 4)\nmy layer id is 2\nDefaultConnectionGene(key=(-2, 1), weight=0.5530250668525696, enabled=False)\nDefaultConnectionGene(key=(4, 1), weight=0.5530250668525696, enabled=True)\n0.5530250668525696\nlocation is\n(0, 2)\nDefaultConnectionGene(key=(5, 1), weight=0.5530250668525696, enabled=True)\n0.5530250668525696\nlocation is\n(0, 3)\nmy layer id is 1\nDefaultConnectionGene(key=(-1, 4), weight=0.9151367334505461, enabled=True)\n0.9151367334505461\nlocation is\n(0, 0)\nDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 1)\nDefaultConnectionGene(key=(-2, 5), weight=1.0, enabled=True)\n1.0\nlocation is\n(1, 1)\nmy layer id is 3\nDefaultConnectionGene(key=(4, 6), weight=0.07014285931465711, enabled=True)\n0.07014285931465711\nlocation is\n(0, 0)\nDefaultConnectionGene(key=(1, 6), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 2)\nmy layer id is 4\nDefaultConnectionGene(key=(4, 7), weight=0.5281321570057987, enabled=True)\n0.5281321570057987\nlocation is\n(0, 0)\nDefaultConnectionGene(key=(6, 7), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 2)\nmy layer id is 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LAYER_TYPE_CONNECTED = \"CONNECTED\"\n",
    "LAYER_TYPE_INPUT = \"INPUT\"\n",
    "LAYER_TYPE_OUTPUT = \"OUTPUT\"\n",
    "for layer_id, layer in layers.items():\n",
    "    layer['is_output_layer'] = False\n",
    "    layer['is_input_layer'] = False\n",
    "    layer['layer_type'] = LAYER_TYPE_CONNECTED\n",
    "    # If I have the output node in me, then I am an output\n",
    "    if 0 in layer['nodes']:\n",
    "        layer['is_output_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_OUTPUT\n",
    "\n",
    "    # If I have the first input in me, then I am the input\n",
    "    if -1 in layer['nodes']:\n",
    "        layer['is_input_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_INPUT\n",
    "    biases = []\n",
    "\n",
    "    layer['input_layers'] = []\n",
    "    ## Compute the shape of required inputs\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        for in_layer in node['input_layers']:\n",
    "            if in_layer not in layer['input_layers']:\n",
    "                layer['input_layers'].append(in_layer)\n",
    "    layer['input_layers'].sort()\n",
    "    layer['input_shape'] = sum(len(layers[jj]['nodes']) for jj in layer['input_layers'])\n",
    "    layer['weights_shape'] = (layer['input_shape'], len(layer['nodes']))\n",
    "\n",
    "\n",
    "    # Handle output layer \"edge\" case\n",
    "    if layer['is_output_layer']:\n",
    "        layer['out_weights'] = []\n",
    "        layer['bias'] = [h.nodes[node_id].bias for node_id, node in layer['nodes'].items()]\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle input layer \"edge\" case\n",
    "    elif layer['is_input_layer']:\n",
    "        layer['in_weights'] = []\n",
    "        layer['bias'] = []\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle generic case\n",
    "    else:\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "\n",
    "        layer['bias'] = [h.nodes[node_id].bias for node_id, node in layer['nodes'].items()]\n",
    "        # else:\n",
    "            # layer['bias'] = [0 for _ in layer['nodes']]\n",
    "    \n",
    "    layer_index = 0          \n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "        ### POSSIBLY NEED THIS\n",
    "        # if node['id'] < 0:\n",
    "        #     biases.append(1)\n",
    "        # else:\n",
    "        #     biases.append(h.nodes[node['id']].bias)\n",
    "        # for output_id in node['output_ids']:\n",
    "        #     if (node['id'], output_id) in h.connections:\n",
    "        #         if output_id in layers[layer_id + 1]['nodes']:\n",
    "        #             layer['out_weights'][node['layer_index']][layers[layer_id + 1]['nodes'][output_id]['layer_index']] = h.connections[(node['id'], output_id)].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        # for input_id in node['input_ids']:\n",
    "        #     if (input_id, node['id']) in h.connections:\n",
    "        #         if input_id in layers[layer_id - 1]['nodes']:\n",
    "        #             layer['in_weights'][node['layer_index']][layers[layer_id -1]['nodes'][input_id]['layer_index']] = h.connections[(input_id, node['id'])].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        #################################################\n",
    "            ### END OF POSSIBLY NEEDING THIS\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "\n",
    "\n",
    "    # layer['out_tensor'] = torch.tensor(layer['out_weights'])\n",
    "    # layer['bias'] = torch.tensor(layer['bias'])\n",
    "    # layer['out_tensor_shape'] = layer['out_tensor'].shape\n",
    "    # layer['in_tensor'] = torch.tensor(layer['in_weights'])\n",
    "    # layer['in_tensor_shape'] = layer['in_tensor'].shape\n",
    "\n",
    "\n",
    "\n",
    "    # Set up current weights\n",
    "    layer['input_weights'] = np.zeros(layer['weights_shape'])\n",
    "    layer_offset = 0\n",
    "    # Check every layer and every node for connections\n",
    "    print(\"my layer id is %s\" % (layer_id))\n",
    "    for input_layer_id in layer['input_layers']:\n",
    "        input_layer = layers[input_layer_id]\n",
    "        for node_id, node in input_layer['nodes'].items():\n",
    "            for node_output_id in node['output_ids']:\n",
    "                if node_output_id in layer['nodes']:\n",
    "                    node_output = layer['nodes'][node_output_id]\n",
    "                    # I HAVE THIS NODE!\n",
    "                    # What is it's weight?\n",
    "                    connection = h.connections[(node_id, node_output_id)]\n",
    "                    print(connection)\n",
    "\n",
    "                    if not connection.enabled:\n",
    "                        continue\n",
    "                    connection_weight = connection.weight\n",
    "                    print(connection_weight)\n",
    "\n",
    "                    in_weight_location = layer_offset + node['layer_index']\n",
    "                    out_weight_location = node_output['layer_index']\n",
    "                    print('location is')\n",
    "                    print((out_weight_location, in_weight_location))\n",
    "                    layer['input_weights'][in_weight_location][out_weight_location] = connection_weight\n",
    "        layer_offset += len(input_layer['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-1, 1, 6, 7],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 2, 3, 4],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': True,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'OUTPUT',\n",
       "  'input_layers': [0, 2, 3, 4],\n",
       "  'input_shape': 5,\n",
       "  'weights_shape': (5, 1),\n",
       "  'out_weights': [],\n",
       "  'bias': [-0.4006558060646057],\n",
       "  'in_weights': [[0]],\n",
       "  'input_weights': array([[-0.17031179],\n",
       "         [ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [ 0.14898947]])},\n",
       " 2: {'nodes': {1: {'depth': 2,\n",
       "    'output_ids': [0, 6],\n",
       "    'input_ids': [-2, 4, 5],\n",
       "    'output_layers': [5, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 1,\n",
       "    'input_layers': [0, 1, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0, 1],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0, 0]],\n",
       "  'bias': [1.2642592191696167],\n",
       "  'input_weights': array([[0.        ],\n",
       "         [0.        ],\n",
       "         [0.55302507],\n",
       "         [0.55302507]])},\n",
       " 1: {'nodes': {4: {'depth': 1,\n",
       "    'output_ids': [1, 7, 6],\n",
       "    'input_ids': [-2, -1],\n",
       "    'output_layers': [2, 4, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   5: {'depth': 1,\n",
       "    'output_ids': [1],\n",
       "    'input_ids': [-2],\n",
       "    'output_layers': [2],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0],\n",
       "  'input_shape': 2,\n",
       "  'weights_shape': (2, 2),\n",
       "  'out_weights': [[0], [0]],\n",
       "  'in_weights': [[0, 0], [0, 0]],\n",
       "  'bias': [-0.8663857890656896, 2.458661014796236],\n",
       "  'input_weights': array([[0.91513673, 0.        ],\n",
       "         [1.        , 1.        ]])},\n",
       " 3: {'nodes': {6: {'depth': 3,\n",
       "    'output_ids': [0, 7],\n",
       "    'input_ids': [1, 4],\n",
       "    'output_layers': [5, 4],\n",
       "    'needs_skip': True,\n",
       "    'id': 6,\n",
       "    'input_layers': [2, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [1, 2],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-1.1082741878131992],\n",
       "  'input_weights': array([[0.07014286],\n",
       "         [0.        ],\n",
       "         [1.        ]])},\n",
       " 4: {'nodes': {7: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [6, 4],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 7,\n",
       "    'input_layers': [3, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [1, 3],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [0.03375522113074291],\n",
       "  'input_weights': array([[0.52813216],\n",
       "         [0.        ],\n",
       "         [1.        ]])},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [0, 4],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [1, 4, 5],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [2, 1, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': True,\n",
       "  'layer_type': 'INPUT',\n",
       "  'input_layers': [],\n",
       "  'input_shape': 0,\n",
       "  'weights_shape': (0, 2),\n",
       "  'in_weights': [],\n",
       "  'bias': [],\n",
       "  'out_weights': [[0, 0], [0, 0]],\n",
       "  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "source": [
    "Add in computation of skip layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'nodes': {1: {'depth': 2,\n",
       "   'output_ids': [0, 6],\n",
       "   'input_ids': [-2, 4, 5],\n",
       "   'output_layers': [5, 3],\n",
       "   'needs_skip': True,\n",
       "   'id': 1,\n",
       "   'input_layers': [0, 1, 1],\n",
       "   'skip_layer_input': True,\n",
       "   'layer_index': 0}},\n",
       " 'is_output_layer': False,\n",
       " 'is_input_layer': False,\n",
       " 'layer_type': 'CONNECTED',\n",
       " 'input_layers': [0, 1],\n",
       " 'input_shape': 4,\n",
       " 'weights_shape': (4, 1),\n",
       " 'out_weights': [[0]],\n",
       " 'in_weights': [[0, 0]],\n",
       " 'bias': [1.2642592191696167],\n",
       " 'input_weights': array([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.55302507],\n",
       "        [0.55302507]])}"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-1, 1, 6, 7],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 2, 3, 4],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': True,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'OUTPUT',\n",
       "  'input_layers': [0, 2, 3, 4],\n",
       "  'input_shape': 5,\n",
       "  'weights_shape': (5, 1),\n",
       "  'out_weights': [],\n",
       "  'bias': [-0.4006558060646057],\n",
       "  'in_weights': [[0]],\n",
       "  'input_weights': array([[-0.17031179],\n",
       "         [ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [ 0.14898947]])},\n",
       " 2: {'nodes': {1: {'depth': 2,\n",
       "    'output_ids': [0, 6],\n",
       "    'input_ids': [-2, 4, 5],\n",
       "    'output_layers': [5, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 1,\n",
       "    'input_layers': [0, 1, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0, 1],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0, 0]],\n",
       "  'bias': [1.2642592191696167],\n",
       "  'input_weights': array([[0.        ],\n",
       "         [0.        ],\n",
       "         [0.55302507],\n",
       "         [0.55302507]])},\n",
       " 1: {'nodes': {4: {'depth': 1,\n",
       "    'output_ids': [1, 7, 6],\n",
       "    'input_ids': [-2, -1],\n",
       "    'output_layers': [2, 4, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   5: {'depth': 1,\n",
       "    'output_ids': [1],\n",
       "    'input_ids': [-2],\n",
       "    'output_layers': [2],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0],\n",
       "  'input_shape': 2,\n",
       "  'weights_shape': (2, 2),\n",
       "  'out_weights': [[0], [0]],\n",
       "  'in_weights': [[0, 0], [0, 0]],\n",
       "  'bias': [-0.8663857890656896, 2.458661014796236],\n",
       "  'input_weights': array([[0.91513673, 0.        ],\n",
       "         [1.        , 1.        ]])},\n",
       " 3: {'nodes': {6: {'depth': 3,\n",
       "    'output_ids': [0, 7],\n",
       "    'input_ids': [1, 4],\n",
       "    'output_layers': [5, 4],\n",
       "    'needs_skip': True,\n",
       "    'id': 6,\n",
       "    'input_layers': [2, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [1, 2],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-1.1082741878131992],\n",
       "  'input_weights': array([[0.07014286],\n",
       "         [0.        ],\n",
       "         [1.        ]])},\n",
       " 4: {'nodes': {7: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [6, 4],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 7,\n",
       "    'input_layers': [3, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [1, 3],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [0.03375522113074291],\n",
       "  'input_weights': array([[0.52813216],\n",
       "         [0.        ],\n",
       "         [1.        ]])},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [0, 4],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [1, 4, 5],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [2, 1, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': True,\n",
       "  'layer_type': 'INPUT',\n",
       "  'input_layers': [],\n",
       "  'input_shape': 0,\n",
       "  'weights_shape': (0, 2),\n",
       "  'in_weights': [],\n",
       "  'bias': [],\n",
       "  'out_weights': [[0, 0], [0, 0]],\n",
       "  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "source": [
    "The question is, how do you code the operations to dynamically create the\n",
    "NN? You need to be able to do the right things in the right order. You have\n",
    "a list of possible operations:\n",
    "* Matrix multiple\n",
    "* Concatenate (for skip layers)\n",
    "* Matrix addition (for biases)\n",
    "* Output\n",
    "\n",
    "The order of operations in each layer is:\n",
    "\n",
    "1. Concatenate input tensors\n",
    "2. Matrix multiply input tensors with weights\n",
    "3. Add bias tensors\n",
    "4. Apply activation function\n",
    "\n",
    "I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "These computations can be computed back-to-front, and then executed forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "ACTIVATE_OPERATION = \"ACTIVATE\"\n",
    "OUTPUT_OPERATION = \"OUTPUT\"\n",
    "TENADD_OPERATION = \"TENADD\" # Tensor ADD\n",
    "ADD_BIAS_OPERATION = \"BIASADD\"\n",
    "TENMUL_OPERATION = \"TENMUL\"\n",
    "TENCAT_OPERATION = \"TENCAT\"\n",
    "order_of_operations = []\n",
    "\n",
    "# for layer_id, layer in layers.items():\n",
    "#     print(layer)\n",
    "#     # Output for final layer\n",
    "#     if layer['is_output_layer']:\n",
    "#         order_of_operations.append(OUTPUT_OPERATION)\n",
    "#     # Activate\n",
    "#     order_of_operations.append(ACTIVATE_OPERATION)\n",
    "#     # Add Bias\n",
    "#     order_of_operations.append(ADD_BIAS_OPERATION)\n",
    "#     # Matrix Multiply weights\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     print(order_of_operations)\n",
    "\n",
    "#     break\n",
    "\n",
    "for layer_id in range(len(layers)):\n",
    "    layer = layers[layer_id]\n",
    "    print(layer)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'nodes': {-1: {'depth': 0, 'output_ids': [0, 4], 'input_ids': [], 'output_layers': [5, 1], 'needs_skip': True, 'id': -1, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 0}, -2: {'depth': 0, 'output_ids': [1, 4, 5], 'input_ids': [], 'output_layers': [2, 1, 1], 'needs_skip': True, 'id': -2, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 1}}, 'is_output_layer': False, 'is_input_layer': True, 'layer_type': 'INPUT', 'input_layers': [], 'input_shape': 0, 'weights_shape': (0, 2), 'in_weights': [], 'bias': [], 'out_weights': [[0, 0], [0, 0]], 'input_weights': array([], shape=(0, 2), dtype=float64)}\n{'nodes': {4: {'depth': 1, 'output_ids': [1, 7, 6], 'input_ids': [-2, -1], 'output_layers': [2, 4, 3], 'needs_skip': True, 'id': 4, 'input_layers': [0, 0], 'skip_layer_input': False, 'layer_index': 0}, 5: {'depth': 1, 'output_ids': [1], 'input_ids': [-2], 'output_layers': [2], 'needs_skip': False, 'id': 5, 'input_layers': [0], 'skip_layer_input': False, 'layer_index': 1}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0], 'input_shape': 2, 'weights_shape': (2, 2), 'out_weights': [[0], [0]], 'in_weights': [[0, 0], [0, 0]], 'bias': [-0.8663857890656896, 2.458661014796236], 'input_weights': array([[0.91513673, 0.        ],\n       [1.        , 1.        ]])}\n{'nodes': {1: {'depth': 2, 'output_ids': [0, 6], 'input_ids': [-2, 4, 5], 'output_layers': [5, 3], 'needs_skip': True, 'id': 1, 'input_layers': [0, 1, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0, 1], 'input_shape': 4, 'weights_shape': (4, 1), 'out_weights': [[0]], 'in_weights': [[0, 0]], 'bias': [1.2642592191696167], 'input_weights': array([[0.        ],\n       [0.        ],\n       [0.55302507],\n       [0.55302507]])}\n{'nodes': {6: {'depth': 3, 'output_ids': [0, 7], 'input_ids': [1, 4], 'output_layers': [5, 4], 'needs_skip': True, 'id': 6, 'input_layers': [2, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [1, 2], 'input_shape': 3, 'weights_shape': (3, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [-1.1082741878131992], 'input_weights': array([[0.07014286],\n       [0.        ],\n       [1.        ]])}\n{'nodes': {7: {'depth': 4, 'output_ids': [0], 'input_ids': [6, 4], 'output_layers': [5], 'needs_skip': False, 'id': 7, 'input_layers': [3, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [1, 3], 'input_shape': 3, 'weights_shape': (3, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [0.03375522113074291], 'input_weights': array([[0.52813216],\n       [0.        ],\n       [1.        ]])}\n{'nodes': {0: {'depth': 5, 'output_ids': [], 'input_ids': [-1, 1, 6, 7], 'output_layers': [], 'needs_skip': False, 'id': 0, 'input_layers': [0, 2, 3, 4], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': True, 'is_input_layer': False, 'layer_type': 'OUTPUT', 'input_layers': [0, 2, 3, 4], 'input_shape': 5, 'weights_shape': (5, 1), 'out_weights': [], 'bias': [-0.4006558060646057], 'in_weights': [[0]], 'input_weights': array([[-0.17031179],\n       [ 0.        ],\n       [ 0.        ],\n       [ 0.        ],\n       [ 0.14898947]])}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(3, 1)\n",
    "c = torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 3.5621],\n",
       "        [-0.6318]])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-1, 1, 6, 7],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 2, 3, 4],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': True,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'OUTPUT',\n",
       "  'input_layers': [0, 2, 3, 4],\n",
       "  'input_shape': 5,\n",
       "  'weights_shape': (5, 1),\n",
       "  'out_weights': [],\n",
       "  'bias': [-0.4006558060646057],\n",
       "  'in_weights': [[0]],\n",
       "  'input_weights': array([[-0.17031179],\n",
       "         [ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [ 0.14898947]])},\n",
       " 2: {'nodes': {1: {'depth': 2,\n",
       "    'output_ids': [0, 6],\n",
       "    'input_ids': [-2, 4, 5],\n",
       "    'output_layers': [5, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 1,\n",
       "    'input_layers': [0, 1, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0, 1],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0, 0]],\n",
       "  'bias': [1.2642592191696167],\n",
       "  'input_weights': array([[0.        ],\n",
       "         [0.        ],\n",
       "         [0.55302507],\n",
       "         [0.55302507]])},\n",
       " 1: {'nodes': {4: {'depth': 1,\n",
       "    'output_ids': [1, 7, 6],\n",
       "    'input_ids': [-2, -1],\n",
       "    'output_layers': [2, 4, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   5: {'depth': 1,\n",
       "    'output_ids': [1],\n",
       "    'input_ids': [-2],\n",
       "    'output_layers': [2],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0],\n",
       "  'input_shape': 2,\n",
       "  'weights_shape': (2, 2),\n",
       "  'out_weights': [[0], [0]],\n",
       "  'in_weights': [[0, 0], [0, 0]],\n",
       "  'bias': [-0.8663857890656896, 2.458661014796236],\n",
       "  'input_weights': array([[0.91513673, 0.        ],\n",
       "         [1.        , 1.        ]])},\n",
       " 3: {'nodes': {6: {'depth': 3,\n",
       "    'output_ids': [0, 7],\n",
       "    'input_ids': [1, 4],\n",
       "    'output_layers': [5, 4],\n",
       "    'needs_skip': True,\n",
       "    'id': 6,\n",
       "    'input_layers': [2, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [1, 2],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-1.1082741878131992],\n",
       "  'input_weights': array([[0.07014286],\n",
       "         [0.        ],\n",
       "         [1.        ]])},\n",
       " 4: {'nodes': {7: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [6, 4],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 7,\n",
       "    'input_layers': [3, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [1, 3],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [0.03375522113074291],\n",
       "  'input_weights': array([[0.52813216],\n",
       "         [0.        ],\n",
       "         [1.        ]])},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [0, 4],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [1, 4, 5],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [2, 1, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': True,\n",
       "  'layer_type': 'INPUT',\n",
       "  'input_layers': [],\n",
       "  'input_shape': 0,\n",
       "  'weights_shape': (0, 2),\n",
       "  'in_weights': [],\n",
       "  'bias': [],\n",
       "  'out_weights': [[0, 0], [0, 0]],\n",
       "  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = nn.Parameter(torch.tensor([0.3, 0.4], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Net, self).__init__()  # just run the init of parent class (nn.Module)\n",
    "        self.weights = {layer_id: self._tt(layer['input_weights'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.biases = {layer_id: self._tt(layer['bias'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.layer_types = {layer_id: layer['layer_type'] for layer_id, layer in layers.items()}\n",
    "        self.layer_inputs = {layer_id: layer['input_layers'] for layer_id, layer in layers.items()}\n",
    "        self.n_layers = len(layers)\n",
    "\n",
    "        self._outputs = None\n",
    "\n",
    "        for w_id, w in self.weights.items():\n",
    "            self.register_parameter(name =\"weight_%s\"%w_id, param=w)\n",
    "\n",
    "        for b_id, b in self.biases.items():\n",
    "            self.register_parameter(name = \"bias_%s\"%b_id, param=b)\n",
    "\n",
    "        # x = F.relu(self.fc1(x))\n",
    "\n",
    "        # self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tt(mat):\n",
    "        return torch.nn.Parameter(torch.tensor(mat,dtype=torch.float64), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        # print(\"running forward\")\n",
    "        self._outputs = {}\n",
    "        for layer_id in range(self.n_layers):\n",
    "            layer_input = None\n",
    "            layer_type = self.layer_types[layer_id]\n",
    "\n",
    "            # print(layer_id)\n",
    "            # print(layer_type)\n",
    "\n",
    "            if layer_type == LAYER_TYPE_INPUT:\n",
    "                self._outputs[layer_id] = x\n",
    "                continue\n",
    "            if layer_type == LAYER_TYPE_CONNECTED:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "\n",
    "            # print(layer_input)\n",
    "            # print(self.weights[layer_id])\n",
    "            # print(self.biases[layer_id])\n",
    "\n",
    "            self._outputs[layer_id] = torch.sigmoid( torch.matmul(layer_input, self.weights[layer_id]) + self.biases[layer_id] )\n",
    "\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                return self._outputs[layer_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: Parameter containing:\n",
       " tensor([-0.4007], dtype=torch.float64, requires_grad=True),\n",
       " 2: Parameter containing:\n",
       " tensor([1.2643], dtype=torch.float64, requires_grad=True),\n",
       " 1: Parameter containing:\n",
       " tensor([-0.8664,  2.4587], dtype=torch.float64, requires_grad=True),\n",
       " 3: Parameter containing:\n",
       " tensor([-1.1083], dtype=torch.float64, requires_grad=True),\n",
       " 4: Parameter containing:\n",
       " tensor([0.0338], dtype=torch.float64, requires_grad=True),\n",
       " 0: Parameter containing:\n",
       " tensor([], dtype=torch.float64, requires_grad=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "net.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "net._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.4130], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "result = net.forward(x_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "expected_result = torch.tensor(xor(x_input[0], x_input[1]))\n",
    "expected_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The function - benchmark - has just started at 1615094972.375127\n",
      "The function - benchmark - took 5.074125051498413 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "# x_input = torch.randn(1, 1, 2, dtype=torch.float64)\n",
    "with MethodTimer('benchmark'):\n",
    "\n",
    "    for k in range(25):\n",
    "        for n in range(400):\n",
    "            x_input = nn.Parameter(torch.tensor([np.random.rand(), np.random.rand()], dtype=torch.float64))\n",
    "\n",
    "\n",
    "            result = net.forward(x_input)\n",
    "            expected_result = torch.tensor(xor(x_input[0], x_input[1]), dtype=torch.float64)\n",
    "            # print(x_input)\n",
    "            # print(expected_result)\n",
    "            # print(result)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(result, expected_result)\n",
    "            net.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                # for parameter in net.parameters():\n",
    "                    # parameter.data -= learning_rate*parameter.grad.data\n",
    "                    # weight -= learning_rate * weight.grad\n",
    "                for  w_id, weight in net.weights.items():\n",
    "                    try:\n",
    "                        weight -= learning_rate * weight.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "                for  b_id, bias in net.biases.items():\n",
    "                    try:\n",
    "                        bias -= learning_rate * bias.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(torch.tensor(xor_inputs, dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.0018,  0.0001], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "net.biases[1].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.5856], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "output = net(x_input)\n",
    "loss = loss_fn(result, expected_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[0.2662],\n        [0.0670],\n        [0.2475],\n        [0.0657],\n        [0.2496]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.1673],\n        [-0.1798],\n        [ 0.3681],\n        [ 0.1978]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[ 0.9123, -0.0033],\n        [ 0.9923,  0.9991]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.0805],\n        [-0.2828],\n        [ 0.7490]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[ 0.3443],\n        [-0.3593],\n        [ 0.8709]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.0767], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([0.8895], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.8925,  2.4565], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-1.4061], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.3450], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "myW = net.weights[1]"
   ]
  },
  {
   "source": [
    "myW"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9123, -0.0033],\n",
       "        [ 0.9923,  0.9991]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.1717, dtype=torch.float64, grad_fn=<MseLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[0.2662],\n        [0.0670],\n        [0.2475],\n        [0.0657],\n        [0.2496]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.1673],\n        [-0.1798],\n        [ 0.3681],\n        [ 0.1978]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[ 0.9123, -0.0033],\n        [ 0.9923,  0.9991]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.0805],\n        [-0.2828],\n        [ 0.7490]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[ 0.3443],\n        [-0.3593],\n        [ 0.8709]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.0767], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([0.8895], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.8925,  2.4565], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-1.4061], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.3450], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: Parameter containing:\n",
       " tensor([[0.2662],\n",
       "         [0.0670],\n",
       "         [0.2475],\n",
       "         [0.0657],\n",
       "         [0.2496]], dtype=torch.float64, requires_grad=True),\n",
       " 2: Parameter containing:\n",
       " tensor([[-0.1673],\n",
       "         [-0.1798],\n",
       "         [ 0.3681],\n",
       "         [ 0.1978]], dtype=torch.float64, requires_grad=True),\n",
       " 1: Parameter containing:\n",
       " tensor([[ 0.9123, -0.0033],\n",
       "         [ 0.9923,  0.9991]], dtype=torch.float64, requires_grad=True),\n",
       " 3: Parameter containing:\n",
       " tensor([[-0.0805],\n",
       "         [-0.2828],\n",
       "         [ 0.7490]], dtype=torch.float64, requires_grad=True),\n",
       " 4: Parameter containing:\n",
       " tensor([[ 0.3443],\n",
       "         [-0.3593],\n",
       "         [ 0.8709]], dtype=torch.float64, requires_grad=True),\n",
       " 0: Parameter containing:\n",
       " tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: Parameter containing:\n",
       " tensor([0.4466, 0.6934], dtype=torch.float64, requires_grad=True),\n",
       " 1: tensor([0.5506, 0.9588], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " 2: tensor([0.7470], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " 3: tensor([0.2383], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " 4: tensor([0.4274], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " 5: tensor([0.5977], dtype=torch.float64, grad_fn=<SigmoidBackward>)}"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "net._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1, 1,2, dtype=torch.float64)\n",
    "label = [xor(val[0][0], val[0][1]) for val in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "def forward(layers, x):\n",
    "    layer_outputs = {}\n",
    "    curr_value = x\n",
    "    for ii in range(len(layers)):\n",
    "        print(ii)\n",
    "        layer = layers[ii]\n",
    "        if layer['is_output_layer']:\n",
    "            # return curr_value\n",
    "            return(layer_outputs)\n",
    "        input_layers = [layer_outputs[layer_id] for layer_id in layer['input_layers']]\n",
    "    return(layer_outputs)\n",
    "        # layer_outputs[ii] = torch.relu(\n",
    "        #     torch.add(\n",
    "        #         torch.matmul(\n",
    "        #             torch.cat(layer['input_layers']),\n",
    "        #             layer['weights']\n",
    "\n",
    "        #         ),\n",
    "        #         layer['bias']\n",
    "        #     )\n",
    "        # )\n",
    "        # curr_value = torch.sigmoid(torch.matmul(curr_value + layers[ii]['bias'], layers[ii]['out_tensor']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward(layers, x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.4006558060646057"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "h.nodes[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The function - Parse NNEAT - has just started at 1615095491.0062232\nThe function - Parse NNEAT - took 0.0011887550354003906 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "with MethodTimer('Parse NNEAT'):\n",
    "    myNeat = nneat(h, p.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "myConnection = (-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "h.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[-0.1703],\n        [ 0.0000],\n        [ 0.0000],\n        [ 0.0000],\n        [ 0.1490]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.0000],\n        [0.0000],\n        [0.5530],\n        [0.5530]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.9151, 0.0000],\n        [1.0000, 1.0000]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.0701],\n        [0.0000],\n        [1.0000]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.5281],\n        [0.0000],\n        [1.0000]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.4007], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([1.2643], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.8664,  2.4587], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-1.1083], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([0.0338], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in myNeat.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The function - Backprop benchmark (10k inputs) - has just started at 1615095693.196116\nThe function - Backprop benchmark (10k inputs) - took 0.0015311241149902344 seconds to complete\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-18162869a542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# print(expected_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mmyNeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2201\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \"\"\"\n\u001b[0;32m-> 2203\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m         warnings.warn(\"Using a target size ({}) that is different to the input size ({}). \"\n\u001b[1;32m   2205\u001b[0m                       \u001b[0;34m\"This will likely lead to incorrect results due to broadcasting. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "# x_input = torch.randn(1, 1, 2, dtype=torch.float64)\n",
    "with MethodTimer('Backprop benchmark (10k inputs)'):\n",
    "\n",
    "    for k in range(25):\n",
    "        for n in range(400):\n",
    "            x_input = nn.Parameter(torch.tensor([np.random.rand(), np.random.rand()], dtype=torch.float64))\n",
    "\n",
    "\n",
    "            result = myNeat.forward(x_input)\n",
    "            expected_result = torch.tensor([xor(x_input[0], x_input[1])], dtype=torch.float64)\n",
    "            # print(x_input)\n",
    "            # print(expected_result)\n",
    "            # print(result)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(result, expected_result)\n",
    "            myNeat.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for parameter in myNeat.parameters():\n",
    "                    try:\n",
    "                        parameter.data -= learning_rate*parameter.grad.data\n",
    "                    except AttributeError:\n",
    "                        continue\n",
    "                    # weight -= learning_rate * weight.grad\n",
    "                # for  w_id, weight in net.weights.items():\n",
    "                #     try:\n",
    "                #         # print(weight.grad)\n",
    "                #         weight -= learning_rate * weight.grad\n",
    "                #     except TypeError:\n",
    "                #         continue\n",
    "                # for  b_id, bias in net.biases.items():\n",
    "                #     try:\n",
    "                #         bias -= learning_rate * bias.grad\n",
    "                #     except TypeError:\n",
    "                #         continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[ 0.6434],\n        [ 1.2305],\n        [-0.4451],\n        [-0.3518],\n        [-0.3164]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.8560],\n        [-0.8797],\n        [-0.3112],\n        [-1.2250]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.8507, 0.0422],\n        [0.9348, 1.0279]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.3604],\n        [-0.8499],\n        [ 0.4200]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.1479],\n        [-1.3651],\n        [ 0.6890]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-3.3236], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.6114], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-1.0203,  2.5215], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-2.0045], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-1.4060], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in myNeat.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<neat.genome.DefaultGenome at 0x7fa16330a310>"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "myNeat.genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "h.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "myNeat.genome.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: Parameter containing:\n",
       " tensor([[-0.1393],\n",
       "         [ 0.2148],\n",
       "         [ 0.0367],\n",
       "         [-0.0018],\n",
       "         [ 0.1243]], dtype=torch.float64, requires_grad=True),\n",
       " 2: Parameter containing:\n",
       " tensor([[-0.1744],\n",
       "         [-0.1848],\n",
       "         [ 0.3618],\n",
       "         [ 0.1876]], dtype=torch.float64, requires_grad=True),\n",
       " 1: Parameter containing:\n",
       " tensor([[ 0.9029, -0.0036],\n",
       "         [ 0.9850,  0.9993]], dtype=torch.float64, requires_grad=True),\n",
       " 3: Parameter containing:\n",
       " tensor([[-0.0801],\n",
       "         [-0.2856],\n",
       "         [ 0.7472]], dtype=torch.float64, requires_grad=True),\n",
       " 4: Parameter containing:\n",
       " tensor([[ 0.3380],\n",
       "         [-0.3733],\n",
       "         [ 0.8678]], dtype=torch.float64, requires_grad=True),\n",
       " 0: Parameter containing:\n",
       " tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "myNeat.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNeat.update_genome_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "h.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "myNeat.genome.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(-0.1393, dtype=torch.float64, grad_fn=<SelectBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "myNeat.genome.connections[myConnection].new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}