{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import neat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from explaneat.core.backprop import NeatNet\n",
    "from explaneat.core import backprop\n",
    "from explaneat.core.backproppop import BackpropPopulation\n",
    "# from explaneat.visualization import visualize\n",
    "from explaneat.core.experiment import ExperimentReporter\n",
    "from explaneat.core.utility import one_hot_encode\n",
    "from explaneat.core.utility import MethodTimer\n",
    "\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.preprocessing import StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from explaneat.core.neuralneat import NeuralNeat as nneat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED      = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = False\n",
    "device = torch.device(\"cuda:1\" if USE_CUDA else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xor(a, b, threshold = 0.5):\n",
    "    response = False\n",
    "    if a > threshold and b < threshold:\n",
    "        response = True\n",
    "    if a < threshold and b > threshold:\n",
    "        response = True\n",
    "    # return (1.0, 0.0) if response else (0.0, 1.0)\n",
    "    return 1.0 if response else 0.0\n",
    "    \n",
    "\n",
    "def create_n_points(n, size, min=0.0, max=1.0):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append([\n",
    "            random.uniform(min, max) for ii in range(size)\n",
    "        ])\n",
    "\n",
    "    return data\n",
    "\n",
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "def overUnder(val, threshold):\n",
    "    return 1. if val > threshold else 0\n",
    "\n",
    "xor_inputs = create_n_points(400, 2, -1, 1)\n",
    "\n",
    "xor_outputs = [\n",
    "    [xor(tup[0], tup[1], 0)] for tup in xor_inputs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.776253115910579, 0.07502145618841682],\n [-0.39480906954787187, -0.47318482686660457],\n [-0.5272023054798749, -0.6414319078015969],\n [0.9009716760188191, 0.8796810194889557],\n [-0.6352370797099778, 0.3271038136619415]]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.0], [0.0], [0.0], [0.0], [1.0]]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_outputs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config_xor\"\n",
    "base_config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_population(config, xs, ys, saveLocation):\n",
    "\n",
    "    if not os.path.exists(saveLocation):\n",
    "        os.makedirs(saveLocation)\n",
    "        \n",
    "    config.save(os.path.join(saveLocation, 'config.conf'))\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    with MethodTimer(\"Backprop everything\"):\n",
    "        p = BackpropPopulation(config, \n",
    "                                xs, \n",
    "                                ys, \n",
    "                                criterion=nn.BCEWithLogitsLoss())\n",
    "\n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5, filename_prefix=str(saveLocation) + \"checkpoint-\" ))\n",
    "    bpReporter = backprop.BackpropReporter(True)\n",
    "    p.add_reporter(bpReporter)\n",
    "    p.add_reporter(ExperimentReporter(saveLocation))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    \n",
    "    print(genomes)\n",
    "    loss = nn.BCELoss()\n",
    "    loss = loss.to(device)\n",
    "    for genome_id, genome in genomes.items():\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        preds = []\n",
    "        for xi in xor_inputs:\n",
    "            preds.append(net.activate(xi))\n",
    "        genome.fitness = float(1./loss(torch.tensor(preds).to(device), torch.tensor(xor_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function - Backprop everything - has just started at 1628756833.758214\n",
      "The function - Backprop everything - took 0.0009009838104248047 seconds to complete\n",
      "The function - generationStart - has just started at 1628756833.759238\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "The function - generationStart - took 2.6941299438476562e-05 seconds to complete\n",
      "The function - pre_backprop - has just started at 1628756833.759276\n",
      "The function - pre_backprop - took 0.0003159046173095703 seconds to complete\n",
      "The function - backprop - has just started at 1628756833.759821\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: -0.0014143950341582111\n",
      "best improvement: tensor(-0.0017, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.5130, dtype=torch.float64, grad_fn=<SqrtBackward>)\n",
      "The function - backprop - took 0.01700425148010254 seconds to complete\n",
      "The function - post_backprop - has just started at 1628756833.7768419\n",
      "The function - post_backprop - took 2.002716064453125e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1628756833.776913\n",
      "{1: <neat.genome.DefaultGenome object at 0x7fab60661d30>, 2: <neat.genome.DefaultGenome object at 0x7fab60661700>, 3: <neat.genome.DefaultGenome object at 0x7fab60661880>, 4: <neat.genome.DefaultGenome object at 0x7fab60661520>, 5: <neat.genome.DefaultGenome object at 0x7fab606612b0>}\n",
      "The function - evaluate fitness - took 0.00608515739440918 seconds to complete\n",
      "The function - post evaluate - has just started at 1628756833.7830431\n",
      "Population's average fitness: 0.55079 stdev: 0.17063\n",
      "Best fitness: 0.88914 - size: (1, 2) - species 1 - id 3\n",
      "Key: 3\n",
      "Fitness: 0.889144241809845\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.11020253581121116, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=-0.6755259194282447, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.16169322738916528, enabled=True)\n",
      "The function - post evaluate - took 0.0001437664031982422 seconds to complete\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1110b5e9ac90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstantiate_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxor_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxor_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Run for up to nGenerations generations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_genomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxNGenerations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_genome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev-mtm/phd-neat-experiments/explaneat/core/backproppop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fitness_function, n, nEpochs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mMethodTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreporters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;31m# Track the best genome ever seen.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/neat_python-0.92-py3.8.egg/neat/reporting.py\u001b[0m in \u001b[0;36mpost_evaluate\u001b[0;34m(self, config, population, species, best_genome)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_genome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreporters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_genome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_reproduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/neat_python-0.92-py3.8.egg/neat/statistics.py\u001b[0m in \u001b[0;36mpost_evaluate\u001b[0;34m(self, config, population, species, best_genome)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_genome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_fit_genomes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_genome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Store the fitnesses of the members of each currently active species.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             raise RuntimeError(\"Only Tensors created explicitly by the user \"\n\u001b[0m\u001b[1;32m     45\u001b[0m                                \"(graph leaves) support the deepcopy protocol at the moment\")\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"
     ]
    }
   ],
   "source": [
    "config = base_config\n",
    "saveLocation = './'\n",
    "maxNGenerations = 3\n",
    "p = instantiate_population(config, xor_inputs, xor_outputs, saveLocation)\n",
    "# Run for up to nGenerations generations.\n",
    "winner = p.run(eval_genomes, maxNGenerations, nEpochs = 5)\n",
    "\n",
    "g = p.best_genome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 7\n",
      "Fitness: 1.0096288919448853\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.32540032267570496, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.1447131335735321, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = deepcopy(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 7\n",
      "Fitness: 1.0096288919448853\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.32540032267570496, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.1447131335735321, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 7\n",
      "Fitness: 1.0096288919448853\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.32540032267570496, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t2 DefaultNodeGene(key=2, bias=-0.9946926512595049, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t3 DefaultNodeGene(key=3, bias=1.3604229232680916, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t4 DefaultNodeGene(key=4, bias=-0.7886409709284502, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t5 DefaultNodeGene(key=5, bias=0.28752704139344826, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.1447131335735321, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 2), weight=1.0, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 3), weight=1.0, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 5), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 2), weight=-0.19788816057211225, enabled=True)\n",
      "\tDefaultConnectionGene(key=(2, 0), weight=0.1447131335735321, enabled=True)\n",
      "\tDefaultConnectionGene(key=(3, 2), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(4, 0), weight=0.1447131335735321, enabled=True)\n",
      "\tDefaultConnectionGene(key=(4, 5), weight=-1.0465833301004204, enabled=True)\n",
      "\tDefaultConnectionGene(key=(5, 3), weight=1.0, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.add_connection(p.config.genome_config, 16, 17, 0.2, True)\n",
    "# h.add_connection(p.config.genome_config, 17, 0, 0.2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 7\n",
      "Fitness: 1.0096288919448853\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.32540032267570496, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t2 DefaultNodeGene(key=2, bias=-0.9946926512595049, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t3 DefaultNodeGene(key=3, bias=1.3604229232680916, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t4 DefaultNodeGene(key=4, bias=-0.7886409709284502, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t5 DefaultNodeGene(key=5, bias=0.28752704139344826, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.1447131335735321, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 2), weight=1.0, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 3), weight=1.0, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 5), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 2), weight=-0.19788816057211225, enabled=True)\n",
      "\tDefaultConnectionGene(key=(2, 0), weight=0.1447131335735321, enabled=True)\n",
      "\tDefaultConnectionGene(key=(3, 2), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(4, 0), weight=0.1447131335735321, enabled=True)\n",
      "\tDefaultConnectionGene(key=(4, 5), weight=-1.0465833301004204, enabled=True)\n",
      "\tDefaultConnectionGene(key=(5, 3), weight=1.0, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[-1, -2]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.config.genome_config.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: <neat.genes.DefaultNodeGene at 0x7faf68fe8790>,\n 2: <neat.genes.DefaultNodeGene at 0x7faf68ff3070>,\n 3: <neat.genes.DefaultNodeGene at 0x7faf68fdfd30>,\n 4: <neat.genes.DefaultNodeGene at 0x7faf68ff31c0>,\n 5: <neat.genes.DefaultNodeGene at 0x7faf68ff32b0>}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_tracker = {node_id:{'depth':0, 'output_ids':[], 'input_ids':[]} for node_id in h.nodes}\n",
    "for node_id in p.config.genome_config.input_keys:\n",
    "    node_tracker[node_id] = {'depth':0, 'output_ids':[], 'input_ids':[]}\n",
    "trace_stack = [node_id for node_id in p.config.genome_config.input_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[-1, -2]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {'depth': 0, 'output_ids': [], 'input_ids': []},\n 2: {'depth': 0, 'output_ids': [], 'input_ids': []},\n 3: {'depth': 0, 'output_ids': [], 'input_ids': []},\n 4: {'depth': 0, 'output_ids': [], 'input_ids': []},\n 5: {'depth': 0, 'output_ids': [], 'input_ids': []},\n -1: {'depth': 0, 'output_ids': [], 'input_ids': []},\n -2: {'depth': 0, 'output_ids': [], 'input_ids': []}}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-2, 0)\n",
      "(-2, 2)\n",
      "(2, 0)\n",
      "(-2, 3)\n",
      "(3, 2)\n",
      "(-2, 4)\n",
      "(4, 0)\n",
      "(-2, 5)\n",
      "(5, 3)\n",
      "(4, 5)\n",
      "(-1, 2)\n"
     ]
    }
   ],
   "source": [
    "for connection in h.connections:\n",
    "    print(connection)\n",
    "    node_tracker[connection[0]]['output_ids'].append(connection[1])\n",
    "    node_tracker[connection[1]]['input_ids'].append(connection[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(trace_stack) > 0:\n",
    "    trace = trace_stack[0]\n",
    "    my_depth = node_tracker[trace]['depth']\n",
    "    next_depth = my_depth + 1\n",
    "    for output_id in node_tracker[trace]['output_ids']:\n",
    "        node_tracker[output_id]['depth'] = max(node_tracker[output_id]['depth'], next_depth)\n",
    "        trace_stack.append(output_id)\n",
    "    del(trace_stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {'depth': 5, 'output_ids': [], 'input_ids': [-2, 2, 4]},\n 2: {'depth': 4, 'output_ids': [0], 'input_ids': [-2, 3, -1]},\n 3: {'depth': 3, 'output_ids': [2], 'input_ids': [-2, 5]},\n 4: {'depth': 1, 'output_ids': [0, 5], 'input_ids': [-2]},\n 5: {'depth': 2, 'output_ids': [3], 'input_ids': [-2, 4]},\n -1: {'depth': 0, 'output_ids': [2], 'input_ids': []},\n -2: {'depth': 0, 'output_ids': [0, 2, 3, 4, 5], 'input_ids': []}}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['output_layers']=[]\n",
    "    node['needs_skip'] = False\n",
    "    node['id'] = node_id\n",
    "    for output_id in node['output_ids']:\n",
    "        node['output_layers'].append(node_tracker[output_id]['depth'])\n",
    "        if node_tracker[output_id]['depth'] > (node['depth']+1):\n",
    "            node['needs_skip'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['input_layers'] = []\n",
    "    node['skip_layer_input'] = False\n",
    "    for input_id in node['input_ids']:\n",
    "        node['input_layers'].append(node_tracker[input_id]['depth'])\n",
    "        if node_tracker[input_id]['depth'] < (node['depth']-1):\n",
    "            node['skip_layer_input'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {'depth': 5,\n  'output_ids': [],\n  'input_ids': [-2, 2, 4],\n  'output_layers': [],\n  'needs_skip': False,\n  'id': 0,\n  'input_layers': [0, 4, 1],\n  'skip_layer_input': True},\n 2: {'depth': 4,\n  'output_ids': [0],\n  'input_ids': [-2, 3, -1],\n  'output_layers': [5],\n  'needs_skip': False,\n  'id': 2,\n  'input_layers': [0, 3, 0],\n  'skip_layer_input': True},\n 3: {'depth': 3,\n  'output_ids': [2],\n  'input_ids': [-2, 5],\n  'output_layers': [4],\n  'needs_skip': False,\n  'id': 3,\n  'input_layers': [0, 2],\n  'skip_layer_input': True},\n 4: {'depth': 1,\n  'output_ids': [0, 5],\n  'input_ids': [-2],\n  'output_layers': [5, 2],\n  'needs_skip': True,\n  'id': 4,\n  'input_layers': [0],\n  'skip_layer_input': False},\n 5: {'depth': 2,\n  'output_ids': [3],\n  'input_ids': [-2, 4],\n  'output_layers': [3],\n  'needs_skip': False,\n  'id': 5,\n  'input_layers': [0, 1],\n  'skip_layer_input': True},\n -1: {'depth': 0,\n  'output_ids': [2],\n  'input_ids': [],\n  'output_layers': [4],\n  'needs_skip': True,\n  'id': -1,\n  'input_layers': [],\n  'skip_layer_input': False},\n -2: {'depth': 0,\n  'output_ids': [0, 2, 3, 4, 5],\n  'input_ids': [],\n  'output_layers': [5, 4, 3, 1, 2],\n  'needs_skip': True,\n  'id': -2,\n  'input_layers': [],\n  'skip_layer_input': False}}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{5: {'nodes': {0: {'depth': 5,\n    'output_ids': [],\n    'input_ids': [-2, 2, 4],\n    'output_layers': [],\n    'needs_skip': False,\n    'id': 0,\n    'input_layers': [0, 4, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}}},\n 4: {'nodes': {2: {'depth': 4,\n    'output_ids': [0],\n    'input_ids': [-2, 3, -1],\n    'output_layers': [5],\n    'needs_skip': False,\n    'id': 2,\n    'input_layers': [0, 3, 0],\n    'skip_layer_input': True,\n    'layer_index': 0}}},\n 3: {'nodes': {3: {'depth': 3,\n    'output_ids': [2],\n    'input_ids': [-2, 5],\n    'output_layers': [4],\n    'needs_skip': False,\n    'id': 3,\n    'input_layers': [0, 2],\n    'skip_layer_input': True,\n    'layer_index': 0}}},\n 1: {'nodes': {4: {'depth': 1,\n    'output_ids': [0, 5],\n    'input_ids': [-2],\n    'output_layers': [5, 2],\n    'needs_skip': True,\n    'id': 4,\n    'input_layers': [0],\n    'skip_layer_input': False,\n    'layer_index': 0}}},\n 2: {'nodes': {5: {'depth': 2,\n    'output_ids': [3],\n    'input_ids': [-2, 4],\n    'output_layers': [3],\n    'needs_skip': False,\n    'id': 5,\n    'input_layers': [0, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}}},\n 0: {'nodes': {-1: {'depth': 0,\n    'output_ids': [2],\n    'input_ids': [],\n    'output_layers': [4],\n    'needs_skip': True,\n    'id': -1,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 0},\n   -2: {'depth': 0,\n    'output_ids': [0, 2, 3, 4, 5],\n    'input_ids': [],\n    'output_layers': [5, 4, 3, 1, 2],\n    'needs_skip': True,\n    'id': -2,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 1}}}}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = {}\n",
    "for node_id, node in node_tracker.items():\n",
    "    if not node['depth'] in layers:\n",
    "        layers[node['depth']] = {\n",
    "            'nodes':{node_id:node}\n",
    "        }\n",
    "    else:\n",
    "        layers[node['depth']]['nodes'][node_id] = node\n",
    "        \n",
    "# Ensure all nodes have a layer index\n",
    "for layer_id, layer in layers.items():\n",
    "    layer_index = 0\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "        \n",
    "        \n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my layer id is 5\n",
      "DefaultConnectionGene(key=(-2, 0), weight=0.1447131335735321, enabled=False)\n",
      "DefaultConnectionGene(key=(4, 0), weight=0.1447131335735321, enabled=True)\n",
      "0.1447131335735321\n",
      "location is\n",
      "(0, 2)\n",
      "DefaultConnectionGene(key=(2, 0), weight=0.1447131335735321, enabled=True)\n",
      "0.1447131335735321\n",
      "location is\n",
      "(0, 3)\n",
      "my layer id is 4\n",
      "DefaultConnectionGene(key=(-1, 2), weight=-0.19788816057211225, enabled=True)\n",
      "-0.19788816057211225\n",
      "location is\n",
      "(0, 0)\n",
      "DefaultConnectionGene(key=(-2, 2), weight=1.0, enabled=False)\n",
      "DefaultConnectionGene(key=(3, 2), weight=1.0, enabled=True)\n",
      "1.0\n",
      "location is\n",
      "(0, 2)\n",
      "my layer id is 3\n",
      "DefaultConnectionGene(key=(-2, 3), weight=1.0, enabled=False)\n",
      "DefaultConnectionGene(key=(5, 3), weight=1.0, enabled=True)\n",
      "1.0\n",
      "location is\n",
      "(0, 2)\n",
      "my layer id is 1\n",
      "DefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n",
      "1.0\n",
      "location is\n",
      "(0, 1)\n",
      "my layer id is 2\n",
      "DefaultConnectionGene(key=(-2, 5), weight=1.0, enabled=True)\n",
      "1.0\n",
      "location is\n",
      "(0, 1)\n",
      "DefaultConnectionGene(key=(4, 5), weight=-1.0465833301004204, enabled=True)\n",
      "-1.0465833301004204\n",
      "location is\n",
      "(0, 2)\n",
      "my layer id is 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LAYER_TYPE_CONNECTED = \"CONNECTED\"\n",
    "LAYER_TYPE_INPUT = \"INPUT\"\n",
    "LAYER_TYPE_OUTPUT = \"OUTPUT\"\n",
    "for layer_id, layer in layers.items():\n",
    "    layer['is_output_layer'] = False\n",
    "    layer['is_input_layer'] = False\n",
    "    layer['layer_type'] = LAYER_TYPE_CONNECTED\n",
    "    # If I have the output node in me, then I am an output\n",
    "    if 0 in layer['nodes']:\n",
    "        layer['is_output_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_OUTPUT\n",
    "\n",
    "    # If I have the first input in me, then I am the input\n",
    "    if -1 in layer['nodes']:\n",
    "        layer['is_input_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_INPUT\n",
    "    biases = []\n",
    "\n",
    "    layer['input_layers'] = []\n",
    "    ## Compute the shape of required inputs\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        for in_layer in node['input_layers']:\n",
    "            if in_layer not in layer['input_layers']:\n",
    "                layer['input_layers'].append(in_layer)\n",
    "    layer['input_layers'].sort()\n",
    "    layer['input_shape'] = sum(len(layers[jj]['nodes']) for jj in layer['input_layers'])\n",
    "    layer['weights_shape'] = (layer['input_shape'], len(layer['nodes']))\n",
    "\n",
    "\n",
    "    # Handle output layer \"edge\" case\n",
    "    if layer['is_output_layer']:\n",
    "        layer['out_weights'] = []\n",
    "        layer['bias'] = [h.nodes[node_id].bias for node_id, node in layer['nodes'].items()]\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle input layer \"edge\" case\n",
    "    elif layer['is_input_layer']:\n",
    "        layer['in_weights'] = []\n",
    "        layer['bias'] = []\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle generic case\n",
    "    else:\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "\n",
    "        layer['bias'] = [h.nodes[node_id].bias for node_id, node in layer['nodes'].items()]\n",
    "        # else:\n",
    "            # layer['bias'] = [0 for _ in layer['nodes']]\n",
    "    \n",
    "    layer_index = 0          \n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "        ### POSSIBLY NEED THIS\n",
    "        # if node['id'] < 0:\n",
    "        #     biases.append(1)\n",
    "        # else:\n",
    "        #     biases.append(h.nodes[node['id']].bias)\n",
    "        # for output_id in node['output_ids']:\n",
    "        #     if (node['id'], output_id) in h.connections:\n",
    "        #         if output_id in layers[layer_id + 1]['nodes']:\n",
    "        #             layer['out_weights'][node['layer_index']][layers[layer_id + 1]['nodes'][output_id]['layer_index']] = h.connections[(node['id'], output_id)].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        # for input_id in node['input_ids']:\n",
    "        #     if (input_id, node['id']) in h.connections:\n",
    "        #         if input_id in layers[layer_id - 1]['nodes']:\n",
    "        #             layer['in_weights'][node['layer_index']][layers[layer_id -1]['nodes'][input_id]['layer_index']] = h.connections[(input_id, node['id'])].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        #################################################\n",
    "            ### END OF POSSIBLY NEEDING THIS\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "\n",
    "\n",
    "    # layer['out_tensor'] = torch.tensor(layer['out_weights'])\n",
    "    # layer['bias'] = torch.tensor(layer['bias'])\n",
    "    # layer['out_tensor_shape'] = layer['out_tensor'].shape\n",
    "    # layer['in_tensor'] = torch.tensor(layer['in_weights'])\n",
    "    # layer['in_tensor_shape'] = layer['in_tensor'].shape\n",
    "\n",
    "\n",
    "\n",
    "    # Set up current weights\n",
    "    layer['input_weights'] = np.zeros(layer['weights_shape'])\n",
    "    layer_offset = 0\n",
    "    # Check every layer and every node for connections\n",
    "    print(\"my layer id is %s\" % (layer_id))\n",
    "    for input_layer_id in layer['input_layers']:\n",
    "        input_layer = layers[input_layer_id]\n",
    "        for node_id, node in input_layer['nodes'].items():\n",
    "            for node_output_id in node['output_ids']:\n",
    "                if node_output_id in layer['nodes']:\n",
    "                    node_output = layer['nodes'][node_output_id]\n",
    "                    # I HAVE THIS NODE!\n",
    "                    # What is it's weight?\n",
    "                    connection = h.connections[(node_id, node_output_id)]\n",
    "                    print(connection)\n",
    "\n",
    "                    if not connection.enabled:\n",
    "                        continue\n",
    "                    connection_weight = connection.weight\n",
    "                    print(connection_weight)\n",
    "\n",
    "                    in_weight_location = layer_offset + node['layer_index']\n",
    "                    out_weight_location = node_output['layer_index']\n",
    "                    print('location is')\n",
    "                    print((out_weight_location, in_weight_location))\n",
    "                    layer['input_weights'][in_weight_location][out_weight_location] = connection_weight\n",
    "        layer_offset += len(input_layer['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{5: {'nodes': {0: {'depth': 5,\n    'output_ids': [],\n    'input_ids': [-2, 2, 4],\n    'output_layers': [],\n    'needs_skip': False,\n    'id': 0,\n    'input_layers': [0, 4, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': True,\n  'is_input_layer': False,\n  'layer_type': 'OUTPUT',\n  'input_layers': [0, 1, 4],\n  'input_shape': 4,\n  'weights_shape': (4, 1),\n  'out_weights': [],\n  'bias': [-0.32540032267570496],\n  'in_weights': [[0]],\n  'input_weights': array([[0.        ],\n         [0.        ],\n         [0.14471313],\n         [0.14471313]])},\n 4: {'nodes': {2: {'depth': 4,\n    'output_ids': [0],\n    'input_ids': [-2, 3, -1],\n    'output_layers': [5],\n    'needs_skip': False,\n    'id': 2,\n    'input_layers': [0, 3, 0],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 3],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [-0.9946926512595049],\n  'input_weights': array([[-0.19788816],\n         [ 0.        ],\n         [ 1.        ]])},\n 3: {'nodes': {3: {'depth': 3,\n    'output_ids': [2],\n    'input_ids': [-2, 5],\n    'output_layers': [4],\n    'needs_skip': False,\n    'id': 3,\n    'input_layers': [0, 2],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 2],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [1.3604229232680916],\n  'input_weights': array([[0.],\n         [0.],\n         [1.]])},\n 1: {'nodes': {4: {'depth': 1,\n    'output_ids': [0, 5],\n    'input_ids': [-2],\n    'output_layers': [5, 2],\n    'needs_skip': True,\n    'id': 4,\n    'input_layers': [0],\n    'skip_layer_input': False,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0],\n  'input_shape': 2,\n  'weights_shape': (2, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0, 0]],\n  'bias': [-0.7886409709284502],\n  'input_weights': array([[0.],\n         [1.]])},\n 2: {'nodes': {5: {'depth': 2,\n    'output_ids': [3],\n    'input_ids': [-2, 4],\n    'output_layers': [3],\n    'needs_skip': False,\n    'id': 5,\n    'input_layers': [0, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 1],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [0.28752704139344826],\n  'input_weights': array([[ 0.        ],\n         [ 1.        ],\n         [-1.04658333]])},\n 0: {'nodes': {-1: {'depth': 0,\n    'output_ids': [2],\n    'input_ids': [],\n    'output_layers': [4],\n    'needs_skip': True,\n    'id': -1,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 0},\n   -2: {'depth': 0,\n    'output_ids': [0, 2, 3, 4, 5],\n    'input_ids': [],\n    'output_layers': [5, 4, 3, 1, 2],\n    'needs_skip': True,\n    'id': -2,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 1}},\n  'is_output_layer': False,\n  'is_input_layer': True,\n  'layer_type': 'INPUT',\n  'input_layers': [],\n  'input_shape': 0,\n  'weights_shape': (0, 2),\n  'in_weights': [],\n  'bias': [],\n  'out_weights': [[0], [0]],\n  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in computation of skip layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'nodes': {5: {'depth': 2,\n   'output_ids': [3],\n   'input_ids': [-2, 4],\n   'output_layers': [3],\n   'needs_skip': False,\n   'id': 5,\n   'input_layers': [0, 1],\n   'skip_layer_input': True,\n   'layer_index': 0}},\n 'is_output_layer': False,\n 'is_input_layer': False,\n 'layer_type': 'CONNECTED',\n 'input_layers': [0, 1],\n 'input_shape': 3,\n 'weights_shape': (3, 1),\n 'out_weights': [[0]],\n 'in_weights': [[0]],\n 'bias': [0.28752704139344826],\n 'input_weights': array([[ 0.        ],\n        [ 1.        ],\n        [-1.04658333]])}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{5: {'nodes': {0: {'depth': 5,\n    'output_ids': [],\n    'input_ids': [-2, 2, 4],\n    'output_layers': [],\n    'needs_skip': False,\n    'id': 0,\n    'input_layers': [0, 4, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': True,\n  'is_input_layer': False,\n  'layer_type': 'OUTPUT',\n  'input_layers': [0, 1, 4],\n  'input_shape': 4,\n  'weights_shape': (4, 1),\n  'out_weights': [],\n  'bias': [-0.32540032267570496],\n  'in_weights': [[0]],\n  'input_weights': array([[0.        ],\n         [0.        ],\n         [0.14471313],\n         [0.14471313]])},\n 4: {'nodes': {2: {'depth': 4,\n    'output_ids': [0],\n    'input_ids': [-2, 3, -1],\n    'output_layers': [5],\n    'needs_skip': False,\n    'id': 2,\n    'input_layers': [0, 3, 0],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 3],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [-0.9946926512595049],\n  'input_weights': array([[-0.19788816],\n         [ 0.        ],\n         [ 1.        ]])},\n 3: {'nodes': {3: {'depth': 3,\n    'output_ids': [2],\n    'input_ids': [-2, 5],\n    'output_layers': [4],\n    'needs_skip': False,\n    'id': 3,\n    'input_layers': [0, 2],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 2],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [1.3604229232680916],\n  'input_weights': array([[0.],\n         [0.],\n         [1.]])},\n 1: {'nodes': {4: {'depth': 1,\n    'output_ids': [0, 5],\n    'input_ids': [-2],\n    'output_layers': [5, 2],\n    'needs_skip': True,\n    'id': 4,\n    'input_layers': [0],\n    'skip_layer_input': False,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0],\n  'input_shape': 2,\n  'weights_shape': (2, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0, 0]],\n  'bias': [-0.7886409709284502],\n  'input_weights': array([[0.],\n         [1.]])},\n 2: {'nodes': {5: {'depth': 2,\n    'output_ids': [3],\n    'input_ids': [-2, 4],\n    'output_layers': [3],\n    'needs_skip': False,\n    'id': 5,\n    'input_layers': [0, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 1],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [0.28752704139344826],\n  'input_weights': array([[ 0.        ],\n         [ 1.        ],\n         [-1.04658333]])},\n 0: {'nodes': {-1: {'depth': 0,\n    'output_ids': [2],\n    'input_ids': [],\n    'output_layers': [4],\n    'needs_skip': True,\n    'id': -1,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 0},\n   -2: {'depth': 0,\n    'output_ids': [0, 2, 3, 4, 5],\n    'input_ids': [],\n    'output_layers': [5, 4, 3, 1, 2],\n    'needs_skip': True,\n    'id': -2,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 1}},\n  'is_output_layer': False,\n  'is_input_layer': True,\n  'layer_type': 'INPUT',\n  'input_layers': [],\n  'input_shape': 0,\n  'weights_shape': (0, 2),\n  'in_weights': [],\n  'bias': [],\n  'out_weights': [[0], [0]],\n  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is, how do you code the operations to dynamically create the\n",
    "NN? You need to be able to do the right things in the right order. You have\n",
    "a list of possible operations:\n",
    "* Matrix multiple\n",
    "* Concatenate (for skip layers)\n",
    "* Matrix addition (for biases)\n",
    "* Output\n",
    "\n",
    "The order of operations in each layer is:\n",
    "\n",
    "1. Concatenate input tensors\n",
    "2. Matrix multiply input tensors with weights\n",
    "3. Add bias tensors\n",
    "4. Apply activation function\n",
    "\n",
    "I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "These computations can be computed back-to-front, and then executed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': {-1: {'depth': 0, 'output_ids': [2], 'input_ids': [], 'output_layers': [4], 'needs_skip': True, 'id': -1, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 0}, -2: {'depth': 0, 'output_ids': [0, 2, 3, 4, 5], 'input_ids': [], 'output_layers': [5, 4, 3, 1, 2], 'needs_skip': True, 'id': -2, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 1}}, 'is_output_layer': False, 'is_input_layer': True, 'layer_type': 'INPUT', 'input_layers': [], 'input_shape': 0, 'weights_shape': (0, 2), 'in_weights': [], 'bias': [], 'out_weights': [[0], [0]], 'input_weights': array([], shape=(0, 2), dtype=float64)}\n",
      "{'nodes': {4: {'depth': 1, 'output_ids': [0, 5], 'input_ids': [-2], 'output_layers': [5, 2], 'needs_skip': True, 'id': 4, 'input_layers': [0], 'skip_layer_input': False, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0], 'input_shape': 2, 'weights_shape': (2, 1), 'out_weights': [[0]], 'in_weights': [[0, 0]], 'bias': [-0.7886409709284502], 'input_weights': array([[0.],\n",
      "       [1.]])}\n",
      "{'nodes': {5: {'depth': 2, 'output_ids': [3], 'input_ids': [-2, 4], 'output_layers': [3], 'needs_skip': False, 'id': 5, 'input_layers': [0, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0, 1], 'input_shape': 3, 'weights_shape': (3, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [0.28752704139344826], 'input_weights': array([[ 0.        ],\n",
      "       [ 1.        ],\n",
      "       [-1.04658333]])}\n",
      "{'nodes': {3: {'depth': 3, 'output_ids': [2], 'input_ids': [-2, 5], 'output_layers': [4], 'needs_skip': False, 'id': 3, 'input_layers': [0, 2], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0, 2], 'input_shape': 3, 'weights_shape': (3, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [1.3604229232680916], 'input_weights': array([[0.],\n",
      "       [0.],\n",
      "       [1.]])}\n",
      "{'nodes': {2: {'depth': 4, 'output_ids': [0], 'input_ids': [-2, 3, -1], 'output_layers': [5], 'needs_skip': False, 'id': 2, 'input_layers': [0, 3, 0], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0, 3], 'input_shape': 3, 'weights_shape': (3, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [-0.9946926512595049], 'input_weights': array([[-0.19788816],\n",
      "       [ 0.        ],\n",
      "       [ 1.        ]])}\n",
      "{'nodes': {0: {'depth': 5, 'output_ids': [], 'input_ids': [-2, 2, 4], 'output_layers': [], 'needs_skip': False, 'id': 0, 'input_layers': [0, 4, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': True, 'is_input_layer': False, 'layer_type': 'OUTPUT', 'input_layers': [0, 1, 4], 'input_shape': 4, 'weights_shape': (4, 1), 'out_weights': [], 'bias': [-0.32540032267570496], 'in_weights': [[0]], 'input_weights': array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.14471313],\n",
      "       [0.14471313]])}\n"
     ]
    }
   ],
   "source": [
    "ACTIVATE_OPERATION = \"ACTIVATE\"\n",
    "OUTPUT_OPERATION = \"OUTPUT\"\n",
    "TENADD_OPERATION = \"TENADD\" # Tensor ADD\n",
    "ADD_BIAS_OPERATION = \"BIASADD\"\n",
    "TENMUL_OPERATION = \"TENMUL\"\n",
    "TENCAT_OPERATION = \"TENCAT\"\n",
    "order_of_operations = []\n",
    "\n",
    "# for layer_id, layer in layers.items():\n",
    "#     print(layer)\n",
    "#     # Output for final layer\n",
    "#     if layer['is_output_layer']:\n",
    "#         order_of_operations.append(OUTPUT_OPERATION)\n",
    "#     # Activate\n",
    "#     order_of_operations.append(ACTIVATE_OPERATION)\n",
    "#     # Add Bias\n",
    "#     order_of_operations.append(ADD_BIAS_OPERATION)\n",
    "#     # Matrix Multiply weights\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     print(order_of_operations)\n",
    "\n",
    "#     break\n",
    "\n",
    "for layer_id in range(len(layers)):\n",
    "    layer = layers[layer_id]\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(3, 1)\n",
    "c = torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0890],\n        [ 1.7597]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{5: {'nodes': {0: {'depth': 5,\n    'output_ids': [],\n    'input_ids': [-2, 2, 4],\n    'output_layers': [],\n    'needs_skip': False,\n    'id': 0,\n    'input_layers': [0, 4, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': True,\n  'is_input_layer': False,\n  'layer_type': 'OUTPUT',\n  'input_layers': [0, 1, 4],\n  'input_shape': 4,\n  'weights_shape': (4, 1),\n  'out_weights': [],\n  'bias': [-0.32540032267570496],\n  'in_weights': [[0]],\n  'input_weights': array([[0.        ],\n         [0.        ],\n         [0.14471313],\n         [0.14471313]])},\n 4: {'nodes': {2: {'depth': 4,\n    'output_ids': [0],\n    'input_ids': [-2, 3, -1],\n    'output_layers': [5],\n    'needs_skip': False,\n    'id': 2,\n    'input_layers': [0, 3, 0],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 3],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [-0.9946926512595049],\n  'input_weights': array([[-0.19788816],\n         [ 0.        ],\n         [ 1.        ]])},\n 3: {'nodes': {3: {'depth': 3,\n    'output_ids': [2],\n    'input_ids': [-2, 5],\n    'output_layers': [4],\n    'needs_skip': False,\n    'id': 3,\n    'input_layers': [0, 2],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 2],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [1.3604229232680916],\n  'input_weights': array([[0.],\n         [0.],\n         [1.]])},\n 1: {'nodes': {4: {'depth': 1,\n    'output_ids': [0, 5],\n    'input_ids': [-2],\n    'output_layers': [5, 2],\n    'needs_skip': True,\n    'id': 4,\n    'input_layers': [0],\n    'skip_layer_input': False,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0],\n  'input_shape': 2,\n  'weights_shape': (2, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0, 0]],\n  'bias': [-0.7886409709284502],\n  'input_weights': array([[0.],\n         [1.]])},\n 2: {'nodes': {5: {'depth': 2,\n    'output_ids': [3],\n    'input_ids': [-2, 4],\n    'output_layers': [3],\n    'needs_skip': False,\n    'id': 5,\n    'input_layers': [0, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 1],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [0.28752704139344826],\n  'input_weights': array([[ 0.        ],\n         [ 1.        ],\n         [-1.04658333]])},\n 0: {'nodes': {-1: {'depth': 0,\n    'output_ids': [2],\n    'input_ids': [],\n    'output_layers': [4],\n    'needs_skip': True,\n    'id': -1,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 0},\n   -2: {'depth': 0,\n    'output_ids': [0, 2, 3, 4, 5],\n    'input_ids': [],\n    'output_layers': [5, 4, 3, 1, 2],\n    'needs_skip': True,\n    'id': -2,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 1}},\n  'is_output_layer': False,\n  'is_input_layer': True,\n  'layer_type': 'INPUT',\n  'input_layers': [],\n  'input_shape': 0,\n  'weights_shape': (0, 2),\n  'in_weights': [],\n  'bias': [],\n  'out_weights': [[0], [0]],\n  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = nn.Parameter(torch.tensor([0.3, 0.4], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Net, self).__init__()  # just run the init of parent class (nn.Module)\n",
    "        self.weights = {layer_id: self._tt(layer['input_weights'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.biases = {layer_id: self._tt(layer['bias'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.layer_types = {layer_id: layer['layer_type'] for layer_id, layer in layers.items()}\n",
    "        self.layer_inputs = {layer_id: layer['input_layers'] for layer_id, layer in layers.items()}\n",
    "        self.n_layers = len(layers)\n",
    "\n",
    "        self._outputs = None\n",
    "\n",
    "        for w_id, w in self.weights.items():\n",
    "            self.register_parameter(name =\"weight_%s\"%w_id, param=w)\n",
    "\n",
    "        for b_id, b in self.biases.items():\n",
    "            self.register_parameter(name = \"bias_%s\"%b_id, param=b)\n",
    "\n",
    "        # x = F.relu(self.fc1(x))\n",
    "\n",
    "        # self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tt(mat):\n",
    "        return torch.nn.Parameter(torch.tensor(mat,dtype=torch.float64), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        # print(\"running forward\")\n",
    "        self._outputs = {}\n",
    "        for layer_id in range(self.n_layers):\n",
    "            layer_input = None\n",
    "            layer_type = self.layer_types[layer_id]\n",
    "\n",
    "            # print(layer_id)\n",
    "            # print(layer_type)\n",
    "\n",
    "            if layer_type == LAYER_TYPE_INPUT:\n",
    "                self._outputs[layer_id] = x\n",
    "                continue\n",
    "            if layer_type == LAYER_TYPE_CONNECTED:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "\n",
    "            # print(layer_input)\n",
    "            # print(self.weights[layer_id])\n",
    "            # print(self.biases[layer_id])\n",
    "\n",
    "            self._outputs[layer_id] = torch.sigmoid( torch.matmul(layer_input, self.weights[layer_id]) + self.biases[layer_id] )\n",
    "\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                return self._outputs[layer_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{5: Parameter containing:\n tensor([-0.3254], dtype=torch.float64, requires_grad=True),\n 4: Parameter containing:\n tensor([-0.9947], dtype=torch.float64, requires_grad=True),\n 3: Parameter containing:\n tensor([1.3604], dtype=torch.float64, requires_grad=True),\n 1: Parameter containing:\n tensor([-0.7886], dtype=torch.float64, requires_grad=True),\n 2: Parameter containing:\n tensor([0.2875], dtype=torch.float64, requires_grad=True),\n 0: Parameter containing:\n tensor([], dtype=torch.float64, requires_grad=True)}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "net._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.4499], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = net.forward(x_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_result = torch.tensor(xor(x_input[0], x_input[1]))\n",
    "expected_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function - benchmark - has just started at 1628331614.001492\n",
      "The function - benchmark - took 5.811469078063965 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "# x_input = torch.randn(1, 1, 2, dtype=torch.float64)\n",
    "with MethodTimer('benchmark'):\n",
    "\n",
    "    for k in range(25):\n",
    "        for n in range(400):\n",
    "            x_input = nn.Parameter(torch.tensor([np.random.rand(), np.random.rand()], dtype=torch.float64))\n",
    "\n",
    "\n",
    "            result = net.forward(x_input)\n",
    "            expected_result = torch.tensor(xor(x_input[0], x_input[1]), dtype=torch.float64)\n",
    "            # print(x_input)\n",
    "            # print(expected_result)\n",
    "            # print(result)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(result, expected_result)\n",
    "            net.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                # for parameter in net.parameters():\n",
    "                    # parameter.data -= learning_rate*parameter.grad.data\n",
    "                    # weight -= learning_rate * weight.grad\n",
    "                for  w_id, weight in net.weights.items():\n",
    "                    try:\n",
    "                        weight -= learning_rate * weight.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "                for  b_id, bias in net.biases.items():\n",
    "                    try:\n",
    "                        bias -= learning_rate * bias.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(torch.tensor(xor_inputs, dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0192], dtype=torch.float64)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.biases[1].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.5588], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "output = net(x_input)\n",
    "loss = loss_fn(result, expected_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0763],\n",
      "        [-0.0542],\n",
      "        [ 0.3221],\n",
      "        [ 0.2249]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3051],\n",
      "        [-0.1099],\n",
      "        [ 0.7828]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0032],\n",
      "        [-0.0108],\n",
      "        [ 0.9855]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3092],\n",
      "        [ 0.8493]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0013],\n",
      "        [ 0.9976],\n",
      "        [-1.0488]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0632], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.2436], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.3353], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.0654], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2816], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "myW = net.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.3092],\n        [ 0.8493]], dtype=torch.float64, requires_grad=True)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3123, dtype=torch.float64, grad_fn=<MseLossBackward>)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0763],\n",
      "        [-0.0542],\n",
      "        [ 0.3221],\n",
      "        [ 0.2249]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3051],\n",
      "        [-0.1099],\n",
      "        [ 0.7828]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0032],\n",
      "        [-0.0108],\n",
      "        [ 0.9855]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3092],\n",
      "        [ 0.8493]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0013],\n",
      "        [ 0.9976],\n",
      "        [-1.0488]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0632], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.2436], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.3353], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.0654], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2816], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{5: Parameter containing:\n tensor([[-0.0763],\n         [-0.0542],\n         [ 0.3221],\n         [ 0.2249]], dtype=torch.float64, requires_grad=True),\n 4: Parameter containing:\n tensor([[-0.3051],\n         [-0.1099],\n         [ 0.7828]], dtype=torch.float64, requires_grad=True),\n 3: Parameter containing:\n tensor([[-0.0032],\n         [-0.0108],\n         [ 0.9855]], dtype=torch.float64, requires_grad=True),\n 1: Parameter containing:\n tensor([[-0.3092],\n         [ 0.8493]], dtype=torch.float64, requires_grad=True),\n 2: Parameter containing:\n tensor([[ 0.0013],\n         [ 0.9976],\n         [-1.0488]], dtype=torch.float64, requires_grad=True),\n 0: Parameter containing:\n tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)}"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: Parameter containing:\n tensor([0.2507, 0.3610], dtype=torch.float64, requires_grad=True),\n 1: tensor([0.3023], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n 2: tensor([0.5806], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n 3: tensor([0.8702], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n 4: tensor([0.3366], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n 5: tensor([0.5492], dtype=torch.float64, grad_fn=<SigmoidBackward>)}"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1, 1,2, dtype=torch.float64)\n",
    "label = [xor(val[0][0], val[0][1]) for val in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "def forward(layers, x):\n",
    "    layer_outputs = {}\n",
    "    curr_value = x\n",
    "    for ii in range(len(layers)):\n",
    "        print(ii)\n",
    "        layer = layers[ii]\n",
    "        if layer['is_output_layer']:\n",
    "            # return curr_value\n",
    "            return(layer_outputs)\n",
    "        input_layers = [layer_outputs[layer_id] for layer_id in layer['input_layers']]\n",
    "    return(layer_outputs)\n",
    "        # layer_outputs[ii] = torch.relu(\n",
    "        #     torch.add(\n",
    "        #         torch.matmul(\n",
    "        #             torch.cat(layer['input_layers']),\n",
    "        #             layer['weights']\n",
    "\n",
    "        #         ),\n",
    "        #         layer['bias']\n",
    "        #     )\n",
    "        # )\n",
    "        # curr_value = torch.sigmoid(torch.matmul(curr_value + layers[ii]['bias'], layers[ii]['out_tensor']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward(layers, x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-0.32540032267570496"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.nodes[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function - Parse NNEAT - has just started at 1628331620.060509\n",
      "The function - Parse NNEAT - took 0.0007951259613037109 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "with MethodTimer('Parse NNEAT'):\n",
    "    myNeat = nneat(h, p.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "myConnection = (-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(-1, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-d9dcbbed06f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmyConnection\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: (-1, 0)"
     ]
    }
   ],
   "source": [
    "h.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1703],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.1490]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.5530],\n",
      "        [0.5530]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.9151, 0.0000],\n",
      "        [1.0000, 1.0000]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0701],\n",
      "        [0.0000],\n",
      "        [1.0000]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.5281],\n",
      "        [0.0000],\n",
      "        [1.0000]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4007], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.2643], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.8664,  2.4587], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.1083], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0338], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in myNeat.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function - Backprop benchmark (10k inputs) - has just started at 1615095693.196116\n",
      "The function - Backprop benchmark (10k inputs) - took 0.0015311241149902344 seconds to complete\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-18162869a542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# print(expected_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mmyNeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2201\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \"\"\"\n\u001b[0;32m-> 2203\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m         warnings.warn(\"Using a target size ({}) that is different to the input size ({}). \"\n\u001b[1;32m   2205\u001b[0m                       \u001b[0;34m\"This will likely lead to incorrect results due to broadcasting. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "# x_input = torch.randn(1, 1, 2, dtype=torch.float64)\n",
    "with MethodTimer('Backprop benchmark (10k inputs)'):\n",
    "\n",
    "    for k in range(25):\n",
    "        for n in range(400):\n",
    "            x_input = nn.Parameter(torch.tensor([np.random.rand(), np.random.rand()], dtype=torch.float64))\n",
    "\n",
    "\n",
    "            result = myNeat.forward(x_input)\n",
    "            expected_result = torch.tensor([xor(x_input[0], x_input[1])], dtype=torch.float64)\n",
    "            # print(x_input)\n",
    "            # print(expected_result)\n",
    "            # print(result)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(result, expected_result)\n",
    "            myNeat.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for parameter in myNeat.parameters():\n",
    "                    try:\n",
    "                        parameter.data -= learning_rate*parameter.grad.data\n",
    "                    except AttributeError:\n",
    "                        continue\n",
    "                    # weight -= learning_rate * weight.grad\n",
    "                # for  w_id, weight in net.weights.items():\n",
    "                #     try:\n",
    "                #         # print(weight.grad)\n",
    "                #         weight -= learning_rate * weight.grad\n",
    "                #     except TypeError:\n",
    "                #         continue\n",
    "                # for  b_id, bias in net.biases.items():\n",
    "                #     try:\n",
    "                #         bias -= learning_rate * bias.grad\n",
    "                #     except TypeError:\n",
    "                #         continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.6434],\n",
      "        [ 1.2305],\n",
      "        [-0.4451],\n",
      "        [-0.3518],\n",
      "        [-0.3164]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.8560],\n",
      "        [-0.8797],\n",
      "        [-0.3112],\n",
      "        [-1.2250]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.8507, 0.0422],\n",
      "        [0.9348, 1.0279]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3604],\n",
      "        [-0.8499],\n",
      "        [ 0.4200]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1479],\n",
      "        [-1.3651],\n",
      "        [ 0.6890]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-3.3236], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.6114], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.0203,  2.5215], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-2.0045], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.4060], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in myNeat.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<neat.genome.DefaultGenome at 0x7fa16330a310>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.genome.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: Parameter containing:\n",
       " tensor([[-0.1393],\n",
       "         [ 0.2148],\n",
       "         [ 0.0367],\n",
       "         [-0.0018],\n",
       "         [ 0.1243]], dtype=torch.float64, requires_grad=True),\n",
       " 2: Parameter containing:\n",
       " tensor([[-0.1744],\n",
       "         [-0.1848],\n",
       "         [ 0.3618],\n",
       "         [ 0.1876]], dtype=torch.float64, requires_grad=True),\n",
       " 1: Parameter containing:\n",
       " tensor([[ 0.9029, -0.0036],\n",
       "         [ 0.9850,  0.9993]], dtype=torch.float64, requires_grad=True),\n",
       " 3: Parameter containing:\n",
       " tensor([[-0.0801],\n",
       "         [-0.2856],\n",
       "         [ 0.7472]], dtype=torch.float64, requires_grad=True),\n",
       " 4: Parameter containing:\n",
       " tensor([[ 0.3380],\n",
       "         [-0.3733],\n",
       "         [ 0.8678]], dtype=torch.float64, requires_grad=True),\n",
       " 0: Parameter containing:\n",
       " tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNeat.update_genome_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.genome.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1393, dtype=torch.float64, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.genome.connections[myConnection].new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}