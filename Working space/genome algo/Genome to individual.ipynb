{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import neat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from explaneat.core.backprop import NeatNet\n",
    "from explaneat.core import backprop\n",
    "from explaneat.core.backproppop import BackpropPopulation\n",
    "# from explaneat.visualization import visualize\n",
    "from explaneat.core.experiment import ExperimentReporter\n",
    "from explaneat.core.utility import one_hot_encode\n",
    "from explaneat.core.utility import MethodTimer\n",
    "\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.preprocessing import StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from explaneat.core.neuralneat import NeuralNeat as nneat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED      = 42\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = False\n",
    "device = torch.device(\"cuda:1\" if USE_CUDA else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xor(a, b, threshold = 0.5):\n",
    "    response = False\n",
    "    if a > threshold and b < threshold:\n",
    "        response = True\n",
    "    if a < threshold and b > threshold:\n",
    "        response = True\n",
    "    # return (1.0, 0.0) if response else (0.0, 1.0)\n",
    "    return 1.0 if response else 0.0\n",
    "    \n",
    "\n",
    "def create_n_points(n, size, min=0.0, max=1.0):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append([\n",
    "            random.uniform(min, max) for ii in range(size)\n",
    "        ])\n",
    "\n",
    "    return data\n",
    "\n",
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "def overUnder(val, threshold):\n",
    "    return 1. if val > threshold else 0\n",
    "\n",
    "xor_inputs = create_n_points(400, 2, -1, 1)\n",
    "\n",
    "xor_outputs = [\n",
    "    [xor(tup[0], tup[1], 0)] for tup in xor_inputs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.06714656611616276, 0.7196194468545101],\n",
       " [0.6420591938524554, 0.001618230387546049],\n",
       " [-0.9106449283183302, -0.07904534474516067],\n",
       " [-0.04362753357092264, 0.6757549534710519],\n",
       " [-0.5180374692730203, -0.936631470897298]]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "xor_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.0], [0.0], [0.0], [1.0], [0.0]]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "xor_outputs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config_xor\"\n",
    "base_config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_population(config, xs, ys, saveLocation):\n",
    "\n",
    "    if not os.path.exists(saveLocation):\n",
    "        os.makedirs(saveLocation)\n",
    "        \n",
    "    config.save(os.path.join(saveLocation, 'config.conf'))\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    with MethodTimer(\"Backprop everything\"):\n",
    "        p = BackpropPopulation(config, \n",
    "                                xs, \n",
    "                                ys, \n",
    "                                criterion=nn.BCEWithLogitsLoss())\n",
    "\n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5, filename_prefix=str(saveLocation) + \"checkpoint-\" ))\n",
    "    bpReporter = backprop.BackpropReporter(True)\n",
    "    p.add_reporter(bpReporter)\n",
    "    p.add_reporter(ExperimentReporter(saveLocation))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    \n",
    "    print(genomes)\n",
    "    loss = nn.BCELoss()\n",
    "    loss = loss.to(device)\n",
    "    for genome_id, genome in genomes.items():\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        preds = []\n",
    "        for xi in xor_inputs:\n",
    "            preds.append(net.activate(xi))\n",
    "        genome.fitness = float(1./loss(torch.tensor(preds).to(device), torch.tensor(xor_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The function - Backprop everything - has just started at 1615092808.2442229\n",
      "The function - Backprop everything - took 0.0019390583038330078 seconds to complete\n",
      "The function - generationStart - has just started at 1615092808.246356\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "The function - generationStart - took 2.9802322387695312e-05 seconds to complete\n",
      "The function - pre_backprop - has just started at 1615092808.246401\n",
      "The function - pre_backprop - took 3.409385681152344e-05 seconds to complete\n",
      "The function - backprop - has just started at 1615092808.246444\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: 0.0\n",
      "best improvement: tensor(0., grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.6553, grad_fn=<DivBackward0>)\n",
      "The function - backprop - took 2.010190010070801 seconds to complete\n",
      "The function - post_backprop - has just started at 1615092810.256727\n",
      "The function - post_backprop - took 2.5033950805664062e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1615092810.256825\n",
      "{1: <neat.genome.DefaultGenome object at 0x7fea6274f2e0>, 2: <neat.genome.DefaultGenome object at 0x7fea6274f940>, 3: <neat.genome.DefaultGenome object at 0x7fea6274f760>, 4: <neat.genome.DefaultGenome object at 0x7fea6274f610>, 5: <neat.genome.DefaultGenome object at 0x7fea6275ee80>}\n",
      "The function - evaluate fitness - took 0.005616903305053711 seconds to complete\n",
      "The function - post evaluate - has just started at 1615092810.262478\n",
      "Population's average fitness: 0.72504 stdev: 0.28994\n",
      "Best fitness: 1.29029 - size: (1, 2) - species 1 - id 3\n",
      "Key: 3\n",
      "Fitness: 1.2902932167053223\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.05767025426030159, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.2787226438522339, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.08881392329931259, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.00037980079650878906 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1615092810.262877\n",
      "The function - pre_reproduction - took 1.1920928955078125e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1615092810.262898\n",
      "Average adjusted fitness: 0.231\n",
      "The function - reproduction - took 0.00015616416931152344 seconds to complete\n",
      "The function - post reproduction - has just started at 1615092810.2630641\n",
      "The function - post reproduction - took 1.0967254638671875e-05 seconds to complete\n",
      "The function - speciate - has just started at 1615092810.2631528\n",
      "Mean genetic distance 0.660, standard deviation 0.319\n",
      "The function - speciate - took 8.606910705566406e-05 seconds to complete\n",
      "The function - end generation - has just started at 1615092810.2632508\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    0     5      1.3    0.231     0\n",
      "Total extinctions: 0\n",
      "Generation time: 2.017 sec\n",
      "The function - end generation - took 0.0001800060272216797 seconds to complete\n",
      "The function - generationStart - has just started at 1615092810.2634418\n",
      "\n",
      " ****** Running generation 1 ****** \n",
      "\n",
      "The function - generationStart - took 2.3126602172851562e-05 seconds to complete\n",
      "The function - pre_backprop - has just started at 1615092810.263475\n",
      "The function - pre_backprop - took 2.193450927734375e-05 seconds to complete\n",
      "The function - backprop - has just started at 1615092810.263508\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: 0.0\n",
      "best improvement: tensor(0., grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.6931, grad_fn=<DivBackward0>)\n",
      "The function - backprop - took 1.9427051544189453 seconds to complete\n",
      "The function - post_backprop - has just started at 1615092812.206298\n",
      "The function - post_backprop - took 2.002716064453125e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1615092812.206337\n",
      "{3: <neat.genome.DefaultGenome object at 0x7fea6274f760>, 1: <neat.genome.DefaultGenome object at 0x7fea6274f2e0>, 6: <neat.genome.DefaultGenome object at 0x7fea5098d070>, 7: <neat.genome.DefaultGenome object at 0x7fea5098d1f0>, 8: <neat.genome.DefaultGenome object at 0x7fea5098d250>}\n",
      "The function - evaluate fitness - took 0.005017995834350586 seconds to complete\n",
      "The function - post evaluate - has just started at 1615092812.211427\n",
      "Population's average fitness: 0.83050 stdev: 0.33860\n",
      "Best fitness: 1.29029 - size: (1, 2) - species 1 - id 3\n",
      "Key: 3\n",
      "Fitness: 1.2902932167053223\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.05767025426030159, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.2787226438522339, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.08881392329931259, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.0002551078796386719 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1615092812.2116952\n",
      "The function - pre_reproduction - took 1.0967254638671875e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1615092812.2117162\n",
      "Average adjusted fitness: 0.493\n",
      "The function - reproduction - took 0.00011277198791503906 seconds to complete\n",
      "The function - post reproduction - has just started at 1615092812.211839\n",
      "The function - post reproduction - took 9.059906005859375e-06 seconds to complete\n",
      "The function - speciate - has just started at 1615092812.2118552\n",
      "Mean genetic distance 0.639, standard deviation 0.251\n",
      "The function - speciate - took 8.392333984375e-05 seconds to complete\n",
      "The function - end generation - has just started at 1615092812.211947\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    1     5      1.3    0.493     1\n",
      "Total extinctions: 0\n",
      "Generation time: 1.949 sec (1.983 average)\n",
      "The function - end generation - took 5.888938903808594e-05 seconds to complete\n",
      "The function - generationStart - has just started at 1615092812.212013\n",
      "\n",
      " ****** Running generation 2 ****** \n",
      "\n",
      "The function - generationStart - took 1.6927719116210938e-05 seconds to complete\n",
      "The function - pre_backprop - has just started at 1615092812.212037\n",
      "The function - pre_backprop - took 1.9073486328125e-05 seconds to complete\n",
      "The function - backprop - has just started at 1615092812.212063\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: 0.0\n",
      "best improvement: tensor(0., grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.7100, grad_fn=<DivBackward0>)\n",
      "The function - backprop - took 1.9455311298370361 seconds to complete\n",
      "The function - post_backprop - has just started at 1615092814.1577039\n",
      "The function - post_backprop - took 2.09808349609375e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1615092814.1577501\n",
      "{3: <neat.genome.DefaultGenome object at 0x7fea6274f760>, 8: <neat.genome.DefaultGenome object at 0x7fea5098d250>, 9: <neat.genome.DefaultGenome object at 0x7fea5098d940>, 10: <neat.genome.DefaultGenome object at 0x7fea5098da60>, 11: <neat.genome.DefaultGenome object at 0x7fea5098db80>}\n",
      "The function - evaluate fitness - took 0.005259990692138672 seconds to complete\n",
      "The function - post evaluate - has just started at 1615092814.163092\n",
      "Population's average fitness: 1.18673 stdev: 0.14924\n",
      "Best fitness: 1.41599 - size: (1, 1) - species 1 - id 9\n",
      "Key: 9\n",
      "Fitness: 1.415993094444275\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.0574650876224041, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.08104127645492554, enabled=True)\n",
      "\n",
      "\n",
      " SPECIES TOPOLOGY IMPROVEMENT\n",
      "\n",
      "\n",
      "{'genome': <neat.genome.DefaultGenome object at 0x7fea5098d8b0>, 'fitness': 1.415993094444275, 'firstDerivatives': [0.0, 0.0, 0.12569987773895264], 'secondDerivatives': [0.0, 0.0, 0.12569987773895264]}\n",
      "Key: 9\n",
      "Fitness: 1.415993094444275\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.0574650876224041, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.08104127645492554, enabled=True)\n",
      "Nodes\n",
      "0    DefaultNodeGene(key=0, bias=-0.0574650876224041, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections\n",
      "(-2, 0)    DefaultConnectionGene(key=(-2, 0), weight=0.08104127645492554, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.00043511390686035156 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1615092814.163542\n",
      "The function - pre_reproduction - took 1.0967254638671875e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1615092814.163567\n",
      "Average adjusted fitness: 0.197\n",
      "The function - reproduction - took 0.00014591217041015625 seconds to complete\n",
      "The function - post reproduction - has just started at 1615092814.163724\n",
      "The function - post reproduction - took 1.0013580322265625e-05 seconds to complete\n",
      "The function - speciate - has just started at 1615092814.1637409\n",
      "Mean genetic distance 0.956, standard deviation 0.582\n",
      "The function - speciate - took 6.914138793945312e-05 seconds to complete\n",
      "The function - end generation - has just started at 1615092814.163818\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    2     5      1.4    0.197     0\n",
      "Total extinctions: 0\n",
      "Generation time: 1.952 sec (1.972 average)\n",
      "The function - end generation - took 5.412101745605469e-05 seconds to complete\n",
      "{0: {'generation': 0, 'generationStartTime': 1615092808.2463858, 'backpropStartTime': 1615092808.246419, 'genomeNodeSizes': [1, 1, 1, 1, 1], 'genomeNodeSizesMean': 1.0, 'genomeNodeSizesSD': 0.0, 'genomeConnectionSizes': [2, 2, 2, 2, 2], 'genomeConnectionSizesMean': 2.0, 'genomeConnectionSizesSD': 0.0, 'backpropEndTime': 1615092810.256751, 'fitnesses': [0.6950081586837769, 0.49419206380844116, 1.2902932167053223, 0.5850921869277954, 0.5606073141098022], 'fitnessMean': 0.7250385880470276, 'fitnessSD': 0.28994046930197515, 'reproductionStartTime': 1615092810.262888, 'reproductionEndTime': 1615092810.263075, 'generationEndTime': 1615092810.2634299}, 1: {'generation': 1, 'generationStartTime': 1615092810.263464, 'backpropStartTime': 1615092810.263486, 'genomeNodeSizes': [1, 1, 1, 1, 1], 'genomeNodeSizesMean': 1.0, 'genomeNodeSizesSD': 0.0, 'genomeConnectionSizes': [2, 2, 2, 1, 1], 'genomeConnectionSizesMean': 1.6, 'genomeConnectionSizesSD': 0.4898979485566356, 'backpropEndTime': 1615092812.206316, 'fitnesses': [1.2902932167053223, 0.6950081586837769, 0.33709320425987244, 0.7080126404762268, 1.1220688819885254], 'fitnessMean': 0.8304952204227447, 'fitnessSD': 0.33859523722195234, 'reproductionStartTime': 1615092812.2117062, 'reproductionEndTime': 1615092812.2118468, 'generationEndTime': 1615092812.2120051}, 2: {'generation': 2, 'generationStartTime': 1615092812.212029, 'backpropStartTime': 1615092812.212045, 'genomeNodeSizes': [1, 1, 1, 1, 1], 'genomeNodeSizesMean': 1.0, 'genomeNodeSizesSD': 0.0, 'genomeConnectionSizes': [2, 1, 1, 1, 2], 'genomeConnectionSizesMean': 1.4, 'genomeConnectionSizesSD': 0.4898979485566356, 'backpropEndTime': 1615092814.157724, 'fitnesses': [1.2902932167053223, 1.1220688819885254, 1.415993094444275, 0.9896554946899414, 1.1156636476516724], 'fitnessMean': 1.1867348670959472, 'fitnessSD': 0.14923588943137622, 'reproductionStartTime': 1615092814.163553, 'reproductionEndTime': 1615092814.163733, 'generationEndTime': 1615092814.163872}}\n"
     ]
    }
   ],
   "source": [
    "config = base_config\n",
    "saveLocation = './'\n",
    "maxNGenerations = 3\n",
    "p = instantiate_population(config, xor_inputs, xor_outputs, saveLocation)\n",
    "# Run for up to nGenerations generations.\n",
    "winner = p.run(eval_genomes, maxNGenerations, nEpochs = 5)\n",
    "\n",
    "g = p.best_genome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.415993094444275\nNodes:\n\t0 DefaultNodeGene(key=0, bias=-0.0574650876224041, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 0), weight=0.08104127645492554, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = deepcopy(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.415993094444275\nNodes:\n\t0 DefaultNodeGene(key=0, bias=-0.0574650876224041, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 0), weight=0.08104127645492554, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.415993094444275\nNodes:\n\t0 DefaultNodeGene(key=0, bias=-0.0574650876224041, response=1.0, activation=sigmoid, aggregation=sum)\n\t2 DefaultNodeGene(key=2, bias=0.04665731895392414, response=1.0, activation=sigmoid, aggregation=sum)\n\t3 DefaultNodeGene(key=3, bias=1.1647211651589515, response=1.0, activation=sigmoid, aggregation=sum)\n\t4 DefaultNodeGene(key=4, bias=-0.36676676399489794, response=1.0, activation=sigmoid, aggregation=sum)\n\t5 DefaultNodeGene(key=5, bias=-0.47366353295619107, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 0), weight=0.08104127645492554, enabled=False)\n\tDefaultConnectionGene(key=(-2, 2), weight=1.0, enabled=False)\n\tDefaultConnectionGene(key=(-2, 3), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(2, 0), weight=0.08104127645492554, enabled=True)\n\tDefaultConnectionGene(key=(3, 0), weight=0.08104127645492554, enabled=True)\n\tDefaultConnectionGene(key=(3, 4), weight=-0.3495623860260543, enabled=True)\n\tDefaultConnectionGene(key=(4, 0), weight=-0.7558365840995874, enabled=True)\n\tDefaultConnectionGene(key=(4, 2), weight=1.0, enabled=False)\n\tDefaultConnectionGene(key=(4, 5), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(5, 2), weight=1.0, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.add_connection(p.config.genome_config, 16, 17, 0.2, True)\n",
    "# h.add_connection(p.config.genome_config, 17, 0, 0.2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.415993094444275\nNodes:\n\t0 DefaultNodeGene(key=0, bias=-0.0574650876224041, response=1.0, activation=sigmoid, aggregation=sum)\n\t2 DefaultNodeGene(key=2, bias=0.04665731895392414, response=1.0, activation=sigmoid, aggregation=sum)\n\t3 DefaultNodeGene(key=3, bias=1.1647211651589515, response=1.0, activation=sigmoid, aggregation=sum)\n\t4 DefaultNodeGene(key=4, bias=-0.36676676399489794, response=1.0, activation=sigmoid, aggregation=sum)\n\t5 DefaultNodeGene(key=5, bias=-0.47366353295619107, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 0), weight=0.08104127645492554, enabled=False)\n\tDefaultConnectionGene(key=(-2, 2), weight=1.0, enabled=False)\n\tDefaultConnectionGene(key=(-2, 3), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(2, 0), weight=0.08104127645492554, enabled=True)\n\tDefaultConnectionGene(key=(3, 0), weight=0.08104127645492554, enabled=True)\n\tDefaultConnectionGene(key=(3, 4), weight=-0.3495623860260543, enabled=True)\n\tDefaultConnectionGene(key=(4, 0), weight=-0.7558365840995874, enabled=True)\n\tDefaultConnectionGene(key=(4, 2), weight=1.0, enabled=False)\n\tDefaultConnectionGene(key=(4, 5), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(5, 2), weight=1.0, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "p.config.genome_config.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: <neat.genes.DefaultNodeGene at 0x7fea5098d2e0>,\n",
       " 2: <neat.genes.DefaultNodeGene at 0x7fea50996ee0>,\n",
       " 3: <neat.genes.DefaultNodeGene at 0x7fea50996eb0>,\n",
       " 4: <neat.genes.DefaultNodeGene at 0x7fea50996f40>,\n",
       " 5: <neat.genes.DefaultNodeGene at 0x7fea5099e0d0>}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "h.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_tracker = {node_id:{'depth':0, 'output_ids':[], 'input_ids':[]} for node_id in h.nodes}\n",
    "for node_id in p.config.genome_config.input_keys:\n",
    "    node_tracker[node_id] = {'depth':0, 'output_ids':[], 'input_ids':[]}\n",
    "trace_stack = [node_id for node_id in p.config.genome_config.input_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "trace_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 2: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 3: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 4: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 5: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " -1: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " -2: {'depth': 0, 'output_ids': [], 'input_ids': []}}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(-2, 0)\n(-2, 2)\n(2, 0)\n(-2, 3)\n(3, 0)\n(-2, 4)\n(4, 2)\n(4, 5)\n(5, 2)\n(4, 0)\n(3, 4)\n"
     ]
    }
   ],
   "source": [
    "for connection in h.connections:\n",
    "    print(connection)\n",
    "    node_tracker[connection[0]]['output_ids'].append(connection[1])\n",
    "    node_tracker[connection[1]]['input_ids'].append(connection[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(trace_stack) > 0:\n",
    "    trace = trace_stack[0]\n",
    "    my_depth = node_tracker[trace]['depth']\n",
    "    next_depth = my_depth + 1\n",
    "    for output_id in node_tracker[trace]['output_ids']:\n",
    "        node_tracker[output_id]['depth'] = max(node_tracker[output_id]['depth'], next_depth)\n",
    "        trace_stack.append(output_id)\n",
    "    del(trace_stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'depth': 5, 'output_ids': [], 'input_ids': [-2, 2, 3, 4]},\n",
       " 2: {'depth': 4, 'output_ids': [0], 'input_ids': [-2, 4, 5]},\n",
       " 3: {'depth': 1, 'output_ids': [0, 4], 'input_ids': [-2]},\n",
       " 4: {'depth': 2, 'output_ids': [2, 5, 0], 'input_ids': [-2, 3]},\n",
       " 5: {'depth': 3, 'output_ids': [2], 'input_ids': [4]},\n",
       " -1: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " -2: {'depth': 0, 'output_ids': [0, 2, 3, 4], 'input_ids': []}}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['output_layers']=[]\n",
    "    node['needs_skip'] = False\n",
    "    node['id'] = node_id\n",
    "    for output_id in node['output_ids']:\n",
    "        node['output_layers'].append(node_tracker[output_id]['depth'])\n",
    "        if node_tracker[output_id]['depth'] > (node['depth']+1):\n",
    "            node['needs_skip'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['input_layers'] = []\n",
    "    node['skip_layer_input'] = False\n",
    "    for input_id in node['input_ids']:\n",
    "        node['input_layers'].append(node_tracker[input_id]['depth'])\n",
    "        if node_tracker[input_id]['depth'] < (node['depth']-1):\n",
    "            node['skip_layer_input'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'depth': 5,\n",
       "  'output_ids': [],\n",
       "  'input_ids': [-2, 2, 3, 4],\n",
       "  'output_layers': [],\n",
       "  'needs_skip': False,\n",
       "  'id': 0,\n",
       "  'input_layers': [0, 4, 1, 2],\n",
       "  'skip_layer_input': True},\n",
       " 2: {'depth': 4,\n",
       "  'output_ids': [0],\n",
       "  'input_ids': [-2, 4, 5],\n",
       "  'output_layers': [5],\n",
       "  'needs_skip': False,\n",
       "  'id': 2,\n",
       "  'input_layers': [0, 2, 3],\n",
       "  'skip_layer_input': True},\n",
       " 3: {'depth': 1,\n",
       "  'output_ids': [0, 4],\n",
       "  'input_ids': [-2],\n",
       "  'output_layers': [5, 2],\n",
       "  'needs_skip': True,\n",
       "  'id': 3,\n",
       "  'input_layers': [0],\n",
       "  'skip_layer_input': False},\n",
       " 4: {'depth': 2,\n",
       "  'output_ids': [2, 5, 0],\n",
       "  'input_ids': [-2, 3],\n",
       "  'output_layers': [4, 3, 5],\n",
       "  'needs_skip': True,\n",
       "  'id': 4,\n",
       "  'input_layers': [0, 1],\n",
       "  'skip_layer_input': True},\n",
       " 5: {'depth': 3,\n",
       "  'output_ids': [2],\n",
       "  'input_ids': [4],\n",
       "  'output_layers': [4],\n",
       "  'needs_skip': False,\n",
       "  'id': 5,\n",
       "  'input_layers': [2],\n",
       "  'skip_layer_input': False},\n",
       " -1: {'depth': 0,\n",
       "  'output_ids': [],\n",
       "  'input_ids': [],\n",
       "  'output_layers': [],\n",
       "  'needs_skip': False,\n",
       "  'id': -1,\n",
       "  'input_layers': [],\n",
       "  'skip_layer_input': False},\n",
       " -2: {'depth': 0,\n",
       "  'output_ids': [0, 2, 3, 4],\n",
       "  'input_ids': [],\n",
       "  'output_layers': [5, 4, 1, 2],\n",
       "  'needs_skip': True,\n",
       "  'id': -2,\n",
       "  'input_layers': [],\n",
       "  'skip_layer_input': False}}"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-2, 2, 3, 4],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 4, 1, 2],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 4: {'nodes': {2: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [-2, 4, 5],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 2,\n",
       "    'input_layers': [0, 2, 3],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 1: {'nodes': {3: {'depth': 1,\n",
       "    'output_ids': [0, 4],\n",
       "    'input_ids': [-2],\n",
       "    'output_layers': [5, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': 3,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}}},\n",
       " 2: {'nodes': {4: {'depth': 2,\n",
       "    'output_ids': [2, 5, 0],\n",
       "    'input_ids': [-2, 3],\n",
       "    'output_layers': [4, 3, 5],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 3: {'nodes': {5: {'depth': 3,\n",
       "    'output_ids': [2],\n",
       "    'input_ids': [4],\n",
       "    'output_layers': [4],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [2],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}}},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [0, 2, 3, 4],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 4, 1, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}}}}"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "layers = {}\n",
    "for node_id, node in node_tracker.items():\n",
    "    if not node['depth'] in layers:\n",
    "        layers[node['depth']] = {\n",
    "            'nodes':{node_id:node}\n",
    "        }\n",
    "    else:\n",
    "        layers[node['depth']]['nodes'][node_id] = node\n",
    "        \n",
    "# Ensure all nodes have a layer index\n",
    "for layer_id, layer in layers.items():\n",
    "    layer_index = 0\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "        \n",
    "        \n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "my layer id is 5\nDefaultConnectionGene(key=(-2, 0), weight=0.08104127645492554, enabled=False)\nDefaultConnectionGene(key=(3, 0), weight=0.08104127645492554, enabled=True)\n0.08104127645492554\nlocation is\n(0, 2)\nDefaultConnectionGene(key=(4, 0), weight=-0.7558365840995874, enabled=True)\n-0.7558365840995874\nlocation is\n(0, 3)\nDefaultConnectionGene(key=(2, 0), weight=0.08104127645492554, enabled=True)\n0.08104127645492554\nlocation is\n(0, 4)\nmy layer id is 4\nDefaultConnectionGene(key=(-2, 2), weight=1.0, enabled=False)\nDefaultConnectionGene(key=(4, 2), weight=1.0, enabled=False)\nDefaultConnectionGene(key=(5, 2), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 3)\nmy layer id is 1\nDefaultConnectionGene(key=(-2, 3), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 1)\nmy layer id is 2\nDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 1)\nDefaultConnectionGene(key=(3, 4), weight=-0.3495623860260543, enabled=True)\n-0.3495623860260543\nlocation is\n(0, 2)\nmy layer id is 3\nDefaultConnectionGene(key=(4, 5), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 0)\nmy layer id is 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LAYER_TYPE_CONNECTED = \"CONNECTED\"\n",
    "LAYER_TYPE_INPUT = \"INPUT\"\n",
    "LAYER_TYPE_OUTPUT = \"OUTPUT\"\n",
    "for layer_id, layer in layers.items():\n",
    "    layer['is_output_layer'] = False\n",
    "    layer['is_input_layer'] = False\n",
    "    layer['layer_type'] = LAYER_TYPE_CONNECTED\n",
    "    # If I have the output node in me, then I am an output\n",
    "    if 0 in layer['nodes']:\n",
    "        layer['is_output_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_OUTPUT\n",
    "\n",
    "    # If I have the first input in me, then I am the input\n",
    "    if -1 in layer['nodes']:\n",
    "        layer['is_input_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_INPUT\n",
    "    biases = []\n",
    "\n",
    "    layer['input_layers'] = []\n",
    "    ## Compute the shape of required inputs\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        for in_layer in node['input_layers']:\n",
    "            if in_layer not in layer['input_layers']:\n",
    "                layer['input_layers'].append(in_layer)\n",
    "    layer['input_layers'].sort()\n",
    "    layer['input_shape'] = sum(len(layers[jj]['nodes']) for jj in layer['input_layers'])\n",
    "    layer['weights_shape'] = (layer['input_shape'], len(layer['nodes']))\n",
    "\n",
    "\n",
    "    # Handle output layer \"edge\" case\n",
    "    if layer['is_output_layer']:\n",
    "        layer['out_weights'] = []\n",
    "        layer['bias'] = [h.nodes[node_id].bias for node_id, node in layer['nodes'].items()]\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle input layer \"edge\" case\n",
    "    elif layer['is_input_layer']:\n",
    "        layer['in_weights'] = []\n",
    "        layer['bias'] = []\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle generic case\n",
    "    else:\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "\n",
    "        layer['bias'] = [h.nodes[node_id].bias for node_id, node in layer['nodes'].items()]\n",
    "        # else:\n",
    "            # layer['bias'] = [0 for _ in layer['nodes']]\n",
    "    \n",
    "    layer_index = 0          \n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "        ### POSSIBLY NEED THIS\n",
    "        # if node['id'] < 0:\n",
    "        #     biases.append(1)\n",
    "        # else:\n",
    "        #     biases.append(h.nodes[node['id']].bias)\n",
    "        # for output_id in node['output_ids']:\n",
    "        #     if (node['id'], output_id) in h.connections:\n",
    "        #         if output_id in layers[layer_id + 1]['nodes']:\n",
    "        #             layer['out_weights'][node['layer_index']][layers[layer_id + 1]['nodes'][output_id]['layer_index']] = h.connections[(node['id'], output_id)].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        # for input_id in node['input_ids']:\n",
    "        #     if (input_id, node['id']) in h.connections:\n",
    "        #         if input_id in layers[layer_id - 1]['nodes']:\n",
    "        #             layer['in_weights'][node['layer_index']][layers[layer_id -1]['nodes'][input_id]['layer_index']] = h.connections[(input_id, node['id'])].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        #################################################\n",
    "            ### END OF POSSIBLY NEEDING THIS\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "\n",
    "\n",
    "    # layer['out_tensor'] = torch.tensor(layer['out_weights'])\n",
    "    # layer['bias'] = torch.tensor(layer['bias'])\n",
    "    # layer['out_tensor_shape'] = layer['out_tensor'].shape\n",
    "    # layer['in_tensor'] = torch.tensor(layer['in_weights'])\n",
    "    # layer['in_tensor_shape'] = layer['in_tensor'].shape\n",
    "\n",
    "\n",
    "\n",
    "    # Set up current weights\n",
    "    layer['input_weights'] = np.zeros(layer['weights_shape'])\n",
    "    layer_offset = 0\n",
    "    # Check every layer and every node for connections\n",
    "    print(\"my layer id is %s\" % (layer_id))\n",
    "    for input_layer_id in layer['input_layers']:\n",
    "        input_layer = layers[input_layer_id]\n",
    "        for node_id, node in input_layer['nodes'].items():\n",
    "            for node_output_id in node['output_ids']:\n",
    "                if node_output_id in layer['nodes']:\n",
    "                    node_output = layer['nodes'][node_output_id]\n",
    "                    # I HAVE THIS NODE!\n",
    "                    # What is it's weight?\n",
    "                    connection = h.connections[(node_id, node_output_id)]\n",
    "                    print(connection)\n",
    "\n",
    "                    if not connection.enabled:\n",
    "                        continue\n",
    "                    connection_weight = connection.weight\n",
    "                    print(connection_weight)\n",
    "\n",
    "                    in_weight_location = layer_offset + node['layer_index']\n",
    "                    out_weight_location = node_output['layer_index']\n",
    "                    print('location is')\n",
    "                    print((out_weight_location, in_weight_location))\n",
    "                    layer['input_weights'][in_weight_location][out_weight_location] = connection_weight\n",
    "        layer_offset += len(input_layer['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-2, 2, 3, 4],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 4, 1, 2],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': True,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'OUTPUT',\n",
       "  'input_layers': [0, 1, 2, 4],\n",
       "  'input_shape': 5,\n",
       "  'weights_shape': (5, 1),\n",
       "  'out_weights': [],\n",
       "  'bias': [-0.0574650876224041],\n",
       "  'in_weights': [[0]],\n",
       "  'input_weights': array([[ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [ 0.08104128],\n",
       "         [-0.75583658],\n",
       "         [ 0.08104128]])},\n",
       " 4: {'nodes': {2: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [-2, 4, 5],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 2,\n",
       "    'input_layers': [0, 2, 3],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0, 2, 3],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [0.04665731895392414],\n",
       "  'input_weights': array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]])},\n",
       " 1: {'nodes': {3: {'depth': 1,\n",
       "    'output_ids': [0, 4],\n",
       "    'input_ids': [-2],\n",
       "    'output_layers': [5, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': 3,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0],\n",
       "  'input_shape': 2,\n",
       "  'weights_shape': (2, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0, 0]],\n",
       "  'bias': [1.1647211651589515],\n",
       "  'input_weights': array([[0.],\n",
       "         [1.]])},\n",
       " 2: {'nodes': {4: {'depth': 2,\n",
       "    'output_ids': [2, 5, 0],\n",
       "    'input_ids': [-2, 3],\n",
       "    'output_layers': [4, 3, 5],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0, 1],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.36676676399489794],\n",
       "  'input_weights': array([[ 0.        ],\n",
       "         [ 1.        ],\n",
       "         [-0.34956239]])},\n",
       " 3: {'nodes': {5: {'depth': 3,\n",
       "    'output_ids': [2],\n",
       "    'input_ids': [4],\n",
       "    'output_layers': [4],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [2],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [2],\n",
       "  'input_shape': 1,\n",
       "  'weights_shape': (1, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.47366353295619107],\n",
       "  'input_weights': array([[1.]])},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [0, 2, 3, 4],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 4, 1, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': True,\n",
       "  'layer_type': 'INPUT',\n",
       "  'input_layers': [],\n",
       "  'input_shape': 0,\n",
       "  'weights_shape': (0, 2),\n",
       "  'in_weights': [],\n",
       "  'bias': [],\n",
       "  'out_weights': [[0], [0]],\n",
       "  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "source": [
    "Add in computation of skip layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'nodes': {4: {'depth': 2,\n",
       "   'output_ids': [2, 5, 0],\n",
       "   'input_ids': [-2, 3],\n",
       "   'output_layers': [4, 3, 5],\n",
       "   'needs_skip': True,\n",
       "   'id': 4,\n",
       "   'input_layers': [0, 1],\n",
       "   'skip_layer_input': True,\n",
       "   'layer_index': 0}},\n",
       " 'is_output_layer': False,\n",
       " 'is_input_layer': False,\n",
       " 'layer_type': 'CONNECTED',\n",
       " 'input_layers': [0, 1],\n",
       " 'input_shape': 3,\n",
       " 'weights_shape': (3, 1),\n",
       " 'out_weights': [[0]],\n",
       " 'in_weights': [[0]],\n",
       " 'bias': [-0.36676676399489794],\n",
       " 'input_weights': array([[ 0.        ],\n",
       "        [ 1.        ],\n",
       "        [-0.34956239]])}"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-2, 2, 3, 4],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 4, 1, 2],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': True,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'OUTPUT',\n",
       "  'input_layers': [0, 1, 2, 4],\n",
       "  'input_shape': 5,\n",
       "  'weights_shape': (5, 1),\n",
       "  'out_weights': [],\n",
       "  'bias': [-0.0574650876224041],\n",
       "  'in_weights': [[0]],\n",
       "  'input_weights': array([[ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [ 0.08104128],\n",
       "         [-0.75583658],\n",
       "         [ 0.08104128]])},\n",
       " 4: {'nodes': {2: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [-2, 4, 5],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 2,\n",
       "    'input_layers': [0, 2, 3],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0, 2, 3],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [0.04665731895392414],\n",
       "  'input_weights': array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]])},\n",
       " 1: {'nodes': {3: {'depth': 1,\n",
       "    'output_ids': [0, 4],\n",
       "    'input_ids': [-2],\n",
       "    'output_layers': [5, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': 3,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0],\n",
       "  'input_shape': 2,\n",
       "  'weights_shape': (2, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0, 0]],\n",
       "  'bias': [1.1647211651589515],\n",
       "  'input_weights': array([[0.],\n",
       "         [1.]])},\n",
       " 2: {'nodes': {4: {'depth': 2,\n",
       "    'output_ids': [2, 5, 0],\n",
       "    'input_ids': [-2, 3],\n",
       "    'output_layers': [4, 3, 5],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0, 1],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.36676676399489794],\n",
       "  'input_weights': array([[ 0.        ],\n",
       "         [ 1.        ],\n",
       "         [-0.34956239]])},\n",
       " 3: {'nodes': {5: {'depth': 3,\n",
       "    'output_ids': [2],\n",
       "    'input_ids': [4],\n",
       "    'output_layers': [4],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [2],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [2],\n",
       "  'input_shape': 1,\n",
       "  'weights_shape': (1, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.47366353295619107],\n",
       "  'input_weights': array([[1.]])},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [0, 2, 3, 4],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 4, 1, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': True,\n",
       "  'layer_type': 'INPUT',\n",
       "  'input_layers': [],\n",
       "  'input_shape': 0,\n",
       "  'weights_shape': (0, 2),\n",
       "  'in_weights': [],\n",
       "  'bias': [],\n",
       "  'out_weights': [[0], [0]],\n",
       "  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "source": [
    "The question is, how do you code the operations to dynamically create the\n",
    "NN? You need to be able to do the right things in the right order. You have\n",
    "a list of possible operations:\n",
    "* Matrix multiple\n",
    "* Concatenate (for skip layers)\n",
    "* Matrix addition (for biases)\n",
    "* Output\n",
    "\n",
    "The order of operations in each layer is:\n",
    "\n",
    "1. Concatenate input tensors\n",
    "2. Matrix multiply input tensors with weights\n",
    "3. Add bias tensors\n",
    "4. Apply activation function\n",
    "\n",
    "I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "These computations can be computed back-to-front, and then executed forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "ACTIVATE_OPERATION = \"ACTIVATE\"\n",
    "OUTPUT_OPERATION = \"OUTPUT\"\n",
    "TENADD_OPERATION = \"TENADD\" # Tensor ADD\n",
    "ADD_BIAS_OPERATION = \"BIASADD\"\n",
    "TENMUL_OPERATION = \"TENMUL\"\n",
    "TENCAT_OPERATION = \"TENCAT\"\n",
    "order_of_operations = []\n",
    "\n",
    "# for layer_id, layer in layers.items():\n",
    "#     print(layer)\n",
    "#     # Output for final layer\n",
    "#     if layer['is_output_layer']:\n",
    "#         order_of_operations.append(OUTPUT_OPERATION)\n",
    "#     # Activate\n",
    "#     order_of_operations.append(ACTIVATE_OPERATION)\n",
    "#     # Add Bias\n",
    "#     order_of_operations.append(ADD_BIAS_OPERATION)\n",
    "#     # Matrix Multiply weights\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     print(order_of_operations)\n",
    "\n",
    "#     break\n",
    "\n",
    "for layer_id in range(len(layers)):\n",
    "    layer = layers[layer_id]\n",
    "    print(layer)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'nodes': {-1: {'depth': 0, 'output_ids': [], 'input_ids': [], 'output_layers': [], 'needs_skip': False, 'id': -1, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 0}, -2: {'depth': 0, 'output_ids': [0, 2, 3, 4], 'input_ids': [], 'output_layers': [5, 4, 1, 2], 'needs_skip': True, 'id': -2, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 1}}, 'is_output_layer': False, 'is_input_layer': True, 'layer_type': 'INPUT', 'input_layers': [], 'input_shape': 0, 'weights_shape': (0, 2), 'in_weights': [], 'bias': [], 'out_weights': [[0], [0]], 'input_weights': array([], shape=(0, 2), dtype=float64)}\n{'nodes': {3: {'depth': 1, 'output_ids': [0, 4], 'input_ids': [-2], 'output_layers': [5, 2], 'needs_skip': True, 'id': 3, 'input_layers': [0], 'skip_layer_input': False, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0], 'input_shape': 2, 'weights_shape': (2, 1), 'out_weights': [[0]], 'in_weights': [[0, 0]], 'bias': [1.1647211651589515], 'input_weights': array([[0.],\n       [1.]])}\n{'nodes': {4: {'depth': 2, 'output_ids': [2, 5, 0], 'input_ids': [-2, 3], 'output_layers': [4, 3, 5], 'needs_skip': True, 'id': 4, 'input_layers': [0, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0, 1], 'input_shape': 3, 'weights_shape': (3, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [-0.36676676399489794], 'input_weights': array([[ 0.        ],\n       [ 1.        ],\n       [-0.34956239]])}\n{'nodes': {5: {'depth': 3, 'output_ids': [2], 'input_ids': [4], 'output_layers': [4], 'needs_skip': False, 'id': 5, 'input_layers': [2], 'skip_layer_input': False, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [2], 'input_shape': 1, 'weights_shape': (1, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [-0.47366353295619107], 'input_weights': array([[1.]])}\n{'nodes': {2: {'depth': 4, 'output_ids': [0], 'input_ids': [-2, 4, 5], 'output_layers': [5], 'needs_skip': False, 'id': 2, 'input_layers': [0, 2, 3], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0, 2, 3], 'input_shape': 4, 'weights_shape': (4, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [0.04665731895392414], 'input_weights': array([[0.],\n       [0.],\n       [0.],\n       [1.]])}\n{'nodes': {0: {'depth': 5, 'output_ids': [], 'input_ids': [-2, 2, 3, 4], 'output_layers': [], 'needs_skip': False, 'id': 0, 'input_layers': [0, 4, 1, 2], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': True, 'is_input_layer': False, 'layer_type': 'OUTPUT', 'input_layers': [0, 1, 2, 4], 'input_shape': 5, 'weights_shape': (5, 1), 'out_weights': [], 'bias': [-0.0574650876224041], 'in_weights': [[0]], 'input_weights': array([[ 0.        ],\n       [ 0.        ],\n       [ 0.08104128],\n       [-0.75583658],\n       [ 0.08104128]])}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(3, 1)\n",
    "c = torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0585],\n",
       "        [0.1552]])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-2, 2, 3, 4],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 4, 1, 2],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': True,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'OUTPUT',\n",
       "  'input_layers': [0, 1, 2, 4],\n",
       "  'input_shape': 5,\n",
       "  'weights_shape': (5, 1),\n",
       "  'out_weights': [],\n",
       "  'bias': [-0.0574650876224041],\n",
       "  'in_weights': [[0]],\n",
       "  'input_weights': array([[ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [ 0.08104128],\n",
       "         [-0.75583658],\n",
       "         [ 0.08104128]])},\n",
       " 4: {'nodes': {2: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [-2, 4, 5],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 2,\n",
       "    'input_layers': [0, 2, 3],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0, 2, 3],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [0.04665731895392414],\n",
       "  'input_weights': array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]])},\n",
       " 1: {'nodes': {3: {'depth': 1,\n",
       "    'output_ids': [0, 4],\n",
       "    'input_ids': [-2],\n",
       "    'output_layers': [5, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': 3,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0],\n",
       "  'input_shape': 2,\n",
       "  'weights_shape': (2, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0, 0]],\n",
       "  'bias': [1.1647211651589515],\n",
       "  'input_weights': array([[0.],\n",
       "         [1.]])},\n",
       " 2: {'nodes': {4: {'depth': 2,\n",
       "    'output_ids': [2, 5, 0],\n",
       "    'input_ids': [-2, 3],\n",
       "    'output_layers': [4, 3, 5],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [0, 1],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.36676676399489794],\n",
       "  'input_weights': array([[ 0.        ],\n",
       "         [ 1.        ],\n",
       "         [-0.34956239]])},\n",
       " 3: {'nodes': {5: {'depth': 3,\n",
       "    'output_ids': [2],\n",
       "    'input_ids': [4],\n",
       "    'output_layers': [4],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [2],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'layer_type': 'CONNECTED',\n",
       "  'input_layers': [2],\n",
       "  'input_shape': 1,\n",
       "  'weights_shape': (1, 1),\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.47366353295619107],\n",
       "  'input_weights': array([[1.]])},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [0, 2, 3, 4],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 4, 1, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': True,\n",
       "  'layer_type': 'INPUT',\n",
       "  'input_layers': [],\n",
       "  'input_shape': 0,\n",
       "  'weights_shape': (0, 2),\n",
       "  'in_weights': [],\n",
       "  'bias': [],\n",
       "  'out_weights': [[0], [0]],\n",
       "  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = nn.Parameter(torch.tensor([0.3, 0.4], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Net, self).__init__()  # just run the init of parent class (nn.Module)\n",
    "        self.weights = {layer_id: self._tt(layer['input_weights'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.biases = {layer_id: self._tt(layer['bias'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.layer_types = {layer_id: layer['layer_type'] for layer_id, layer in layers.items()}\n",
    "        self.layer_inputs = {layer_id: layer['input_layers'] for layer_id, layer in layers.items()}\n",
    "        self.n_layers = len(layers)\n",
    "\n",
    "        self._outputs = None\n",
    "\n",
    "        for w_id, w in self.weights.items():\n",
    "            self.register_parameter(name =\"weight_%s\"%w_id, param=w)\n",
    "\n",
    "        for b_id, b in self.biases.items():\n",
    "            self.register_parameter(name = \"bias_%s\"%b_id, param=b)\n",
    "\n",
    "        # x = F.relu(self.fc1(x))\n",
    "\n",
    "        # self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tt(mat):\n",
    "        return torch.nn.Parameter(torch.tensor(mat,dtype=torch.float64), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        # print(\"running forward\")\n",
    "        self._outputs = {}\n",
    "        for layer_id in range(self.n_layers):\n",
    "            layer_input = None\n",
    "            layer_type = self.layer_types[layer_id]\n",
    "\n",
    "            # print(layer_id)\n",
    "            # print(layer_type)\n",
    "\n",
    "            if layer_type == LAYER_TYPE_INPUT:\n",
    "                self._outputs[layer_id] = x\n",
    "                continue\n",
    "            if layer_type == LAYER_TYPE_CONNECTED:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "\n",
    "            # print(layer_input)\n",
    "            # print(self.weights[layer_id])\n",
    "            # print(self.biases[layer_id])\n",
    "\n",
    "            self._outputs[layer_id] = torch.sigmoid( torch.matmul(layer_input, self.weights[layer_id]) + self.biases[layer_id] )\n",
    "\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                return self._outputs[layer_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: Parameter containing:\n",
       " tensor([-0.0575], dtype=torch.float64, requires_grad=True),\n",
       " 4: Parameter containing:\n",
       " tensor([0.0467], dtype=torch.float64, requires_grad=True),\n",
       " 1: Parameter containing:\n",
       " tensor([1.1647], dtype=torch.float64, requires_grad=True),\n",
       " 2: Parameter containing:\n",
       " tensor([-0.3668], dtype=torch.float64, requires_grad=True),\n",
       " 3: Parameter containing:\n",
       " tensor([-0.4737], dtype=torch.float64, requires_grad=True),\n",
       " 0: Parameter containing:\n",
       " tensor([], dtype=torch.float64, requires_grad=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "net.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "net._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.4331], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "result = net.forward(x_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "expected_result = torch.tensor(xor(x_input[0], x_input[1]))\n",
    "expected_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The function - benchmark - has just started at 1615092814.643156\n",
      "The function - benchmark - took 5.848366022109985 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "# x_input = torch.randn(1, 1, 2, dtype=torch.float64)\n",
    "with MethodTimer('benchmark'):\n",
    "\n",
    "    for k in range(25):\n",
    "        for n in range(400):\n",
    "            x_input = nn.Parameter(torch.tensor([np.random.rand(), np.random.rand()], dtype=torch.float64))\n",
    "\n",
    "\n",
    "            result = net.forward(x_input)\n",
    "            expected_result = torch.tensor(xor(x_input[0], x_input[1]), dtype=torch.float64)\n",
    "            # print(x_input)\n",
    "            # print(expected_result)\n",
    "            # print(result)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(result, expected_result)\n",
    "            net.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                # for parameter in net.parameters():\n",
    "                    # parameter.data -= learning_rate*parameter.grad.data\n",
    "                    # weight -= learning_rate * weight.grad\n",
    "                for  w_id, weight in net.weights.items():\n",
    "                    try:\n",
    "                        weight -= learning_rate * weight.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "                for  b_id, bias in net.biases.items():\n",
    "                    try:\n",
    "                        bias -= learning_rate * bias.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(torch.tensor(xor_inputs, dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.0083], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "net.biases[1].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.4844], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "output = net(x_input)\n",
    "loss = loss_fn(result, expected_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[ 0.1315],\n        [-0.1235],\n        [ 0.0934],\n        [-0.5734],\n        [ 0.0732]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.1986],\n        [-0.2043],\n        [-0.1504],\n        [ 0.8159]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.0614],\n        [0.8300]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[ 0.1794],\n        [ 0.8517],\n        [-0.6349]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.9659]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.0297], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.3506], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([0.8202], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.7256], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.5633], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "myW = net.weights[1]"
   ]
  },
  {
   "source": [
    "myW"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0614],\n",
       "        [0.8300]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.2346, dtype=torch.float64, grad_fn=<MseLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[ 0.1315],\n        [-0.1235],\n        [ 0.0934],\n        [-0.5734],\n        [ 0.0732]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.1986],\n        [-0.2043],\n        [-0.1504],\n        [ 0.8159]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.0614],\n        [0.8300]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[ 0.1794],\n        [ 0.8517],\n        [-0.6349]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.9659]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.0297], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.3506], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([0.8202], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.7256], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.5633], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: Parameter containing:\n",
       " tensor([[ 0.1315],\n",
       "         [-0.1235],\n",
       "         [ 0.0934],\n",
       "         [-0.5734],\n",
       "         [ 0.0732]], dtype=torch.float64, requires_grad=True),\n",
       " 4: Parameter containing:\n",
       " tensor([[-0.1986],\n",
       "         [-0.2043],\n",
       "         [-0.1504],\n",
       "         [ 0.8159]], dtype=torch.float64, requires_grad=True),\n",
       " 1: Parameter containing:\n",
       " tensor([[0.0614],\n",
       "         [0.8300]], dtype=torch.float64, requires_grad=True),\n",
       " 2: Parameter containing:\n",
       " tensor([[ 0.1794],\n",
       "         [ 0.8517],\n",
       "         [-0.6349]], dtype=torch.float64, requires_grad=True),\n",
       " 3: Parameter containing:\n",
       " tensor([[0.9659]], dtype=torch.float64, requires_grad=True),\n",
       " 0: Parameter containing:\n",
       " tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: Parameter containing:\n",
       " tensor([0.2095, 0.3605], dtype=torch.float64, requires_grad=True),\n",
       " 1: tensor([0.7562], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " 2: tensor([0.2971], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " 3: tensor([0.4314], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " 4: tensor([0.4604], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " 5: tensor([0.4719], dtype=torch.float64, grad_fn=<SigmoidBackward>)}"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "net._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1, 1,2, dtype=torch.float64)\n",
    "label = [xor(val[0][0], val[0][1]) for val in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "def forward(layers, x):\n",
    "    layer_outputs = {}\n",
    "    curr_value = x\n",
    "    for ii in range(len(layers)):\n",
    "        print(ii)\n",
    "        layer = layers[ii]\n",
    "        if layer['is_output_layer']:\n",
    "            # return curr_value\n",
    "            return(layer_outputs)\n",
    "        input_layers = [layer_outputs[layer_id] for layer_id in layer['input_layers']]\n",
    "    return(layer_outputs)\n",
    "        # layer_outputs[ii] = torch.relu(\n",
    "        #     torch.add(\n",
    "        #         torch.matmul(\n",
    "        #             torch.cat(layer['input_layers']),\n",
    "        #             layer['weights']\n",
    "\n",
    "        #         ),\n",
    "        #         layer['bias']\n",
    "        #     )\n",
    "        # )\n",
    "        # curr_value = torch.sigmoid(torch.matmul(curr_value + layers[ii]['bias'], layers[ii]['out_tensor']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward(layers, x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.0574650876224041"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "h.nodes[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The function - Parse NNEAT - has just started at 1615092850.771071\nThe function - Parse NNEAT - took 0.001669168472290039 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "with MethodTimer('Parse NNEAT'):\n",
    "    myNeat = nneat(h, p.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.4347], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "myNeat.forward(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The function - Backprop benchmark (10k inputs) - has just started at 1615092852.182579\n",
      "The function - Backprop benchmark (10k inputs) - took 5.201025009155273 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "# x_input = torch.randn(1, 1, 2, dtype=torch.float64)\n",
    "with MethodTimer('Backprop benchmark (10k inputs)'):\n",
    "\n",
    "    for k in range(25):\n",
    "        for n in range(400):\n",
    "            x_input = nn.Parameter(torch.tensor([np.random.rand(), np.random.rand()], dtype=torch.float64))\n",
    "\n",
    "\n",
    "            result = myNeat.forward(x_input)\n",
    "            expected_result = torch.tensor(xor(x_input[0], x_input[1]), dtype=torch.float64)\n",
    "            # print(x_input)\n",
    "            # print(expected_result)\n",
    "            # print(result)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(result, expected_result)\n",
    "            myNeat.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                # for parameter in net.parameters():\n",
    "                    # try:\n",
    "                    #     parameter.data -= learning_rate*parameter.grad.data\n",
    "                    # except AttributeError:\n",
    "                    #     continue\n",
    "                    # weight -= learning_rate * weight.grad\n",
    "                for  w_id, weight in net.weights.items():\n",
    "                    try:\n",
    "                        weight -= learning_rate * weight.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "                for  b_id, bias in net.biases.items():\n",
    "                    try:\n",
    "                        bias -= learning_rate * bias.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[ 0.1315],\n        [-0.1235],\n        [ 0.0934],\n        [-0.5734],\n        [ 0.0732]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[-0.1986],\n        [-0.2043],\n        [-0.1504],\n        [ 0.8159]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.0614],\n        [0.8300]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[ 0.1794],\n        [ 0.8517],\n        [-0.6349]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([[0.9659]], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.0297], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.3506], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([0.8202], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.7256], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([-0.5633], dtype=torch.float64, requires_grad=True)\nParameter containing:\ntensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NeuralNeat' object has no attribute 'genome'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-dcc5df52631a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyNeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    576\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NeuralNeat' object has no attribute 'genome'"
     ]
    }
   ],
   "source": [
    "myNeat.genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}