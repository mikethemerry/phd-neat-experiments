{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import neat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from explaneat.core.backprop import NeatNet\n",
    "from explaneat.core import backprop\n",
    "from explaneat.core.backproppop import BackpropPopulation\n",
    "# from explaneat.visualization import visualize\n",
    "from explaneat.core.experiment import ExperimentReporter\n",
    "from explaneat.core.utility import one_hot_encode\n",
    "from explaneat.core.utility import MethodTimer\n",
    "\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.preprocessing import StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from explaneat.core.neuralneat import NeuralNeat as nneat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED      = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = False\n",
    "device = torch.device(\"cuda:1\" if USE_CUDA else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xor(a, b, threshold = 0.5):\n",
    "    response = False\n",
    "    if a > threshold and b < threshold:\n",
    "        response = True\n",
    "    if a < threshold and b > threshold:\n",
    "        response = True\n",
    "    # return (1.0, 0.0) if response else (0.0, 1.0)\n",
    "    return 1.0 if response else 0.0\n",
    "    \n",
    "\n",
    "def create_n_points(n, size, min=0.0, max=1.0):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append([\n",
    "            random.uniform(min, max) for ii in range(size)\n",
    "        ])\n",
    "\n",
    "    return data\n",
    "\n",
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "def overUnder(val, threshold):\n",
    "    return 1. if val > threshold else 0\n",
    "\n",
    "xor_inputs = create_n_points(400, 2, -1, 1)\n",
    "\n",
    "xor_outputs = [\n",
    "    [xor(tup[0], tup[1], 0)] for tup in xor_inputs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.870015669339151, 0.04251848380257339],\n [-0.09132695985153005, -0.06454170656147773],\n [0.14681228380560185, 0.2647219775028271],\n [0.46285542547505343, -0.8571944154754261],\n [0.5377812869629481, -0.3478608864242061]]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.0], [0.0], [0.0], [1.0], [1.0]]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_outputs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config_xor\"\n",
    "base_config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_population(config, xs, ys, saveLocation):\n",
    "\n",
    "    if not os.path.exists(saveLocation):\n",
    "        os.makedirs(saveLocation)\n",
    "        \n",
    "    config.save(os.path.join(saveLocation, 'config.conf'))\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    with MethodTimer(\"Backprop everything\"):\n",
    "        p = BackpropPopulation(config, \n",
    "                                xs, \n",
    "                                ys, \n",
    "                                criterion=nn.BCEWithLogitsLoss())\n",
    "\n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5, filename_prefix=str(saveLocation) + \"checkpoint-\" ))\n",
    "    bpReporter = backprop.BackpropReporter(True)\n",
    "    p.add_reporter(bpReporter)\n",
    "    p.add_reporter(ExperimentReporter(saveLocation))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    \n",
    "    print(genomes)\n",
    "    loss = nn.BCELoss()\n",
    "    loss = loss.to(device)\n",
    "    for genome_id, genome in genomes.items():\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        preds = []\n",
    "        for xi in xor_inputs:\n",
    "            preds.append(net.activate(xi))\n",
    "        genome.fitness = float(1./loss(torch.tensor(preds).to(device), torch.tensor(xor_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function - Backprop everything - has just started at 1632343889.854615\n",
      "The function - Backprop everything - took 0.044628143310546875 seconds to complete\n",
      "The function - generationStart - has just started at 1632343889.899742\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "The function - generationStart - took 0.00016427040100097656 seconds to complete\n",
      "The function - pre_backprop - has just started at 1632343889.899939\n",
      "The function - pre_backprop - took 9.202957153320312e-05 seconds to complete\n",
      "The function - backprop - has just started at 1632343889.9001012\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: -0.0012103368198654208\n",
      "best improvement: -0.0016138206778952835\n",
      "best loss: 0.5130461264252956\n",
      "The function - backprop - took 0.08482789993286133 seconds to complete\n",
      "The function - post_backprop - has just started at 1632343889.984957\n",
      "The function - post_backprop - took 2.288818359375e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1632343889.985062\n",
      "{1: <neat.genome.DefaultGenome object at 0x7fa79801d520>, 2: <neat.genome.DefaultGenome object at 0x7fa79801d550>, 3: <neat.genome.DefaultGenome object at 0x7fa7da091460>, 4: <neat.genome.DefaultGenome object at 0x7fa7da091760>, 5: <neat.genome.DefaultGenome object at 0x7fa7da091a60>}\n",
      "The function - evaluate fitness - took 0.010772228240966797 seconds to complete\n",
      "The function - post evaluate - has just started at 1632343889.9959319\n",
      "Population's average fitness: 0.46381 stdev: 0.11670\n",
      "Best fitness: 0.62888 - size: (1, 2) - species 1 - id 3\n",
      "Key: 3\n",
      "Fitness: 0.6288788318634033\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.21028348572964897, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=0.7017329503078745, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=1.108447049029712, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.00046515464782714844 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1632343889.996421\n",
      "The function - pre_reproduction - took 1.6927719116210938e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1632343889.99645\n",
      "Average adjusted fitness: 0.194\n",
      "The function - reproduction - took 0.00023889541625976562 seconds to complete\n",
      "The function - post reproduction - has just started at 1632343889.996704\n",
      "The function - post reproduction - took 2.288818359375e-05 seconds to complete\n",
      "The function - speciate - has just started at 1632343889.9967391\n",
      "Mean genetic distance 1.366, standard deviation 0.234\n",
      "The function - speciate - took 9.584426879882812e-05 seconds to complete\n",
      "The function - end generation - has just started at 1632343889.996844\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    0     5      0.6    0.194     0\n",
      "Total extinctions: 0\n",
      "Generation time: 0.097 sec\n",
      "The function - end generation - took 0.00012111663818359375 seconds to complete\n",
      "The function - generationStart - has just started at 1632343889.9969769\n",
      "\n",
      " ****** Running generation 1 ****** \n",
      "\n",
      "The function - generationStart - took 3.0994415283203125e-05 seconds to complete\n",
      "The function - pre_backprop - has just started at 1632343889.997016\n",
      "The function - pre_backprop - took 2.5033950805664062e-05 seconds to complete\n",
      "The function - backprop - has just started at 1632343889.9970539\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: -0.0009433671875344718\n",
      "best improvement: -0.0013748700733076102\n",
      "best loss: 0.5130461264252956\n",
      "The function - backprop - took 0.013761043548583984 seconds to complete\n",
      "The function - post_backprop - has just started at 1632343890.0108328\n",
      "The function - post_backprop - took 2.1219253540039062e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1632343890.010875\n",
      "{3: <neat.genome.DefaultGenome object at 0x7fa7da091460>, 4: <neat.genome.DefaultGenome object at 0x7fa7da091760>, 6: <neat.genome.DefaultGenome object at 0x7fa7c8824400>, 7: <neat.genome.DefaultGenome object at 0x7fa7c8824640>, 8: <neat.genome.DefaultGenome object at 0x7fa7c88246a0>}\n",
      "The function - evaluate fitness - took 0.005801200866699219 seconds to complete\n",
      "The function - post evaluate - has just started at 1632343890.0167801\n",
      "Population's average fitness: 0.66674 stdev: 0.20757\n",
      "Best fitness: 1.04071 - size: (2, 2) - species 1 - id 6\n",
      "Key: 6\n",
      "Fitness: 1.0407109260559082\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.05669275103529431, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=2.283953286287462, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=1.0906448201827157, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=1.8134750207166896, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.6403394255827368, enabled=True)\n",
      "\n",
      "\n",
      " SPECIES TOPOLOGY IMPROVEMENT\n",
      "\n",
      "\n",
      "{'genome': <neat.genome.DefaultGenome object at 0x7fa7c8824370>, 'fitness': 1.0407109260559082, 'firstDerivatives': [0.0, 0.4118320941925049], 'secondDerivatives': [0.0, 0.4118320941925049]}\n",
      "Key: 6\n",
      "Fitness: 1.0407109260559082\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.05669275103529431, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=2.283953286287462, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=1.0906448201827157, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=1.8134750207166896, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.6403394255827368, enabled=True)\n",
      "Nodes\n",
      "0    DefaultNodeGene(key=0, bias=0.05669275103529431, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "1    DefaultNodeGene(key=1, bias=2.283953286287462, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections\n",
      "(-1, 0)    DefaultConnectionGene(key=(-1, 0), weight=0.6403394255827368, enabled=True)\n",
      "(-2, 0)    DefaultConnectionGene(key=(-2, 0), weight=1.0906448201827157, enabled=False)\n",
      "(-2, 1)    DefaultConnectionGene(key=(-2, 1), weight=1.8134750207166896, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.0005688667297363281 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1632343890.017368\n",
      "The function - pre_reproduction - took 1.5974044799804688e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1632343890.017396\n",
      "Average adjusted fitness: 0.224\n",
      "The function - reproduction - took 0.0001590251922607422 seconds to complete\n",
      "The function - post reproduction - has just started at 1632343890.017569\n",
      "The function - post reproduction - took 1.4066696166992188e-05 seconds to complete\n",
      "The function - speciate - has just started at 1632343890.0175931\n",
      "Mean genetic distance 1.206, standard deviation 0.535\n",
      "The function - speciate - took 9.298324584960938e-05 seconds to complete\n",
      "The function - end generation - has just started at 1632343890.017697\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    1     5      1.0    0.224     0\n",
      "Total extinctions: 0\n",
      "Generation time: 0.021 sec (0.059 average)\n",
      "The function - end generation - took 7.295608520507812e-05 seconds to complete\n",
      "The function - generationStart - has just started at 1632343890.017781\n",
      "\n",
      " ****** Running generation 2 ****** \n",
      "\n",
      "The function - generationStart - took 2.193450927734375e-05 seconds to complete\n",
      "The function - pre_backprop - has just started at 1632343890.017813\n",
      "The function - pre_backprop - took 2.4080276489257812e-05 seconds to complete\n",
      "The function - backprop - has just started at 1632343890.017848\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: -0.0010543289991321147\n",
      "best improvement: -0.0011725124211061644\n",
      "best loss: 0.508410428821649\n",
      "The function - backprop - took 0.011567831039428711 seconds to complete\n",
      "The function - post_backprop - has just started at 1632343890.029433\n",
      "The function - post_backprop - took 1.9073486328125e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1632343890.0294778\n",
      "{6: <neat.genome.DefaultGenome object at 0x7fa7c8824400>, 7: <neat.genome.DefaultGenome object at 0x7fa7c8824640>, 9: <neat.genome.DefaultGenome object at 0x7fa7c882aa60>, 10: <neat.genome.DefaultGenome object at 0x7fa7c882ab80>, 11: <neat.genome.DefaultGenome object at 0x7fa7c882adc0>}\n",
      "The function - evaluate fitness - took 0.007711172103881836 seconds to complete\n",
      "The function - post evaluate - has just started at 1632343890.0374231\n",
      "Population's average fitness: 0.82902 stdev: 0.12779\n",
      "Best fitness: 1.04071 - size: (2, 2) - species 1 - id 6\n",
      "Key: 6\n",
      "Fitness: 1.0407109260559082\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.05669275103529431, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=2.283953286287462, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=1.0906448201827157, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=1.8134750207166896, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.6403394255827368, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.0003788471221923828 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1632343890.0378182\n",
      "The function - pre_reproduction - took 1.4781951904296875e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1632343890.037847\n",
      "Average adjusted fitness: 0.124\n",
      "The function - reproduction - took 0.0001919269561767578 seconds to complete\n",
      "The function - post reproduction - has just started at 1632343890.038052\n",
      "The function - post reproduction - took 1.2874603271484375e-05 seconds to complete\n",
      "The function - speciate - has just started at 1632343890.0380769\n",
      "Mean genetic distance 1.410, standard deviation 0.411\n",
      "The function - speciate - took 9.322166442871094e-05 seconds to complete\n",
      "The function - end generation - has just started at 1632343890.038181\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    2     5      1.0    0.124     1\n",
      "Total extinctions: 0\n",
      "Generation time: 0.020 sec (0.046 average)\n",
      "The function - end generation - took 6.985664367675781e-05 seconds to complete\n",
      "{0: {'generation': 0, 'generationStartTime': 1632343889.899904, 'backpropStartTime': 1632343889.899969, 'genomeNodeSizes': [1, 1, 1, 1, 1], 'genomeNodeSizesMean': 1.0, 'genomeNodeSizesSD': 0.0, 'genomeConnectionSizes': [2, 2, 2, 2, 2], 'genomeConnectionSizesMean': 2.0, 'genomeConnectionSizesSD': 0.0, 'backpropEndTime': 1632343889.984979, 'fitnesses': [0.26955050230026245, 0.4575798809528351, 0.6288788318634033, 0.5164390802383423, 0.44659170508384705], 'fitnessMean': 0.46380800008773804, 'fitnessSD': 0.11669582325790409, 'reproductionStartTime': 1632343889.996437, 'reproductionEndTime': 1632343889.996727, 'generationEndTime': 1632343889.996964}, 1: {'generation': 1, 'generationStartTime': 1632343889.9970071, 'backpropStartTime': 1632343889.997029, 'genomeNodeSizes': [1, 1, 2, 1, 1], 'genomeNodeSizesMean': 1.2, 'genomeNodeSizesSD': 0.4, 'genomeConnectionSizes': [2, 2, 3, 1, 2], 'genomeConnectionSizesMean': 2.0, 'genomeConnectionSizesSD': 0.6324555320336759, 'backpropEndTime': 1632343890.010853, 'fitnesses': [0.6288788318634033, 0.5164390802383423, 1.0407109260559082, 0.7047711610794067, 0.44288885593414307], 'fitnessMean': 0.6667377710342407, 'fitnessSD': 0.20757350117815174, 'reproductionStartTime': 1632343890.0173829, 'reproductionEndTime': 1632343890.0175822, 'generationEndTime': 1632343890.0177689}, 2: {'generation': 2, 'generationStartTime': 1632343890.017802, 'backpropStartTime': 1632343890.017824, 'genomeNodeSizes': [2, 1, 1, 2, 1], 'genomeNodeSizesMean': 1.4, 'genomeNodeSizesSD': 0.4898979485566356, 'genomeConnectionSizes': [3, 1, 1, 3, 1], 'genomeConnectionSizesMean': 1.8, 'genomeConnectionSizesSD': 0.9797958971132713, 'backpropEndTime': 1632343890.029451, 'fitnesses': [1.0407109260559082, 0.7047711610794067, 0.7327441573143005, 0.7556813359260559, 0.9112123250961304], 'fitnessMean': 0.8290239810943604, 'fitnessSD': 0.1277920168914931, 'reproductionStartTime': 1632343890.037833, 'reproductionEndTime': 1632343890.038065, 'generationEndTime': 1632343890.038251}}\n"
     ]
    }
   ],
   "source": [
    "config = base_config\n",
    "saveLocation = './'\n",
    "maxNGenerations = 3\n",
    "p = instantiate_population(config, xor_inputs, xor_outputs, saveLocation)\n",
    "# Run for up to nGenerations generations.\n",
    "winner = p.run(eval_genomes, maxNGenerations, nEpochs = 5)\n",
    "\n",
    "g = p.best_genome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 6\n",
      "Fitness: 1.0407109260559082\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.05669275103529431, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=2.283953286287462, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=1.0906448201827157, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=1.8134750207166896, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.6403394255827368, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = deepcopy(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 6\n",
      "Fitness: 1.0407109260559082\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.05669275103529431, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=2.283953286287462, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=1.0906448201827157, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=1.8134750207166896, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.6403394255827368, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 6\n",
      "Fitness: 1.0407109260559082\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.05669275103529431, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=2.283953286287462, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t3 DefaultNodeGene(key=3, bias=-1.242454911423579, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t4 DefaultNodeGene(key=4, bias=-0.601721113606463, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t5 DefaultNodeGene(key=5, bias=0.5964337650762562, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t6 DefaultNodeGene(key=6, bias=2.176185665300897, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=1.0906448201827157, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=1.8134750207166896, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 3), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 5), weight=1.0, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 6), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.6403394255827368, enabled=True)\n",
      "\tDefaultConnectionGene(key=(0, 3), weight=-0.3701066217618221, enabled=True)\n",
      "\tDefaultConnectionGene(key=(0, 5), weight=-1.1972958561094662, enabled=True)\n",
      "\tDefaultConnectionGene(key=(3, 1), weight=1.8134750207166896, enabled=True)\n",
      "\tDefaultConnectionGene(key=(4, 0), weight=1.0906448201827157, enabled=True)\n",
      "\tDefaultConnectionGene(key=(4, 6), weight=-0.899410082400078, enabled=True)\n",
      "\tDefaultConnectionGene(key=(5, 1), weight=1.8134750207166896, enabled=True)\n",
      "\tDefaultConnectionGene(key=(5, 3), weight=-0.2849532481902134, enabled=True)\n",
      "\tDefaultConnectionGene(key=(6, 3), weight=-1.0150796089907899, enabled=True)\n",
      "\tDefaultConnectionGene(key=(6, 5), weight=1.0, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.add_connection(p.config.genome_config, 16, 17, 0.2, True)\n",
    "# h.add_connection(p.config.genome_config, 17, 0, 0.2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 6\n",
      "Fitness: 1.0407109260559082\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.05669275103529431, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=2.283953286287462, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t3 DefaultNodeGene(key=3, bias=-1.242454911423579, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t4 DefaultNodeGene(key=4, bias=-0.601721113606463, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t5 DefaultNodeGene(key=5, bias=0.5964337650762562, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "\t6 DefaultNodeGene(key=6, bias=2.176185665300897, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=1.0906448201827157, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 1), weight=1.8134750207166896, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 3), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 5), weight=1.0, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-2, 6), weight=1.0, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.6403394255827368, enabled=True)\n",
      "\tDefaultConnectionGene(key=(0, 3), weight=-0.3701066217618221, enabled=True)\n",
      "\tDefaultConnectionGene(key=(0, 5), weight=-1.1972958561094662, enabled=True)\n",
      "\tDefaultConnectionGene(key=(3, 1), weight=1.8134750207166896, enabled=True)\n",
      "\tDefaultConnectionGene(key=(4, 0), weight=1.0906448201827157, enabled=True)\n",
      "\tDefaultConnectionGene(key=(4, 6), weight=-0.899410082400078, enabled=True)\n",
      "\tDefaultConnectionGene(key=(5, 1), weight=1.8134750207166896, enabled=True)\n",
      "\tDefaultConnectionGene(key=(5, 3), weight=-0.2849532481902134, enabled=True)\n",
      "\tDefaultConnectionGene(key=(6, 3), weight=-1.0150796089907899, enabled=True)\n",
      "\tDefaultConnectionGene(key=(6, 5), weight=1.0, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[-1, -2]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.config.genome_config.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: <neat.genes.DefaultNodeGene at 0x7fa7c882abe0>,\n 1: <neat.genes.DefaultNodeGene at 0x7fa7c882aca0>,\n 3: <neat.genes.DefaultNodeGene at 0x7fa7c8830430>,\n 4: <neat.genes.DefaultNodeGene at 0x7fa7c8830d00>,\n 5: <neat.genes.DefaultNodeGene at 0x7fa7c8830e20>,\n 6: <neat.genes.DefaultNodeGene at 0x7fa7c8830f40>}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_tracker = {node_id:{'depth':0, 'output_ids':[], 'input_ids':[]} for node_id in h.nodes}\n",
    "for node_id in p.config.genome_config.input_keys:\n",
    "    node_tracker[node_id] = {'depth':0, 'output_ids':[], 'input_ids':[]}\n",
    "trace_stack = [node_id for node_id in p.config.genome_config.input_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[-1, -2]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {'depth': 0, 'output_ids': [], 'input_ids': []},\n 1: {'depth': 0, 'output_ids': [], 'input_ids': []},\n 3: {'depth': 0, 'output_ids': [], 'input_ids': []},\n 4: {'depth': 0, 'output_ids': [], 'input_ids': []},\n 5: {'depth': 0, 'output_ids': [], 'input_ids': []},\n 6: {'depth': 0, 'output_ids': [], 'input_ids': []},\n -1: {'depth': 0, 'output_ids': [], 'input_ids': []},\n -2: {'depth': 0, 'output_ids': [], 'input_ids': []}}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 0)\n",
      "(-2, 0)\n",
      "(-2, 1)\n",
      "(-2, 3)\n",
      "(3, 1)\n",
      "(-2, 4)\n",
      "(4, 0)\n",
      "(-2, 5)\n",
      "(5, 1)\n",
      "(-2, 6)\n",
      "(6, 5)\n",
      "(5, 3)\n",
      "(0, 5)\n",
      "(0, 3)\n",
      "(4, 6)\n",
      "(6, 3)\n"
     ]
    }
   ],
   "source": [
    "for connection in h.connections:\n",
    "    print(connection)\n",
    "    node_tracker[connection[0]]['output_ids'].append(connection[1])\n",
    "    node_tracker[connection[1]]['input_ids'].append(connection[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(trace_stack) > 0:\n",
    "    trace = trace_stack[0]\n",
    "    my_depth = node_tracker[trace]['depth']\n",
    "    next_depth = my_depth + 1\n",
    "    for output_id in node_tracker[trace]['output_ids']:\n",
    "        node_tracker[output_id]['depth'] = max(node_tracker[output_id]['depth'], next_depth)\n",
    "        trace_stack.append(output_id)\n",
    "    del(trace_stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {'depth': 2, 'output_ids': [5, 3], 'input_ids': [-1, -2, 4]},\n 1: {'depth': 5, 'output_ids': [], 'input_ids': [-2, 3, 5]},\n 3: {'depth': 4, 'output_ids': [1], 'input_ids': [-2, 5, 0, 6]},\n 4: {'depth': 1, 'output_ids': [0, 6], 'input_ids': [-2]},\n 5: {'depth': 3, 'output_ids': [1, 3], 'input_ids': [-2, 6, 0]},\n 6: {'depth': 2, 'output_ids': [5, 3], 'input_ids': [-2, 4]},\n -1: {'depth': 0, 'output_ids': [0], 'input_ids': []},\n -2: {'depth': 0, 'output_ids': [0, 1, 3, 4, 5, 6], 'input_ids': []}}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['output_layers']=[]\n",
    "    node['needs_skip'] = False\n",
    "    node['id'] = node_id\n",
    "    for output_id in node['output_ids']:\n",
    "        node['output_layers'].append(node_tracker[output_id]['depth'])\n",
    "        if node_tracker[output_id]['depth'] > (node['depth']+1):\n",
    "            node['needs_skip'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['input_layers'] = []\n",
    "    node['skip_layer_input'] = False\n",
    "    for input_id in node['input_ids']:\n",
    "        node['input_layers'].append(node_tracker[input_id]['depth'])\n",
    "        if node_tracker[input_id]['depth'] < (node['depth']-1):\n",
    "            node['skip_layer_input'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {'depth': 2,\n  'output_ids': [5, 3],\n  'input_ids': [-1, -2, 4],\n  'output_layers': [3, 4],\n  'needs_skip': True,\n  'id': 0,\n  'input_layers': [0, 0, 1],\n  'skip_layer_input': True},\n 1: {'depth': 5,\n  'output_ids': [],\n  'input_ids': [-2, 3, 5],\n  'output_layers': [],\n  'needs_skip': False,\n  'id': 1,\n  'input_layers': [0, 4, 3],\n  'skip_layer_input': True},\n 3: {'depth': 4,\n  'output_ids': [1],\n  'input_ids': [-2, 5, 0, 6],\n  'output_layers': [5],\n  'needs_skip': False,\n  'id': 3,\n  'input_layers': [0, 3, 2, 2],\n  'skip_layer_input': True},\n 4: {'depth': 1,\n  'output_ids': [0, 6],\n  'input_ids': [-2],\n  'output_layers': [2, 2],\n  'needs_skip': False,\n  'id': 4,\n  'input_layers': [0],\n  'skip_layer_input': False},\n 5: {'depth': 3,\n  'output_ids': [1, 3],\n  'input_ids': [-2, 6, 0],\n  'output_layers': [5, 4],\n  'needs_skip': True,\n  'id': 5,\n  'input_layers': [0, 2, 2],\n  'skip_layer_input': True},\n 6: {'depth': 2,\n  'output_ids': [5, 3],\n  'input_ids': [-2, 4],\n  'output_layers': [3, 4],\n  'needs_skip': True,\n  'id': 6,\n  'input_layers': [0, 1],\n  'skip_layer_input': True},\n -1: {'depth': 0,\n  'output_ids': [0],\n  'input_ids': [],\n  'output_layers': [2],\n  'needs_skip': True,\n  'id': -1,\n  'input_layers': [],\n  'skip_layer_input': False},\n -2: {'depth': 0,\n  'output_ids': [0, 1, 3, 4, 5, 6],\n  'input_ids': [],\n  'output_layers': [2, 5, 4, 1, 3, 2],\n  'needs_skip': True,\n  'id': -2,\n  'input_layers': [],\n  'skip_layer_input': False}}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{2: {'nodes': {0: {'depth': 2,\n    'output_ids': [5, 3],\n    'input_ids': [-1, -2, 4],\n    'output_layers': [3, 4],\n    'needs_skip': True,\n    'id': 0,\n    'input_layers': [0, 0, 1],\n    'skip_layer_input': True,\n    'layer_index': 0},\n   6: {'depth': 2,\n    'output_ids': [5, 3],\n    'input_ids': [-2, 4],\n    'output_layers': [3, 4],\n    'needs_skip': True,\n    'id': 6,\n    'input_layers': [0, 1],\n    'skip_layer_input': True,\n    'layer_index': 1}}},\n 5: {'nodes': {1: {'depth': 5,\n    'output_ids': [],\n    'input_ids': [-2, 3, 5],\n    'output_layers': [],\n    'needs_skip': False,\n    'id': 1,\n    'input_layers': [0, 4, 3],\n    'skip_layer_input': True,\n    'layer_index': 0}}},\n 4: {'nodes': {3: {'depth': 4,\n    'output_ids': [1],\n    'input_ids': [-2, 5, 0, 6],\n    'output_layers': [5],\n    'needs_skip': False,\n    'id': 3,\n    'input_layers': [0, 3, 2, 2],\n    'skip_layer_input': True,\n    'layer_index': 0}}},\n 1: {'nodes': {4: {'depth': 1,\n    'output_ids': [0, 6],\n    'input_ids': [-2],\n    'output_layers': [2, 2],\n    'needs_skip': False,\n    'id': 4,\n    'input_layers': [0],\n    'skip_layer_input': False,\n    'layer_index': 0}}},\n 3: {'nodes': {5: {'depth': 3,\n    'output_ids': [1, 3],\n    'input_ids': [-2, 6, 0],\n    'output_layers': [5, 4],\n    'needs_skip': True,\n    'id': 5,\n    'input_layers': [0, 2, 2],\n    'skip_layer_input': True,\n    'layer_index': 0}}},\n 0: {'nodes': {-1: {'depth': 0,\n    'output_ids': [0],\n    'input_ids': [],\n    'output_layers': [2],\n    'needs_skip': True,\n    'id': -1,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 0},\n   -2: {'depth': 0,\n    'output_ids': [0, 1, 3, 4, 5, 6],\n    'input_ids': [],\n    'output_layers': [2, 5, 4, 1, 3, 2],\n    'needs_skip': True,\n    'id': -2,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 1}}}}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = {}\n",
    "for node_id, node in node_tracker.items():\n",
    "    if not node['depth'] in layers:\n",
    "        layers[node['depth']] = {\n",
    "            'nodes':{node_id:node}\n",
    "        }\n",
    "    else:\n",
    "        layers[node['depth']]['nodes'][node_id] = node\n",
    "        \n",
    "# Ensure all nodes have a layer index\n",
    "for layer_id, layer in layers.items():\n",
    "    layer_index = 0\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "        \n",
    "        \n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my layer id is 2\n",
      "DefaultConnectionGene(key=(-1, 0), weight=0.6403394255827368, enabled=True)\n",
      "0.6403394255827368\n",
      "location is\n",
      "(0, 0)\n",
      "DefaultConnectionGene(key=(-2, 0), weight=1.0906448201827157, enabled=False)\n",
      "DefaultConnectionGene(key=(-2, 6), weight=1.0, enabled=True)\n",
      "1.0\n",
      "location is\n",
      "(1, 1)\n",
      "DefaultConnectionGene(key=(4, 0), weight=1.0906448201827157, enabled=True)\n",
      "1.0906448201827157\n",
      "location is\n",
      "(0, 2)\n",
      "DefaultConnectionGene(key=(4, 6), weight=-0.899410082400078, enabled=True)\n",
      "-0.899410082400078\n",
      "location is\n",
      "(1, 2)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-aa11e4917545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Handle generic case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out_weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in_weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-aa11e4917545>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Handle generic case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out_weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in_weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": [
    "\n",
    "LAYER_TYPE_CONNECTED = \"CONNECTED\"\n",
    "LAYER_TYPE_INPUT = \"INPUT\"\n",
    "LAYER_TYPE_OUTPUT = \"OUTPUT\"\n",
    "for layer_id, layer in layers.items():\n",
    "    layer['is_output_layer'] = False\n",
    "    layer['is_input_layer'] = False\n",
    "    layer['layer_type'] = LAYER_TYPE_CONNECTED\n",
    "    # If I have the output node in me, then I am an output\n",
    "    if 0 in layer['nodes']:\n",
    "        layer['is_output_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_OUTPUT\n",
    "\n",
    "    # If I have the first input in me, then I am the input\n",
    "    if -1 in layer['nodes']:\n",
    "        layer['is_input_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_INPUT\n",
    "    biases = []\n",
    "\n",
    "    layer['input_layers'] = []\n",
    "    ## Compute the shape of required inputs\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        for in_layer in node['input_layers']:\n",
    "            if in_layer not in layer['input_layers']:\n",
    "                layer['input_layers'].append(in_layer)\n",
    "    layer['input_layers'].sort()\n",
    "    layer['input_shape'] = sum(len(layers[jj]['nodes']) for jj in layer['input_layers'])\n",
    "    layer['weights_shape'] = (layer['input_shape'], len(layer['nodes']))\n",
    "\n",
    "\n",
    "    # Handle output layer \"edge\" case\n",
    "    if layer['is_output_layer']:\n",
    "        layer['out_weights'] = []\n",
    "        layer['bias'] = [h.nodes[node_id].bias for node_id, node in layer['nodes'].items()]\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle input layer \"edge\" case\n",
    "    elif layer['is_input_layer']:\n",
    "        layer['in_weights'] = []\n",
    "        layer['bias'] = []\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle generic case\n",
    "    else:\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "\n",
    "        layer['bias'] = [h.nodes[node_id].bias for node_id, node in layer['nodes'].items()]\n",
    "        # else:\n",
    "            # layer['bias'] = [0 for _ in layer['nodes']]\n",
    "    \n",
    "    layer_index = 0          \n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "        ### POSSIBLY NEED THIS\n",
    "        # if node['id'] < 0:\n",
    "        #     biases.append(1)\n",
    "        # else:\n",
    "        #     biases.append(h.nodes[node['id']].bias)\n",
    "        # for output_id in node['output_ids']:\n",
    "        #     if (node['id'], output_id) in h.connections:\n",
    "        #         if output_id in layers[layer_id + 1]['nodes']:\n",
    "        #             layer['out_weights'][node['layer_index']][layers[layer_id + 1]['nodes'][output_id]['layer_index']] = h.connections[(node['id'], output_id)].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        # for input_id in node['input_ids']:\n",
    "        #     if (input_id, node['id']) in h.connections:\n",
    "        #         if input_id in layers[layer_id - 1]['nodes']:\n",
    "        #             layer['in_weights'][node['layer_index']][layers[layer_id -1]['nodes'][input_id]['layer_index']] = h.connections[(input_id, node['id'])].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        #################################################\n",
    "            ### END OF POSSIBLY NEEDING THIS\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "\n",
    "\n",
    "    # layer['out_tensor'] = torch.tensor(layer['out_weights'])\n",
    "    # layer['bias'] = torch.tensor(layer['bias'])\n",
    "    # layer['out_tensor_shape'] = layer['out_tensor'].shape\n",
    "    # layer['in_tensor'] = torch.tensor(layer['in_weights'])\n",
    "    # layer['in_tensor_shape'] = layer['in_tensor'].shape\n",
    "\n",
    "\n",
    "\n",
    "    # Set up current weights\n",
    "    layer['input_weights'] = np.zeros(layer['weights_shape'])\n",
    "    layer_offset = 0\n",
    "    # Check every layer and every node for connections\n",
    "    print(\"my layer id is %s\" % (layer_id))\n",
    "    for input_layer_id in layer['input_layers']:\n",
    "        input_layer = layers[input_layer_id]\n",
    "        for node_id, node in input_layer['nodes'].items():\n",
    "            for node_output_id in node['output_ids']:\n",
    "                if node_output_id in layer['nodes']:\n",
    "                    node_output = layer['nodes'][node_output_id]\n",
    "                    # I HAVE THIS NODE!\n",
    "                    # What is it's weight?\n",
    "                    connection = h.connections[(node_id, node_output_id)]\n",
    "                    print(connection)\n",
    "\n",
    "                    if not connection.enabled:\n",
    "                        continue\n",
    "                    connection_weight = connection.weight\n",
    "                    print(connection_weight)\n",
    "\n",
    "                    in_weight_location = layer_offset + node['layer_index']\n",
    "                    out_weight_location = node_output['layer_index']\n",
    "                    print('location is')\n",
    "                    print((out_weight_location, in_weight_location))\n",
    "                    layer['input_weights'][in_weight_location][out_weight_location] = connection_weight\n",
    "        layer_offset += len(input_layer['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{5: {'nodes': {0: {'depth': 5,\n    'output_ids': [],\n    'input_ids': [-2, 2, 4],\n    'output_layers': [],\n    'needs_skip': False,\n    'id': 0,\n    'input_layers': [0, 4, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': True,\n  'is_input_layer': False,\n  'layer_type': 'OUTPUT',\n  'input_layers': [0, 1, 4],\n  'input_shape': 4,\n  'weights_shape': (4, 1),\n  'out_weights': [],\n  'bias': [-0.32540032267570496],\n  'in_weights': [[0]],\n  'input_weights': array([[0.        ],\n         [0.        ],\n         [0.14471313],\n         [0.14471313]])},\n 4: {'nodes': {2: {'depth': 4,\n    'output_ids': [0],\n    'input_ids': [-2, 3, -1],\n    'output_layers': [5],\n    'needs_skip': False,\n    'id': 2,\n    'input_layers': [0, 3, 0],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 3],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [-0.9946926512595049],\n  'input_weights': array([[-0.19788816],\n         [ 0.        ],\n         [ 1.        ]])},\n 3: {'nodes': {3: {'depth': 3,\n    'output_ids': [2],\n    'input_ids': [-2, 5],\n    'output_layers': [4],\n    'needs_skip': False,\n    'id': 3,\n    'input_layers': [0, 2],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 2],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [1.3604229232680916],\n  'input_weights': array([[0.],\n         [0.],\n         [1.]])},\n 1: {'nodes': {4: {'depth': 1,\n    'output_ids': [0, 5],\n    'input_ids': [-2],\n    'output_layers': [5, 2],\n    'needs_skip': True,\n    'id': 4,\n    'input_layers': [0],\n    'skip_layer_input': False,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0],\n  'input_shape': 2,\n  'weights_shape': (2, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0, 0]],\n  'bias': [-0.7886409709284502],\n  'input_weights': array([[0.],\n         [1.]])},\n 2: {'nodes': {5: {'depth': 2,\n    'output_ids': [3],\n    'input_ids': [-2, 4],\n    'output_layers': [3],\n    'needs_skip': False,\n    'id': 5,\n    'input_layers': [0, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 1],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [0.28752704139344826],\n  'input_weights': array([[ 0.        ],\n         [ 1.        ],\n         [-1.04658333]])},\n 0: {'nodes': {-1: {'depth': 0,\n    'output_ids': [2],\n    'input_ids': [],\n    'output_layers': [4],\n    'needs_skip': True,\n    'id': -1,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 0},\n   -2: {'depth': 0,\n    'output_ids': [0, 2, 3, 4, 5],\n    'input_ids': [],\n    'output_layers': [5, 4, 3, 1, 2],\n    'needs_skip': True,\n    'id': -2,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 1}},\n  'is_output_layer': False,\n  'is_input_layer': True,\n  'layer_type': 'INPUT',\n  'input_layers': [],\n  'input_shape': 0,\n  'weights_shape': (0, 2),\n  'in_weights': [],\n  'bias': [],\n  'out_weights': [[0], [0]],\n  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in computation of skip layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'nodes': {5: {'depth': 2,\n   'output_ids': [3],\n   'input_ids': [-2, 4],\n   'output_layers': [3],\n   'needs_skip': False,\n   'id': 5,\n   'input_layers': [0, 1],\n   'skip_layer_input': True,\n   'layer_index': 0}},\n 'is_output_layer': False,\n 'is_input_layer': False,\n 'layer_type': 'CONNECTED',\n 'input_layers': [0, 1],\n 'input_shape': 3,\n 'weights_shape': (3, 1),\n 'out_weights': [[0]],\n 'in_weights': [[0]],\n 'bias': [0.28752704139344826],\n 'input_weights': array([[ 0.        ],\n        [ 1.        ],\n        [-1.04658333]])}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{5: {'nodes': {0: {'depth': 5,\n    'output_ids': [],\n    'input_ids': [-2, 2, 4],\n    'output_layers': [],\n    'needs_skip': False,\n    'id': 0,\n    'input_layers': [0, 4, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': True,\n  'is_input_layer': False,\n  'layer_type': 'OUTPUT',\n  'input_layers': [0, 1, 4],\n  'input_shape': 4,\n  'weights_shape': (4, 1),\n  'out_weights': [],\n  'bias': [-0.32540032267570496],\n  'in_weights': [[0]],\n  'input_weights': array([[0.        ],\n         [0.        ],\n         [0.14471313],\n         [0.14471313]])},\n 4: {'nodes': {2: {'depth': 4,\n    'output_ids': [0],\n    'input_ids': [-2, 3, -1],\n    'output_layers': [5],\n    'needs_skip': False,\n    'id': 2,\n    'input_layers': [0, 3, 0],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 3],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [-0.9946926512595049],\n  'input_weights': array([[-0.19788816],\n         [ 0.        ],\n         [ 1.        ]])},\n 3: {'nodes': {3: {'depth': 3,\n    'output_ids': [2],\n    'input_ids': [-2, 5],\n    'output_layers': [4],\n    'needs_skip': False,\n    'id': 3,\n    'input_layers': [0, 2],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 2],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [1.3604229232680916],\n  'input_weights': array([[0.],\n         [0.],\n         [1.]])},\n 1: {'nodes': {4: {'depth': 1,\n    'output_ids': [0, 5],\n    'input_ids': [-2],\n    'output_layers': [5, 2],\n    'needs_skip': True,\n    'id': 4,\n    'input_layers': [0],\n    'skip_layer_input': False,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0],\n  'input_shape': 2,\n  'weights_shape': (2, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0, 0]],\n  'bias': [-0.7886409709284502],\n  'input_weights': array([[0.],\n         [1.]])},\n 2: {'nodes': {5: {'depth': 2,\n    'output_ids': [3],\n    'input_ids': [-2, 4],\n    'output_layers': [3],\n    'needs_skip': False,\n    'id': 5,\n    'input_layers': [0, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 1],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [0.28752704139344826],\n  'input_weights': array([[ 0.        ],\n         [ 1.        ],\n         [-1.04658333]])},\n 0: {'nodes': {-1: {'depth': 0,\n    'output_ids': [2],\n    'input_ids': [],\n    'output_layers': [4],\n    'needs_skip': True,\n    'id': -1,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 0},\n   -2: {'depth': 0,\n    'output_ids': [0, 2, 3, 4, 5],\n    'input_ids': [],\n    'output_layers': [5, 4, 3, 1, 2],\n    'needs_skip': True,\n    'id': -2,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 1}},\n  'is_output_layer': False,\n  'is_input_layer': True,\n  'layer_type': 'INPUT',\n  'input_layers': [],\n  'input_shape': 0,\n  'weights_shape': (0, 2),\n  'in_weights': [],\n  'bias': [],\n  'out_weights': [[0], [0]],\n  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is, how do you code the operations to dynamically create the\n",
    "NN? You need to be able to do the right things in the right order. You have\n",
    "a list of possible operations:\n",
    "* Matrix multiple\n",
    "* Concatenate (for skip layers)\n",
    "* Matrix addition (for biases)\n",
    "* Output\n",
    "\n",
    "The order of operations in each layer is:\n",
    "\n",
    "1. Concatenate input tensors\n",
    "2. Matrix multiply input tensors with weights\n",
    "3. Add bias tensors\n",
    "4. Apply activation function\n",
    "\n",
    "I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "These computations can be computed back-to-front, and then executed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': {-1: {'depth': 0, 'output_ids': [2], 'input_ids': [], 'output_layers': [4], 'needs_skip': True, 'id': -1, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 0}, -2: {'depth': 0, 'output_ids': [0, 2, 3, 4, 5], 'input_ids': [], 'output_layers': [5, 4, 3, 1, 2], 'needs_skip': True, 'id': -2, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 1}}, 'is_output_layer': False, 'is_input_layer': True, 'layer_type': 'INPUT', 'input_layers': [], 'input_shape': 0, 'weights_shape': (0, 2), 'in_weights': [], 'bias': [], 'out_weights': [[0], [0]], 'input_weights': array([], shape=(0, 2), dtype=float64)}\n",
      "{'nodes': {4: {'depth': 1, 'output_ids': [0, 5], 'input_ids': [-2], 'output_layers': [5, 2], 'needs_skip': True, 'id': 4, 'input_layers': [0], 'skip_layer_input': False, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0], 'input_shape': 2, 'weights_shape': (2, 1), 'out_weights': [[0]], 'in_weights': [[0, 0]], 'bias': [-0.7886409709284502], 'input_weights': array([[0.],\n",
      "       [1.]])}\n",
      "{'nodes': {5: {'depth': 2, 'output_ids': [3], 'input_ids': [-2, 4], 'output_layers': [3], 'needs_skip': False, 'id': 5, 'input_layers': [0, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0, 1], 'input_shape': 3, 'weights_shape': (3, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [0.28752704139344826], 'input_weights': array([[ 0.        ],\n",
      "       [ 1.        ],\n",
      "       [-1.04658333]])}\n",
      "{'nodes': {3: {'depth': 3, 'output_ids': [2], 'input_ids': [-2, 5], 'output_layers': [4], 'needs_skip': False, 'id': 3, 'input_layers': [0, 2], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0, 2], 'input_shape': 3, 'weights_shape': (3, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [1.3604229232680916], 'input_weights': array([[0.],\n",
      "       [0.],\n",
      "       [1.]])}\n",
      "{'nodes': {2: {'depth': 4, 'output_ids': [0], 'input_ids': [-2, 3, -1], 'output_layers': [5], 'needs_skip': False, 'id': 2, 'input_layers': [0, 3, 0], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'layer_type': 'CONNECTED', 'input_layers': [0, 3], 'input_shape': 3, 'weights_shape': (3, 1), 'out_weights': [[0]], 'in_weights': [[0]], 'bias': [-0.9946926512595049], 'input_weights': array([[-0.19788816],\n",
      "       [ 0.        ],\n",
      "       [ 1.        ]])}\n",
      "{'nodes': {0: {'depth': 5, 'output_ids': [], 'input_ids': [-2, 2, 4], 'output_layers': [], 'needs_skip': False, 'id': 0, 'input_layers': [0, 4, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': True, 'is_input_layer': False, 'layer_type': 'OUTPUT', 'input_layers': [0, 1, 4], 'input_shape': 4, 'weights_shape': (4, 1), 'out_weights': [], 'bias': [-0.32540032267570496], 'in_weights': [[0]], 'input_weights': array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.14471313],\n",
      "       [0.14471313]])}\n"
     ]
    }
   ],
   "source": [
    "ACTIVATE_OPERATION = \"ACTIVATE\"\n",
    "OUTPUT_OPERATION = \"OUTPUT\"\n",
    "TENADD_OPERATION = \"TENADD\" # Tensor ADD\n",
    "ADD_BIAS_OPERATION = \"BIASADD\"\n",
    "TENMUL_OPERATION = \"TENMUL\"\n",
    "TENCAT_OPERATION = \"TENCAT\"\n",
    "order_of_operations = []\n",
    "\n",
    "# for layer_id, layer in layers.items():\n",
    "#     print(layer)\n",
    "#     # Output for final layer\n",
    "#     if layer['is_output_layer']:\n",
    "#         order_of_operations.append(OUTPUT_OPERATION)\n",
    "#     # Activate\n",
    "#     order_of_operations.append(ACTIVATE_OPERATION)\n",
    "#     # Add Bias\n",
    "#     order_of_operations.append(ADD_BIAS_OPERATION)\n",
    "#     # Matrix Multiply weights\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     print(order_of_operations)\n",
    "\n",
    "#     break\n",
    "\n",
    "for layer_id in range(len(layers)):\n",
    "    layer = layers[layer_id]\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(3, 1)\n",
    "c = torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0890],\n        [ 1.7597]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{5: {'nodes': {0: {'depth': 5,\n    'output_ids': [],\n    'input_ids': [-2, 2, 4],\n    'output_layers': [],\n    'needs_skip': False,\n    'id': 0,\n    'input_layers': [0, 4, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': True,\n  'is_input_layer': False,\n  'layer_type': 'OUTPUT',\n  'input_layers': [0, 1, 4],\n  'input_shape': 4,\n  'weights_shape': (4, 1),\n  'out_weights': [],\n  'bias': [-0.32540032267570496],\n  'in_weights': [[0]],\n  'input_weights': array([[0.        ],\n         [0.        ],\n         [0.14471313],\n         [0.14471313]])},\n 4: {'nodes': {2: {'depth': 4,\n    'output_ids': [0],\n    'input_ids': [-2, 3, -1],\n    'output_layers': [5],\n    'needs_skip': False,\n    'id': 2,\n    'input_layers': [0, 3, 0],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 3],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [-0.9946926512595049],\n  'input_weights': array([[-0.19788816],\n         [ 0.        ],\n         [ 1.        ]])},\n 3: {'nodes': {3: {'depth': 3,\n    'output_ids': [2],\n    'input_ids': [-2, 5],\n    'output_layers': [4],\n    'needs_skip': False,\n    'id': 3,\n    'input_layers': [0, 2],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 2],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [1.3604229232680916],\n  'input_weights': array([[0.],\n         [0.],\n         [1.]])},\n 1: {'nodes': {4: {'depth': 1,\n    'output_ids': [0, 5],\n    'input_ids': [-2],\n    'output_layers': [5, 2],\n    'needs_skip': True,\n    'id': 4,\n    'input_layers': [0],\n    'skip_layer_input': False,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0],\n  'input_shape': 2,\n  'weights_shape': (2, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0, 0]],\n  'bias': [-0.7886409709284502],\n  'input_weights': array([[0.],\n         [1.]])},\n 2: {'nodes': {5: {'depth': 2,\n    'output_ids': [3],\n    'input_ids': [-2, 4],\n    'output_layers': [3],\n    'needs_skip': False,\n    'id': 5,\n    'input_layers': [0, 1],\n    'skip_layer_input': True,\n    'layer_index': 0}},\n  'is_output_layer': False,\n  'is_input_layer': False,\n  'layer_type': 'CONNECTED',\n  'input_layers': [0, 1],\n  'input_shape': 3,\n  'weights_shape': (3, 1),\n  'out_weights': [[0]],\n  'in_weights': [[0]],\n  'bias': [0.28752704139344826],\n  'input_weights': array([[ 0.        ],\n         [ 1.        ],\n         [-1.04658333]])},\n 0: {'nodes': {-1: {'depth': 0,\n    'output_ids': [2],\n    'input_ids': [],\n    'output_layers': [4],\n    'needs_skip': True,\n    'id': -1,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 0},\n   -2: {'depth': 0,\n    'output_ids': [0, 2, 3, 4, 5],\n    'input_ids': [],\n    'output_layers': [5, 4, 3, 1, 2],\n    'needs_skip': True,\n    'id': -2,\n    'input_layers': [],\n    'skip_layer_input': False,\n    'layer_index': 1}},\n  'is_output_layer': False,\n  'is_input_layer': True,\n  'layer_type': 'INPUT',\n  'input_layers': [],\n  'input_shape': 0,\n  'weights_shape': (0, 2),\n  'in_weights': [],\n  'bias': [],\n  'out_weights': [[0], [0]],\n  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = nn.Parameter(torch.tensor([0.3, 0.4], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Net, self).__init__()  # just run the init of parent class (nn.Module)\n",
    "        self.weights = {layer_id: self._tt(layer['input_weights'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.biases = {layer_id: self._tt(layer['bias'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.layer_types = {layer_id: layer['layer_type'] for layer_id, layer in layers.items()}\n",
    "        self.layer_inputs = {layer_id: layer['input_layers'] for layer_id, layer in layers.items()}\n",
    "        self.n_layers = len(layers)\n",
    "\n",
    "        self._outputs = None\n",
    "\n",
    "        for w_id, w in self.weights.items():\n",
    "            self.register_parameter(name =\"weight_%s\"%w_id, param=w)\n",
    "\n",
    "        for b_id, b in self.biases.items():\n",
    "            self.register_parameter(name = \"bias_%s\"%b_id, param=b)\n",
    "\n",
    "        # x = F.relu(self.fc1(x))\n",
    "\n",
    "        # self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tt(mat):\n",
    "        return torch.nn.Parameter(torch.tensor(mat,dtype=torch.float64), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        # print(\"running forward\")\n",
    "        self._outputs = {}\n",
    "        for layer_id in range(self.n_layers):\n",
    "            layer_input = None\n",
    "            layer_type = self.layer_types[layer_id]\n",
    "\n",
    "            # print(layer_id)\n",
    "            # print(layer_type)\n",
    "\n",
    "            if layer_type == LAYER_TYPE_INPUT:\n",
    "                self._outputs[layer_id] = x\n",
    "                continue\n",
    "            if layer_type == LAYER_TYPE_CONNECTED:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "\n",
    "            # print(layer_input)\n",
    "            # print(self.weights[layer_id])\n",
    "            # print(self.biases[layer_id])\n",
    "\n",
    "            self._outputs[layer_id] = torch.sigmoid( torch.matmul(layer_input, self.weights[layer_id]) + self.biases[layer_id] )\n",
    "\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                return self._outputs[layer_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{5: Parameter containing:\n tensor([-0.3254], dtype=torch.float64, requires_grad=True),\n 4: Parameter containing:\n tensor([-0.9947], dtype=torch.float64, requires_grad=True),\n 3: Parameter containing:\n tensor([1.3604], dtype=torch.float64, requires_grad=True),\n 1: Parameter containing:\n tensor([-0.7886], dtype=torch.float64, requires_grad=True),\n 2: Parameter containing:\n tensor([0.2875], dtype=torch.float64, requires_grad=True),\n 0: Parameter containing:\n tensor([], dtype=torch.float64, requires_grad=True)}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "net._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.4499], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = net.forward(x_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_result = torch.tensor(xor(x_input[0], x_input[1]))\n",
    "expected_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function - benchmark - has just started at 1628331614.001492\n",
      "The function - benchmark - took 5.811469078063965 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "# x_input = torch.randn(1, 1, 2, dtype=torch.float64)\n",
    "with MethodTimer('benchmark'):\n",
    "\n",
    "    for k in range(25):\n",
    "        for n in range(400):\n",
    "            x_input = nn.Parameter(torch.tensor([np.random.rand(), np.random.rand()], dtype=torch.float64))\n",
    "\n",
    "\n",
    "            result = net.forward(x_input)\n",
    "            expected_result = torch.tensor(xor(x_input[0], x_input[1]), dtype=torch.float64)\n",
    "            # print(x_input)\n",
    "            # print(expected_result)\n",
    "            # print(result)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(result, expected_result)\n",
    "            net.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                # for parameter in net.parameters():\n",
    "                    # parameter.data -= learning_rate*parameter.grad.data\n",
    "                    # weight -= learning_rate * weight.grad\n",
    "                for  w_id, weight in net.weights.items():\n",
    "                    try:\n",
    "                        weight -= learning_rate * weight.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "                for  b_id, bias in net.biases.items():\n",
    "                    try:\n",
    "                        bias -= learning_rate * bias.grad\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(torch.tensor(xor_inputs, dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0192], dtype=torch.float64)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.biases[1].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.5588], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "output = net(x_input)\n",
    "loss = loss_fn(result, expected_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0763],\n",
      "        [-0.0542],\n",
      "        [ 0.3221],\n",
      "        [ 0.2249]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3051],\n",
      "        [-0.1099],\n",
      "        [ 0.7828]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0032],\n",
      "        [-0.0108],\n",
      "        [ 0.9855]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3092],\n",
      "        [ 0.8493]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0013],\n",
      "        [ 0.9976],\n",
      "        [-1.0488]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0632], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.2436], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.3353], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.0654], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2816], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "myW = net.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.3092],\n        [ 0.8493]], dtype=torch.float64, requires_grad=True)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3123, dtype=torch.float64, grad_fn=<MseLossBackward>)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0763],\n",
      "        [-0.0542],\n",
      "        [ 0.3221],\n",
      "        [ 0.2249]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3051],\n",
      "        [-0.1099],\n",
      "        [ 0.7828]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0032],\n",
      "        [-0.0108],\n",
      "        [ 0.9855]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3092],\n",
      "        [ 0.8493]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0013],\n",
      "        [ 0.9976],\n",
      "        [-1.0488]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0632], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.2436], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.3353], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.0654], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2816], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{5: Parameter containing:\n tensor([[-0.0763],\n         [-0.0542],\n         [ 0.3221],\n         [ 0.2249]], dtype=torch.float64, requires_grad=True),\n 4: Parameter containing:\n tensor([[-0.3051],\n         [-0.1099],\n         [ 0.7828]], dtype=torch.float64, requires_grad=True),\n 3: Parameter containing:\n tensor([[-0.0032],\n         [-0.0108],\n         [ 0.9855]], dtype=torch.float64, requires_grad=True),\n 1: Parameter containing:\n tensor([[-0.3092],\n         [ 0.8493]], dtype=torch.float64, requires_grad=True),\n 2: Parameter containing:\n tensor([[ 0.0013],\n         [ 0.9976],\n         [-1.0488]], dtype=torch.float64, requires_grad=True),\n 0: Parameter containing:\n tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)}"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: Parameter containing:\n tensor([0.2507, 0.3610], dtype=torch.float64, requires_grad=True),\n 1: tensor([0.3023], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n 2: tensor([0.5806], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n 3: tensor([0.8702], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n 4: tensor([0.3366], dtype=torch.float64, grad_fn=<SigmoidBackward>),\n 5: tensor([0.5492], dtype=torch.float64, grad_fn=<SigmoidBackward>)}"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1, 1,2, dtype=torch.float64)\n",
    "label = [xor(val[0][0], val[0][1]) for val in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "def forward(layers, x):\n",
    "    layer_outputs = {}\n",
    "    curr_value = x\n",
    "    for ii in range(len(layers)):\n",
    "        print(ii)\n",
    "        layer = layers[ii]\n",
    "        if layer['is_output_layer']:\n",
    "            # return curr_value\n",
    "            return(layer_outputs)\n",
    "        input_layers = [layer_outputs[layer_id] for layer_id in layer['input_layers']]\n",
    "    return(layer_outputs)\n",
    "        # layer_outputs[ii] = torch.relu(\n",
    "        #     torch.add(\n",
    "        #         torch.matmul(\n",
    "        #             torch.cat(layer['input_layers']),\n",
    "        #             layer['weights']\n",
    "\n",
    "        #         ),\n",
    "        #         layer['bias']\n",
    "        #     )\n",
    "        # )\n",
    "        # curr_value = torch.sigmoid(torch.matmul(curr_value + layers[ii]['bias'], layers[ii]['out_tensor']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward(layers, x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-0.32540032267570496"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.nodes[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function - Parse NNEAT - has just started at 1628331620.060509\n",
      "The function - Parse NNEAT - took 0.0007951259613037109 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "with MethodTimer('Parse NNEAT'):\n",
    "    myNeat = nneat(h, p.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "myConnection = (-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(-1, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-d9dcbbed06f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmyConnection\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: (-1, 0)"
     ]
    }
   ],
   "source": [
    "h.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1703],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.1490]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.5530],\n",
      "        [0.5530]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.9151, 0.0000],\n",
      "        [1.0000, 1.0000]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0701],\n",
      "        [0.0000],\n",
      "        [1.0000]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.5281],\n",
      "        [0.0000],\n",
      "        [1.0000]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4007], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.2643], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.8664,  2.4587], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.1083], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0338], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in myNeat.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function - Backprop benchmark (10k inputs) - has just started at 1615095693.196116\n",
      "The function - Backprop benchmark (10k inputs) - took 0.0015311241149902344 seconds to complete\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-18162869a542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# print(expected_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mmyNeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2201\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \"\"\"\n\u001b[0;32m-> 2203\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m         warnings.warn(\"Using a target size ({}) that is different to the input size ({}). \"\n\u001b[1;32m   2205\u001b[0m                       \u001b[0;34m\"This will likely lead to incorrect results due to broadcasting. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "# x_input = torch.randn(1, 1, 2, dtype=torch.float64)\n",
    "with MethodTimer('Backprop benchmark (10k inputs)'):\n",
    "\n",
    "    for k in range(25):\n",
    "        for n in range(400):\n",
    "            x_input = nn.Parameter(torch.tensor([np.random.rand(), np.random.rand()], dtype=torch.float64))\n",
    "\n",
    "\n",
    "            result = myNeat.forward(x_input)\n",
    "            expected_result = torch.tensor([xor(x_input[0], x_input[1])], dtype=torch.float64)\n",
    "            # print(x_input)\n",
    "            # print(expected_result)\n",
    "            # print(result)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(result, expected_result)\n",
    "            myNeat.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for parameter in myNeat.parameters():\n",
    "                    try:\n",
    "                        parameter.data -= learning_rate*parameter.grad.data\n",
    "                    except AttributeError:\n",
    "                        continue\n",
    "                    # weight -= learning_rate * weight.grad\n",
    "                # for  w_id, weight in net.weights.items():\n",
    "                #     try:\n",
    "                #         # print(weight.grad)\n",
    "                #         weight -= learning_rate * weight.grad\n",
    "                #     except TypeError:\n",
    "                #         continue\n",
    "                # for  b_id, bias in net.biases.items():\n",
    "                #     try:\n",
    "                #         bias -= learning_rate * bias.grad\n",
    "                #     except TypeError:\n",
    "                #         continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.6434],\n",
      "        [ 1.2305],\n",
      "        [-0.4451],\n",
      "        [-0.3518],\n",
      "        [-0.3164]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.8560],\n",
      "        [-0.8797],\n",
      "        [-0.3112],\n",
      "        [-1.2250]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.8507, 0.0422],\n",
      "        [0.9348, 1.0279]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3604],\n",
      "        [-0.8499],\n",
      "        [ 0.4200]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1479],\n",
      "        [-1.3651],\n",
      "        [ 0.6890]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-3.3236], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.6114], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.0203,  2.5215], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-2.0045], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.4060], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in myNeat.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<neat.genome.DefaultGenome at 0x7fa16330a310>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.genome.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: Parameter containing:\n",
       " tensor([[-0.1393],\n",
       "         [ 0.2148],\n",
       "         [ 0.0367],\n",
       "         [-0.0018],\n",
       "         [ 0.1243]], dtype=torch.float64, requires_grad=True),\n",
       " 2: Parameter containing:\n",
       " tensor([[-0.1744],\n",
       "         [-0.1848],\n",
       "         [ 0.3618],\n",
       "         [ 0.1876]], dtype=torch.float64, requires_grad=True),\n",
       " 1: Parameter containing:\n",
       " tensor([[ 0.9029, -0.0036],\n",
       "         [ 0.9850,  0.9993]], dtype=torch.float64, requires_grad=True),\n",
       " 3: Parameter containing:\n",
       " tensor([[-0.0801],\n",
       "         [-0.2856],\n",
       "         [ 0.7472]], dtype=torch.float64, requires_grad=True),\n",
       " 4: Parameter containing:\n",
       " tensor([[ 0.3380],\n",
       "         [-0.3733],\n",
       "         [ 0.8678]], dtype=torch.float64, requires_grad=True),\n",
       " 0: Parameter containing:\n",
       " tensor([], size=(0, 2), dtype=torch.float64, requires_grad=True)}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNeat.update_genome_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1703117936849594"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.genome.connections[myConnection].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1393, dtype=torch.float64, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNeat.genome.connections[myConnection].new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}