{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import neat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from explaneat.core.backprop import NeatNet\n",
    "from explaneat.core import backprop\n",
    "from explaneat.core.backproppop import BackpropPopulation\n",
    "# from explaneat.visualization import visualize\n",
    "from explaneat.core.experiment import ExperimentReporter\n",
    "from explaneat.core.utility import one_hot_encode\n",
    "\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.preprocessing import StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED      = 42\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA = False\n",
    "device = torch.device(\"cuda:1\" if USE_CUDA else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xor(a, b, threshold = 0.5):\n",
    "    response = False\n",
    "    if a > threshold and b < threshold:\n",
    "        response = True\n",
    "    if a < threshold and b > threshold:\n",
    "        response = True\n",
    "    # return (1.0, 0.0) if response else (0.0, 1.0)\n",
    "    return 1.0 if response else 0.0\n",
    "    \n",
    "\n",
    "def create_n_points(n, size, min=0.0, max=1.0):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append([\n",
    "            random.uniform(min, max) for ii in range(size)\n",
    "        ])\n",
    "\n",
    "    return data\n",
    "\n",
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "def overUnder(val, threshold):\n",
    "    return 1. if val > threshold else 0\n",
    "\n",
    "xor_inputs = create_n_points(400, 2, -1, 1)\n",
    "\n",
    "xor_outputs = [\n",
    "    [xor(tup[0], tup[1], 0)] for tup in xor_inputs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.46017335909155244, 0.7885475077946231],\n",
       " [0.8015664915968379, -0.15680671292793424],\n",
       " [0.6552814993490459, -0.054154277627632474],\n",
       " [0.07733256366163754, -0.5455376330956947],\n",
       " [-0.8279523340150154, -0.7617755115787825]]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "xor_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.0], [1.0], [1.0], [1.0], [0.0]]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "xor_outputs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config_xor\"\n",
    "base_config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_population(config, xs, ys, saveLocation):\n",
    "\n",
    "    if not os.path.exists(saveLocation):\n",
    "        os.makedirs(saveLocation)\n",
    "        \n",
    "    config.save(os.path.join(saveLocation, 'config.conf'))\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    p = BackpropPopulation(config, \n",
    "                            xs, \n",
    "                            ys, \n",
    "                            criterion=nn.BCEWithLogitsLoss())\n",
    "\n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5, filename_prefix=str(saveLocation) + \"checkpoint-\" ))\n",
    "    bpReporter = backprop.BackpropReporter(True)\n",
    "    p.add_reporter(bpReporter)\n",
    "    p.add_reporter(ExperimentReporter(saveLocation))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    \n",
    "    print(genomes)\n",
    "    loss = nn.BCELoss()\n",
    "    loss = loss.to(device)\n",
    "    for genome_id, genome in genomes.items():\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        preds = []\n",
    "        for xi in xor_inputs:\n",
    "            preds.append(net.activate(xi))\n",
    "        genome.fitness = float(1./loss(torch.tensor(preds).to(device), torch.tensor(xor_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The function - generationStart - has just started at 1614481310.349806\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "The function - generationStart - took 0.0002789497375488281 seconds to complete\n",
      "The function - pre_backprop - has just started at 1614481310.3501172\n",
      "The function - pre_backprop - took 7.987022399902344e-05 seconds to complete\n",
      "The function - backprop - has just started at 1614481310.350234\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: 0.0\n",
      "best improvement: tensor(0., grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.6689, grad_fn=<DivBackward0>)\n",
      "The function - backprop - took 2.4360978603363037 seconds to complete\n",
      "The function - post_backprop - has just started at 1614481312.786432\n",
      "The function - post_backprop - took 2.5033950805664062e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1614481312.786518\n",
      "{1: <neat.genome.DefaultGenome object at 0x7fbcd0ef8d60>, 2: <neat.genome.DefaultGenome object at 0x7fbcd0ef8d90>, 3: <neat.genome.DefaultGenome object at 0x7fbcd0ef8ee0>, 4: <neat.genome.DefaultGenome object at 0x7fbce06697f0>, 5: <neat.genome.DefaultGenome object at 0x7fbcd0404280>}\n",
      "The function - evaluate fitness - took 0.0076580047607421875 seconds to complete\n",
      "The function - post evaluate - has just started at 1614481312.794256\n",
      "Population's average fitness: 0.59289 stdev: 0.28154\n",
      "Best fitness: 1.08152 - size: (1, 2) - species 1 - id 3\n",
      "Key: 3\n",
      "Fitness: 1.0815234184265137\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.24954037368297577, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=-0.12936899065971375, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.07517384737730026, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.0005450248718261719 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1614481312.79482\n",
      "The function - pre_reproduction - took 1.5974044799804688e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1614481312.79485\n",
      "Average adjusted fitness: 0.371\n",
      "The function - reproduction - took 0.0002219676971435547 seconds to complete\n",
      "The function - post reproduction - has just started at 1614481312.79509\n",
      "The function - post reproduction - took 1.4066696166992188e-05 seconds to complete\n",
      "The function - speciate - has just started at 1614481312.795115\n",
      "Mean genetic distance 0.573, standard deviation 0.337\n",
      "The function - speciate - took 8.20159912109375e-05 seconds to complete\n",
      "The function - end generation - has just started at 1614481312.795205\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    0     5      1.1    0.371     0\n",
      "Total extinctions: 0\n",
      "Generation time: 2.446 sec\n",
      "The function - end generation - took 0.0007679462432861328 seconds to complete\n",
      "The function - generationStart - has just started at 1614481312.795987\n",
      "\n",
      " ****** Running generation 1 ****** \n",
      "\n",
      "The function - generationStart - took 7.915496826171875e-05 seconds to complete\n",
      "The function - pre_backprop - has just started at 1614481312.79608\n",
      "The function - pre_backprop - took 3.0040740966796875e-05 seconds to complete\n",
      "The function - backprop - has just started at 1614481312.7961228\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: 0.0\n",
      "best improvement: tensor(0., grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.6871, grad_fn=<DivBackward0>)\n",
      "The function - backprop - took 2.245476245880127 seconds to complete\n",
      "The function - post_backprop - has just started at 1614481315.042078\n",
      "The function - post_backprop - took 6.699562072753906e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1614481315.042173\n",
      "{3: <neat.genome.DefaultGenome object at 0x7fbcd0ef8ee0>, 1: <neat.genome.DefaultGenome object at 0x7fbcd0ef8d60>, 6: <neat.genome.DefaultGenome object at 0x7fbc808ed910>, 7: <neat.genome.DefaultGenome object at 0x7fbc808eda90>, 8: <neat.genome.DefaultGenome object at 0x7fbc808edc10>}\n",
      "The function - evaluate fitness - took 0.005706071853637695 seconds to complete\n",
      "The function - post evaluate - has just started at 1614481315.047938\n",
      "Population's average fitness: 0.72682 stdev: 0.21846\n",
      "Best fitness: 1.08152 - size: (1, 2) - species 1 - id 3\n",
      "Key: 3\n",
      "Fitness: 1.0815234184265137\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=-0.24954037368297577, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=-0.12936899065971375, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=0.07517384737730026, enabled=True)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.0003037452697753906 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1614481315.048256\n",
      "The function - pre_reproduction - took 1.52587890625e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1614481315.0482821\n",
      "Average adjusted fitness: 0.325\n",
      "The function - reproduction - took 0.0001437664031982422 seconds to complete\n",
      "The function - post reproduction - has just started at 1614481315.0484369\n",
      "The function - post reproduction - took 1.52587890625e-05 seconds to complete\n",
      "The function - speciate - has just started at 1614481315.0484622\n",
      "Mean genetic distance 0.650, standard deviation 0.241\n",
      "The function - speciate - took 9.179115295410156e-05 seconds to complete\n",
      "The function - end generation - has just started at 1614481315.048565\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    1     5      1.1    0.325     1\n",
      "Total extinctions: 0\n",
      "Generation time: 2.253 sec (2.349 average)\n",
      "The function - end generation - took 7.724761962890625e-05 seconds to complete\n",
      "The function - generationStart - has just started at 1614481315.0486531\n",
      "\n",
      " ****** Running generation 2 ****** \n",
      "\n",
      "The function - generationStart - took 0.00011086463928222656 seconds to complete\n",
      "The function - pre_backprop - has just started at 1614481315.0487838\n",
      "The function - pre_backprop - took 2.5272369384765625e-05 seconds to complete\n",
      "The function - backprop - has just started at 1614481315.048821\n",
      "about to start backprop with 5 epochs\n",
      "mean improvement: 0.0\n",
      "best improvement: tensor(0., grad_fn=<SubBackward0>)\n",
      "best loss: tensor(0.6962, grad_fn=<DivBackward0>)\n",
      "The function - backprop - took 2.0449750423431396 seconds to complete\n",
      "The function - post_backprop - has just started at 1614481317.0938811\n",
      "The function - post_backprop - took 2.09808349609375e-05 seconds to complete\n",
      "The function - evaluate fitness - has just started at 1614481317.093921\n",
      "{3: <neat.genome.DefaultGenome object at 0x7fbcd0ef8ee0>, 8: <neat.genome.DefaultGenome object at 0x7fbc808edc10>, 9: <neat.genome.DefaultGenome object at 0x7fbc808f7700>, 10: <neat.genome.DefaultGenome object at 0x7fbc808f7880>, 11: <neat.genome.DefaultGenome object at 0x7fbc808f7a00>}\n",
      "The function - evaluate fitness - took 0.005373954772949219 seconds to complete\n",
      "The function - post evaluate - has just started at 1614481317.099338\n",
      "Population's average fitness: 0.93042 stdev: 0.13453\n",
      "Best fitness: 1.09683 - size: (1, 1) - species 1 - id 9\n",
      "Key: 9\n",
      "Fitness: 1.0968289375305176\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.2840055525302887, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=-0.6365209221839905, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=-0.11565177142620087, enabled=True)\n",
      "\n",
      "\n",
      " SPECIES TOPOLOGY IMPROVEMENT\n",
      "\n",
      "\n",
      "{'genome': <neat.genome.DefaultGenome object at 0x7fbc808ed940>, 'fitness': 1.0968289375305176, 'firstDerivatives': [0.0, 0.0, 0.015305519104003906], 'secondDerivatives': [0.0, 0.0, 0.015305519104003906]}\n",
      "Key: 9\n",
      "Fitness: 1.0968289375305176\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.2840055525302887, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-2, 0), weight=-0.6365209221839905, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-1, 0), weight=-0.11565177142620087, enabled=True)\n",
      "Nodes\n",
      "0    DefaultNodeGene(key=0, bias=0.2840055525302887, response=1.0, activation=sigmoid, aggregation=sum)\n",
      "Connections\n",
      "(-1, 0)    DefaultConnectionGene(key=(-1, 0), weight=-0.11565177142620087, enabled=True)\n",
      "(-2, 0)    DefaultConnectionGene(key=(-2, 0), weight=-0.6365209221839905, enabled=False)\n",
      "ending generation %s\n",
      "The function - post evaluate - took 0.00043702125549316406 seconds to complete\n",
      "The function - pre_reproduction - has just started at 1614481317.09979\n",
      "The function - pre_reproduction - took 1.3828277587890625e-05 seconds to complete\n",
      "The function - reproduction - has just started at 1614481317.0998132\n",
      "Average adjusted fitness: 0.159\n",
      "The function - reproduction - took 0.00026869773864746094 seconds to complete\n",
      "The function - post reproduction - has just started at 1614481317.1000938\n",
      "The function - post reproduction - took 1.430511474609375e-05 seconds to complete\n",
      "The function - speciate - has just started at 1614481317.100118\n",
      "Mean genetic distance 0.896, standard deviation 0.469\n",
      "The function - speciate - took 0.00014400482177734375 seconds to complete\n",
      "The function - end generation - has just started at 1614481317.100273\n",
      "Population of 5 members in 1 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    2     5      1.1    0.159     0\n",
      "Total extinctions: 0\n",
      "Generation time: 2.052 sec (2.250 average)\n",
      "The function - end generation - took 7.700920104980469e-05 seconds to complete\n",
      "{0: {'generation': 0, 'generationStartTime': 1614481310.350083, 'backpropStartTime': 1614481310.350152, 'genomeNodeSizes': [1, 1, 1, 1, 1], 'genomeNodeSizesMean': 1.0, 'genomeNodeSizesSD': 0.0, 'genomeConnectionSizes': [2, 2, 2, 2, 2], 'genomeConnectionSizesMean': 2.0, 'genomeConnectionSizesSD': 0.0, 'backpropEndTime': 1614481312.7864552, 'fitnesses': [0.6546214818954468, 0.5040234327316284, 1.0815234184265137, 0.5023809671401978, 0.22187907993793488], 'fitnessMean': 0.5928856760263443, 'fitnessSD': 0.2815356630976919, 'reproductionStartTime': 1614481312.794836, 'reproductionEndTime': 1614481312.795103, 'generationEndTime': 1614481312.795972}, 1: {'generation': 1, 'generationStartTime': 1614481312.796066, 'backpropStartTime': 1614481312.796093, 'genomeNodeSizes': [1, 1, 1, 1, 1], 'genomeNodeSizesMean': 1.0, 'genomeNodeSizesSD': 0.0, 'genomeConnectionSizes': [2, 2, 2, 2, 2], 'genomeConnectionSizesMean': 2.0, 'genomeConnectionSizesSD': 0.0, 'backpropEndTime': 1614481315.0421429, 'fitnesses': [1.0815234184265137, 0.6546214818954468, 0.724825382232666, 0.4018233120441437, 0.7713139057159424], 'fitnessMean': 0.7268215000629425, 'fitnessSD': 0.21846449339738033, 'reproductionStartTime': 1614481315.04827, 'reproductionEndTime': 1614481315.0484512, 'generationEndTime': 1614481315.0486422}, 2: {'generation': 2, 'generationStartTime': 1614481315.048764, 'backpropStartTime': 1614481315.048796, 'genomeNodeSizes': [1, 1, 1, 1, 1], 'genomeNodeSizesMean': 1.0, 'genomeNodeSizesSD': 0.0, 'genomeConnectionSizes': [2, 2, 2, 2, 2], 'genomeConnectionSizesMean': 2.0, 'genomeConnectionSizesSD': 0.0, 'backpropEndTime': 1614481317.0939, 'fitnesses': [1.0815234184265137, 0.7713139057159424, 1.0968289375305176, 0.8836385607719421, 0.8187995553016663], 'fitnessMean': 0.9304208755493164, 'fitnessSD': 0.1345262454063225, 'reproductionStartTime': 1614481317.099803, 'reproductionEndTime': 1614481317.100107, 'generationEndTime': 1614481317.100349}}\n"
     ]
    }
   ],
   "source": [
    "config = base_config\n",
    "saveLocation = './'\n",
    "maxNGenerations = 3\n",
    "p = instantiate_population(config, xor_inputs, xor_outputs, saveLocation)\n",
    "# Run for up to nGenerations generations.\n",
    "winner = p.run(eval_genomes, maxNGenerations, nEpochs = 5)\n",
    "\n",
    "g = p.best_genome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.0968289375305176\nNodes:\n\t0 DefaultNodeGene(key=0, bias=0.2840055525302887, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 0), weight=-0.6365209221839905, enabled=False)\n\tDefaultConnectionGene(key=(-1, 0), weight=-0.11565177142620087, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = deepcopy(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.0968289375305176\nNodes:\n\t0 DefaultNodeGene(key=0, bias=0.2840055525302887, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 0), weight=-0.6365209221839905, enabled=False)\n\tDefaultConnectionGene(key=(-1, 0), weight=-0.11565177142620087, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_node(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)\n",
    "h.mutate_add_connection(p.config.genome_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.0968289375305176\nNodes:\n\t0 DefaultNodeGene(key=0, bias=0.2840055525302887, response=1.0, activation=sigmoid, aggregation=sum)\n\t3 DefaultNodeGene(key=3, bias=-0.22266171274789123, response=1.0, activation=sigmoid, aggregation=sum)\n\t4 DefaultNodeGene(key=4, bias=-1.952108050005937, response=1.0, activation=sigmoid, aggregation=sum)\n\t5 DefaultNodeGene(key=5, bias=-0.41877374337595313, response=1.0, activation=sigmoid, aggregation=sum)\n\t6 DefaultNodeGene(key=6, bias=-0.6640235819833576, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 0), weight=-0.6365209221839905, enabled=False)\n\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-2, 5), weight=0.7796292335753101, enabled=True)\n\tDefaultConnectionGene(key=(-1, 0), weight=-0.11565177142620087, enabled=False)\n\tDefaultConnectionGene(key=(-1, 3), weight=1.0, enabled=False)\n\tDefaultConnectionGene(key=(-1, 5), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-1, 6), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(3, 0), weight=-0.11565177142620087, enabled=True)\n\tDefaultConnectionGene(key=(4, 0), weight=-0.6365209221839905, enabled=True)\n\tDefaultConnectionGene(key=(4, 5), weight=-0.4668377906660507, enabled=True)\n\tDefaultConnectionGene(key=(5, 3), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(6, 3), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(6, 4), weight=1.115361001875095, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.add_connection(p.config.genome_config, 16, 17, 0.2, True)\n",
    "# h.add_connection(p.config.genome_config, 17, 0, 0.2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key: 9\nFitness: 1.0968289375305176\nNodes:\n\t0 DefaultNodeGene(key=0, bias=0.2840055525302887, response=1.0, activation=sigmoid, aggregation=sum)\n\t3 DefaultNodeGene(key=3, bias=-0.22266171274789123, response=1.0, activation=sigmoid, aggregation=sum)\n\t4 DefaultNodeGene(key=4, bias=-1.952108050005937, response=1.0, activation=sigmoid, aggregation=sum)\n\t5 DefaultNodeGene(key=5, bias=-0.41877374337595313, response=1.0, activation=sigmoid, aggregation=sum)\n\t6 DefaultNodeGene(key=6, bias=-0.6640235819833576, response=1.0, activation=sigmoid, aggregation=sum)\nConnections:\n\tDefaultConnectionGene(key=(-2, 0), weight=-0.6365209221839905, enabled=False)\n\tDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-2, 5), weight=0.7796292335753101, enabled=True)\n\tDefaultConnectionGene(key=(-1, 0), weight=-0.11565177142620087, enabled=False)\n\tDefaultConnectionGene(key=(-1, 3), weight=1.0, enabled=False)\n\tDefaultConnectionGene(key=(-1, 5), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(-1, 6), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(3, 0), weight=-0.11565177142620087, enabled=True)\n\tDefaultConnectionGene(key=(4, 0), weight=-0.6365209221839905, enabled=True)\n\tDefaultConnectionGene(key=(4, 5), weight=-0.4668377906660507, enabled=True)\n\tDefaultConnectionGene(key=(5, 3), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(6, 3), weight=1.0, enabled=True)\n\tDefaultConnectionGene(key=(6, 4), weight=1.115361001875095, enabled=True)\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "p.config.genome_config.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: <neat.genes.DefaultNodeGene at 0x7fbcd0f05b80>,\n",
       " 3: <neat.genes.DefaultNodeGene at 0x7fbc808fe070>,\n",
       " 4: <neat.genes.DefaultNodeGene at 0x7fbc808f2be0>,\n",
       " 5: <neat.genes.DefaultNodeGene at 0x7fbc808fe1c0>,\n",
       " 6: <neat.genes.DefaultNodeGene at 0x7fbc808fe2b0>}"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "h.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_tracker = {node_id:{'depth':0, 'output_ids':[], 'input_ids':[]} for node_id in h.nodes}\n",
    "for node_id in p.config.genome_config.input_keys:\n",
    "    node_tracker[node_id] = {'depth':0, 'output_ids':[], 'input_ids':[]}\n",
    "trace_stack = [node_id for node_id in p.config.genome_config.input_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "trace_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 3: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 4: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 5: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " 6: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " -1: {'depth': 0, 'output_ids': [], 'input_ids': []},\n",
       " -2: {'depth': 0, 'output_ids': [], 'input_ids': []}}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(-1, 0)\n(-2, 0)\n(-1, 3)\n(3, 0)\n(-2, 4)\n(4, 0)\n(-1, 5)\n(5, 3)\n(-1, 6)\n(6, 3)\n(6, 4)\n(4, 5)\n(-2, 5)\n"
     ]
    }
   ],
   "source": [
    "for connection in h.connections:\n",
    "    print(connection)\n",
    "    node_tracker[connection[0]]['output_ids'].append(connection[1])\n",
    "    node_tracker[connection[1]]['input_ids'].append(connection[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(trace_stack) > 0:\n",
    "    trace = trace_stack[0]\n",
    "    my_depth = node_tracker[trace]['depth']\n",
    "    next_depth = my_depth + 1\n",
    "    for output_id in node_tracker[trace]['output_ids']:\n",
    "        node_tracker[output_id]['depth'] = max(node_tracker[output_id]['depth'], next_depth)\n",
    "        trace_stack.append(output_id)\n",
    "    del(trace_stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'depth': 5, 'output_ids': [], 'input_ids': [-1, -2, 3, 4]},\n",
       " 3: {'depth': 4, 'output_ids': [0], 'input_ids': [-1, 5, 6]},\n",
       " 4: {'depth': 2, 'output_ids': [0, 5], 'input_ids': [-2, 6]},\n",
       " 5: {'depth': 3, 'output_ids': [3], 'input_ids': [-1, 4, -2]},\n",
       " 6: {'depth': 1, 'output_ids': [3, 4], 'input_ids': [-1]},\n",
       " -1: {'depth': 0, 'output_ids': [0, 3, 5, 6], 'input_ids': []},\n",
       " -2: {'depth': 0, 'output_ids': [0, 4, 5], 'input_ids': []}}"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['output_layers']=[]\n",
    "    node['needs_skip'] = False\n",
    "    node['id'] = node_id\n",
    "    for output_id in node['output_ids']:\n",
    "        node['output_layers'].append(node_tracker[output_id]['depth'])\n",
    "        if node_tracker[output_id]['depth'] > (node['depth']+1):\n",
    "            node['needs_skip'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node in node_tracker.items():\n",
    "    node['input_layers'] = []\n",
    "    node['skip_layer_input'] = False\n",
    "    for input_id in node['input_ids']:\n",
    "        node['input_layers'].append(node_tracker[input_id]['depth'])\n",
    "        if node_tracker[input_id]['depth'] < (node['depth']-1):\n",
    "            node['skip_layer_input'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'depth': 5,\n",
       "  'output_ids': [],\n",
       "  'input_ids': [-1, -2, 3, 4],\n",
       "  'output_layers': [],\n",
       "  'needs_skip': False,\n",
       "  'id': 0,\n",
       "  'input_layers': [0, 0, 4, 2],\n",
       "  'skip_layer_input': True},\n",
       " 3: {'depth': 4,\n",
       "  'output_ids': [0],\n",
       "  'input_ids': [-1, 5, 6],\n",
       "  'output_layers': [5],\n",
       "  'needs_skip': False,\n",
       "  'id': 3,\n",
       "  'input_layers': [0, 3, 1],\n",
       "  'skip_layer_input': True},\n",
       " 4: {'depth': 2,\n",
       "  'output_ids': [0, 5],\n",
       "  'input_ids': [-2, 6],\n",
       "  'output_layers': [5, 3],\n",
       "  'needs_skip': True,\n",
       "  'id': 4,\n",
       "  'input_layers': [0, 1],\n",
       "  'skip_layer_input': True},\n",
       " 5: {'depth': 3,\n",
       "  'output_ids': [3],\n",
       "  'input_ids': [-1, 4, -2],\n",
       "  'output_layers': [4],\n",
       "  'needs_skip': False,\n",
       "  'id': 5,\n",
       "  'input_layers': [0, 2, 0],\n",
       "  'skip_layer_input': True},\n",
       " 6: {'depth': 1,\n",
       "  'output_ids': [3, 4],\n",
       "  'input_ids': [-1],\n",
       "  'output_layers': [4, 2],\n",
       "  'needs_skip': True,\n",
       "  'id': 6,\n",
       "  'input_layers': [0],\n",
       "  'skip_layer_input': False},\n",
       " -1: {'depth': 0,\n",
       "  'output_ids': [0, 3, 5, 6],\n",
       "  'input_ids': [],\n",
       "  'output_layers': [5, 4, 3, 1],\n",
       "  'needs_skip': True,\n",
       "  'id': -1,\n",
       "  'input_layers': [],\n",
       "  'skip_layer_input': False},\n",
       " -2: {'depth': 0,\n",
       "  'output_ids': [0, 4, 5],\n",
       "  'input_ids': [],\n",
       "  'output_layers': [5, 2, 3],\n",
       "  'needs_skip': True,\n",
       "  'id': -2,\n",
       "  'input_layers': [],\n",
       "  'skip_layer_input': False}}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-1, -2, 3, 4],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 0, 4, 2],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 4: {'nodes': {3: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [-1, 5, 6],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 3,\n",
       "    'input_layers': [0, 3, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 2: {'nodes': {4: {'depth': 2,\n",
       "    'output_ids': [0, 5],\n",
       "    'input_ids': [-2, 6],\n",
       "    'output_layers': [5, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 3: {'nodes': {5: {'depth': 3,\n",
       "    'output_ids': [3],\n",
       "    'input_ids': [-1, 4, -2],\n",
       "    'output_layers': [4],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [0, 2, 0],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}}},\n",
       " 1: {'nodes': {6: {'depth': 1,\n",
       "    'output_ids': [3, 4],\n",
       "    'input_ids': [-1],\n",
       "    'output_layers': [4, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': 6,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}}},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [0, 3, 5, 6],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 4, 3, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [0, 4, 5],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 2, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}}}}"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "layers = {}\n",
    "for node_id, node in node_tracker.items():\n",
    "    if not node['depth'] in layers:\n",
    "        layers[node['depth']] = {\n",
    "            'nodes':{node_id:node}\n",
    "        }\n",
    "    else:\n",
    "        layers[node['depth']]['nodes'][node_id] = node\n",
    "        \n",
    "# Ensure all nodes have a layer index\n",
    "for layer_id, layer in layers.items():\n",
    "    layer_index = 0\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "        \n",
    "        \n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "my layer id is 5\nDefaultConnectionGene(key=(-1, 0), weight=-0.11565177142620087, enabled=False)\nDefaultConnectionGene(key=(-2, 0), weight=-0.6365209221839905, enabled=False)\nDefaultConnectionGene(key=(4, 0), weight=-0.6365209221839905, enabled=True)\n-0.6365209221839905\nlocation is\n(0, 2)\nDefaultConnectionGene(key=(3, 0), weight=-0.11565177142620087, enabled=True)\n-0.11565177142620087\nlocation is\n(0, 3)\nmy layer id is 4\nDefaultConnectionGene(key=(-1, 3), weight=1.0, enabled=False)\nDefaultConnectionGene(key=(6, 3), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 2)\nDefaultConnectionGene(key=(5, 3), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 3)\nmy layer id is 2\nDefaultConnectionGene(key=(-2, 4), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 1)\nDefaultConnectionGene(key=(6, 4), weight=1.115361001875095, enabled=True)\n1.115361001875095\nlocation is\n(0, 2)\nmy layer id is 3\nDefaultConnectionGene(key=(-1, 5), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 0)\nDefaultConnectionGene(key=(-2, 5), weight=0.7796292335753101, enabled=True)\n0.7796292335753101\nlocation is\n(0, 1)\nDefaultConnectionGene(key=(4, 5), weight=-0.4668377906660507, enabled=True)\n-0.4668377906660507\nlocation is\n(0, 2)\nmy layer id is 1\nDefaultConnectionGene(key=(-1, 6), weight=1.0, enabled=True)\n1.0\nlocation is\n(0, 0)\nmy layer id is 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LAYER_TYPE_CONNECTED = \"CONNECTED\"\n",
    "LAYER_TYPE_INPUT = \"INPUT\"\n",
    "LAYER_TYPE_OUTPUT = \"OUTPUT\"\n",
    "for layer_id, layer in layers.items():\n",
    "    layer['is_output_layer'] = False\n",
    "    layer['is_input_layer'] = False\n",
    "    layer['layer_type'] = LAYER_TYPE_CONNECTED\n",
    "    # If I have the output node in me, then I am an output\n",
    "    if 0 in layer['nodes']:\n",
    "        layer['is_output_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_OUTPUT\n",
    "\n",
    "    # If I have the first input in me, then I am the input\n",
    "    if -1 in layer['nodes']:\n",
    "        layer['is_input_layer'] = True\n",
    "        layer['layer_type'] = LAYER_TYPE_INPUT\n",
    "    biases = []\n",
    "\n",
    "    layer['input_layers'] = []\n",
    "    ## Compute the shape of required inputs\n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        for in_layer in node['input_layers']:\n",
    "            if in_layer not in layer['input_layers']:\n",
    "                layer['input_layers'].append(in_layer)\n",
    "    layer['input_layers'].sort()\n",
    "    layer['input_shape'] = sum(len(layers[jj]['nodes']) for jj in layer['input_layers'])\n",
    "    layer['weights_shape'] = (layer['input_shape'], len(layer['nodes']))\n",
    "\n",
    "\n",
    "    # Handle output layer \"edge\" case\n",
    "    if layer['is_output_layer']:\n",
    "        layer['out_weights'] = []\n",
    "        layer['bias'] = []\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle input layer \"edge\" case\n",
    "    elif layer['is_input_layer']:\n",
    "        layer['in_weights'] = []\n",
    "        layer['bias'] = []\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "    # Handle generic case\n",
    "    else:\n",
    "        layer['out_weights'] = [[0 for __ in layers[layer_id+1]['nodes']] for _ in layer['nodes']]\n",
    "        layer['in_weights'] = [[0 for __ in layers[layer_id-1]['nodes']] for _ in layer['nodes']]\n",
    "\n",
    "        layer['bias'] = [h.nodes[node_id].bias for node_id, node in layer['nodes'].items()]\n",
    "        # else:\n",
    "            # layer['bias'] = [0 for _ in layer['nodes']]\n",
    "    \n",
    "    layer_index = 0          \n",
    "    for node_id, node in layer['nodes'].items():\n",
    "        node['layer_index'] = layer_index\n",
    "        layer_index += 1\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "        ### POSSIBLY NEED THIS\n",
    "        # if node['id'] < 0:\n",
    "        #     biases.append(1)\n",
    "        # else:\n",
    "        #     biases.append(h.nodes[node['id']].bias)\n",
    "        # for output_id in node['output_ids']:\n",
    "        #     if (node['id'], output_id) in h.connections:\n",
    "        #         if output_id in layers[layer_id + 1]['nodes']:\n",
    "        #             layer['out_weights'][node['layer_index']][layers[layer_id + 1]['nodes'][output_id]['layer_index']] = h.connections[(node['id'], output_id)].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        # for input_id in node['input_ids']:\n",
    "        #     if (input_id, node['id']) in h.connections:\n",
    "        #         if input_id in layers[layer_id - 1]['nodes']:\n",
    "        #             layer['in_weights'][node['layer_index']][layers[layer_id -1]['nodes'][input_id]['layer_index']] = h.connections[(input_id, node['id'])].weight\n",
    "        #         else:\n",
    "        #             # TODO: this is a skip layer to deal with\n",
    "        #             pass\n",
    "        #     else:\n",
    "        #         # this is not a connection that exists, so default of 0 holds\n",
    "        #         pass\n",
    "        #################################################\n",
    "            ### END OF POSSIBLY NEEDING THIS\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "    #################################################\n",
    "\n",
    "\n",
    "    # layer['out_tensor'] = torch.tensor(layer['out_weights'])\n",
    "    # layer['bias'] = torch.tensor(layer['bias'])\n",
    "    # layer['out_tensor_shape'] = layer['out_tensor'].shape\n",
    "    # layer['in_tensor'] = torch.tensor(layer['in_weights'])\n",
    "    # layer['in_tensor_shape'] = layer['in_tensor'].shape\n",
    "\n",
    "\n",
    "\n",
    "    # Set up current weights\n",
    "    layer['input_weights'] = np.zeros(layer['weights_shape'])\n",
    "    layer_offset = 0\n",
    "    # Check every layer and every node for connections\n",
    "    print(\"my layer id is %s\" % (layer_id))\n",
    "    for input_layer_id in layer['input_layers']:\n",
    "        input_layer = layers[input_layer_id]\n",
    "        for node_id, node in input_layer['nodes'].items():\n",
    "            for node_output_id in node['output_ids']:\n",
    "                if node_output_id in layer['nodes']:\n",
    "                    node_output = layer['nodes'][node_output_id]\n",
    "                    # I HAVE THIS NODE!\n",
    "                    # What is it's weight?\n",
    "                    connection = h.connections[(node_id, node_output_id)]\n",
    "                    print(connection)\n",
    "\n",
    "                    if not connection.enabled:\n",
    "                        continue\n",
    "                    connection_weight = connection.weight\n",
    "                    print(connection_weight)\n",
    "\n",
    "                    in_weight_location = layer_offset + node['layer_index']\n",
    "                    out_weight_location = node_output['layer_index']\n",
    "                    print('location is')\n",
    "                    print((out_weight_location, in_weight_location))\n",
    "                    layer['input_weights'][in_weight_location][out_weight_location] = connection_weight\n",
    "        layer_offset += len(input_layer['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-1, -2, 3, 4],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 0, 4, 2],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': True,\n",
       "  'out_weights': [],\n",
       "  'bias': [],\n",
       "  'in_weights': [[0]],\n",
       "  'out_tensor': tensor([]),\n",
       "  'out_tensor_shape': torch.Size([0]),\n",
       "  'in_tensor': tensor([[-0.1157]]),\n",
       "  'in_tensor_shape': torch.Size([1, 1]),\n",
       "  'is_input_layer': False,\n",
       "  'input_layers': [0, 2, 4],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'input_weights': array([[ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [-0.63652092],\n",
       "         [-0.11565177]]),\n",
       "  'layer_type': 'OUTPUT'},\n",
       " 4: {'nodes': {3: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [-1, 5, 6],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 3,\n",
       "    'input_layers': [0, 3, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.22266171274789123],\n",
       "  'out_tensor': tensor([[-0.1157]]),\n",
       "  'out_tensor_shape': torch.Size([1, 1]),\n",
       "  'in_tensor': tensor([[1.]]),\n",
       "  'in_tensor_shape': torch.Size([1, 1]),\n",
       "  'input_layers': [0, 1, 3],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'input_weights': array([[0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       "  'layer_type': 'CONNECTED'},\n",
       " 2: {'nodes': {4: {'depth': 2,\n",
       "    'output_ids': [0, 5],\n",
       "    'input_ids': [-2, 6],\n",
       "    'output_layers': [5, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-1.952108050005937],\n",
       "  'out_tensor': tensor([[-0.4668]]),\n",
       "  'out_tensor_shape': torch.Size([1, 1]),\n",
       "  'in_tensor': tensor([[1.1154]]),\n",
       "  'in_tensor_shape': torch.Size([1, 1]),\n",
       "  'input_layers': [0, 1],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'input_weights': array([[0.      ],\n",
       "         [1.      ],\n",
       "         [1.115361]]),\n",
       "  'layer_type': 'CONNECTED'},\n",
       " 3: {'nodes': {5: {'depth': 3,\n",
       "    'output_ids': [3],\n",
       "    'input_ids': [-1, 4, -2],\n",
       "    'output_layers': [4],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [0, 2, 0],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.41877374337595313],\n",
       "  'out_tensor': tensor([[1.]]),\n",
       "  'out_tensor_shape': torch.Size([1, 1]),\n",
       "  'in_tensor': tensor([[-0.4668]]),\n",
       "  'in_tensor_shape': torch.Size([1, 1]),\n",
       "  'input_layers': [0, 2],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'input_weights': array([[ 1.        ],\n",
       "         [ 0.77962923],\n",
       "         [-0.46683779]]),\n",
       "  'layer_type': 'CONNECTED'},\n",
       " 1: {'nodes': {6: {'depth': 1,\n",
       "    'output_ids': [3, 4],\n",
       "    'input_ids': [-1],\n",
       "    'output_layers': [4, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': 6,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0, 0]],\n",
       "  'bias': [-0.6640235819833576],\n",
       "  'out_tensor': tensor([[1.1154]]),\n",
       "  'out_tensor_shape': torch.Size([1, 1]),\n",
       "  'in_tensor': tensor([[1., 0.]]),\n",
       "  'in_tensor_shape': torch.Size([1, 2]),\n",
       "  'input_layers': [0],\n",
       "  'input_shape': 2,\n",
       "  'weights_shape': (2, 1),\n",
       "  'input_weights': array([[1.],\n",
       "         [0.]]),\n",
       "  'layer_type': 'CONNECTED'},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [0, 3, 5, 6],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 4, 3, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [0, 4, 5],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 2, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_input_layer': True,\n",
       "  'is_output_layer': False,\n",
       "  'in_weights': [],\n",
       "  'bias': [],\n",
       "  'out_weights': [[0], [0]],\n",
       "  'out_tensor': tensor([[1.],\n",
       "          [0.]]),\n",
       "  'out_tensor_shape': torch.Size([2, 1]),\n",
       "  'in_tensor': tensor([]),\n",
       "  'in_tensor_shape': torch.Size([0]),\n",
       "  'input_layers': [],\n",
       "  'input_shape': 0,\n",
       "  'weights_shape': (0, 2),\n",
       "  'input_weights': array([], shape=(0, 2), dtype=float64),\n",
       "  'layer_type': 'INPUT'}}"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "source": [
    "Add in computation of skip layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'nodes': {4: {'depth': 2,\n",
       "   'output_ids': [0, 5],\n",
       "   'input_ids': [-2, 6],\n",
       "   'output_layers': [5, 3],\n",
       "   'needs_skip': True,\n",
       "   'id': 4,\n",
       "   'input_layers': [0, 1],\n",
       "   'skip_layer_input': True,\n",
       "   'layer_index': 0}},\n",
       " 'is_output_layer': False,\n",
       " 'is_input_layer': False,\n",
       " 'out_weights': [[-0.4668377906660507]],\n",
       " 'in_weights': [[1.115361001875095]],\n",
       " 'bias': tensor([-1.9521]),\n",
       " 'out_tensor': tensor([[-0.4668]]),\n",
       " 'out_tensor_shape': torch.Size([1, 1]),\n",
       " 'in_tensor': tensor([[1.1154]]),\n",
       " 'in_tensor_shape': torch.Size([1, 1])}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers"
   ]
  },
  {
   "source": [
    "The question is, how do you code the operations to dynamically create the\n",
    "NN? You need to be able to do the right things in the right order. You have\n",
    "a list of possible operations:\n",
    "* Matrix multiple\n",
    "* Concatenate (for skip layers)\n",
    "* Matrix addition (for biases)\n",
    "* Output\n",
    "\n",
    "The order of operations in each layer is:\n",
    "\n",
    "1. Concatenate input tensors\n",
    "2. Matrix multiply input tensors with weights\n",
    "3. Add bias tensors\n",
    "4. Apply activation function\n",
    "\n",
    "I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "These computations can be computed back-to-front, and then executed forward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "ACTIVATE_OPERATION = \"ACTIVATE\"\n",
    "OUTPUT_OPERATION = \"OUTPUT\"\n",
    "TENADD_OPERATION = \"TENADD\" # Tensor ADD\n",
    "ADD_BIAS_OPERATION = \"BIASADD\"\n",
    "TENMUL_OPERATION = \"TENMUL\"\n",
    "TENCAT_OPERATION = \"TENCAT\"\n",
    "order_of_operations = []\n",
    "\n",
    "# for layer_id, layer in layers.items():\n",
    "#     print(layer)\n",
    "#     # Output for final layer\n",
    "#     if layer['is_output_layer']:\n",
    "#         order_of_operations.append(OUTPUT_OPERATION)\n",
    "#     # Activate\n",
    "#     order_of_operations.append(ACTIVATE_OPERATION)\n",
    "#     # Add Bias\n",
    "#     order_of_operations.append(ADD_BIAS_OPERATION)\n",
    "#     # Matrix Multiply weights\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     print(order_of_operations)\n",
    "\n",
    "#     break\n",
    "\n",
    "for layer_id in range(len(layers)):\n",
    "    layer = layers[layer_id]\n",
    "    print(layer)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'nodes': {-1: {'depth': 0, 'output_ids': [0, 3, 5, 6], 'input_ids': [], 'output_layers': [5, 4, 3, 1], 'needs_skip': True, 'id': -1, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 0}, -2: {'depth': 0, 'output_ids': [0, 4, 5], 'input_ids': [], 'output_layers': [5, 2, 3], 'needs_skip': True, 'id': -2, 'input_layers': [], 'skip_layer_input': False, 'layer_index': 1}}, 'is_input_layer': True, 'is_output_layer': False, 'in_weights': [], 'bias': tensor([]), 'out_weights': [[1.0], [0]], 'out_tensor': tensor([[1.],\n        [0.]]), 'out_tensor_shape': torch.Size([2, 1]), 'in_tensor': tensor([]), 'in_tensor_shape': torch.Size([0])}\n{'nodes': {6: {'depth': 1, 'output_ids': [3, 4], 'input_ids': [-1], 'output_layers': [4, 2], 'needs_skip': True, 'id': 6, 'input_layers': [0], 'skip_layer_input': False, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'out_weights': [[1.115361001875095]], 'in_weights': [[1.0, 0]], 'bias': tensor([-0.6640]), 'out_tensor': tensor([[1.1154]]), 'out_tensor_shape': torch.Size([1, 1]), 'in_tensor': tensor([[1., 0.]]), 'in_tensor_shape': torch.Size([1, 2])}\n{'nodes': {4: {'depth': 2, 'output_ids': [0, 5], 'input_ids': [-2, 6], 'output_layers': [5, 3], 'needs_skip': True, 'id': 4, 'input_layers': [0, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'out_weights': [[-0.4668377906660507]], 'in_weights': [[1.115361001875095]], 'bias': tensor([-1.9521]), 'out_tensor': tensor([[-0.4668]]), 'out_tensor_shape': torch.Size([1, 1]), 'in_tensor': tensor([[1.1154]]), 'in_tensor_shape': torch.Size([1, 1])}\n{'nodes': {5: {'depth': 3, 'output_ids': [3], 'input_ids': [-1, 4, -2], 'output_layers': [4], 'needs_skip': False, 'id': 5, 'input_layers': [0, 2, 0], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'out_weights': [[1.0]], 'in_weights': [[-0.4668377906660507]], 'bias': tensor([-0.4188]), 'out_tensor': tensor([[1.]]), 'out_tensor_shape': torch.Size([1, 1]), 'in_tensor': tensor([[-0.4668]]), 'in_tensor_shape': torch.Size([1, 1])}\n{'nodes': {3: {'depth': 4, 'output_ids': [0], 'input_ids': [-1, 5, 6], 'output_layers': [5], 'needs_skip': False, 'id': 3, 'input_layers': [0, 3, 1], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': False, 'is_input_layer': False, 'out_weights': [[-0.11565177142620087]], 'in_weights': [[1.0]], 'bias': tensor([-0.2227]), 'out_tensor': tensor([[-0.1157]]), 'out_tensor_shape': torch.Size([1, 1]), 'in_tensor': tensor([[1.]]), 'in_tensor_shape': torch.Size([1, 1])}\n{'nodes': {0: {'depth': 5, 'output_ids': [], 'input_ids': [-1, -2, 3, 4], 'output_layers': [], 'needs_skip': False, 'id': 0, 'input_layers': [0, 0, 4, 2], 'skip_layer_input': True, 'layer_index': 0}}, 'is_output_layer': True, 'out_weights': [], 'bias': tensor([]), 'in_weights': [[-0.11565177142620087]], 'out_tensor': tensor([]), 'out_tensor_shape': torch.Size([0]), 'in_tensor': tensor([[-0.1157]]), 'in_tensor_shape': torch.Size([1, 1]), 'is_input_layer': False}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(3, 1)\n",
    "c = torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-5.9067],\n",
       "        [ 0.5591]])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in alyers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{5: {'nodes': {0: {'depth': 5,\n",
       "    'output_ids': [],\n",
       "    'input_ids': [-1, -2, 3, 4],\n",
       "    'output_layers': [],\n",
       "    'needs_skip': False,\n",
       "    'id': 0,\n",
       "    'input_layers': [0, 0, 4, 2],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': True,\n",
       "  'out_weights': [],\n",
       "  'bias': [],\n",
       "  'in_weights': [[0]],\n",
       "  'out_tensor': tensor([]),\n",
       "  'out_tensor_shape': torch.Size([0]),\n",
       "  'in_tensor': tensor([[-0.1157]]),\n",
       "  'in_tensor_shape': torch.Size([1, 1]),\n",
       "  'is_input_layer': False,\n",
       "  'input_layers': [0, 2, 4],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'input_weights': array([[ 0.        ],\n",
       "         [ 0.        ],\n",
       "         [-0.63652092],\n",
       "         [-0.11565177]])},\n",
       " 4: {'nodes': {3: {'depth': 4,\n",
       "    'output_ids': [0],\n",
       "    'input_ids': [-1, 5, 6],\n",
       "    'output_layers': [5],\n",
       "    'needs_skip': False,\n",
       "    'id': 3,\n",
       "    'input_layers': [0, 3, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.22266171274789123],\n",
       "  'out_tensor': tensor([[-0.1157]]),\n",
       "  'out_tensor_shape': torch.Size([1, 1]),\n",
       "  'in_tensor': tensor([[1.]]),\n",
       "  'in_tensor_shape': torch.Size([1, 1]),\n",
       "  'input_layers': [0, 1, 3],\n",
       "  'input_shape': 4,\n",
       "  'weights_shape': (4, 1),\n",
       "  'input_weights': array([[0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.]])},\n",
       " 2: {'nodes': {4: {'depth': 2,\n",
       "    'output_ids': [0, 5],\n",
       "    'input_ids': [-2, 6],\n",
       "    'output_layers': [5, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': 4,\n",
       "    'input_layers': [0, 1],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-1.952108050005937],\n",
       "  'out_tensor': tensor([[-0.4668]]),\n",
       "  'out_tensor_shape': torch.Size([1, 1]),\n",
       "  'in_tensor': tensor([[1.1154]]),\n",
       "  'in_tensor_shape': torch.Size([1, 1]),\n",
       "  'input_layers': [0, 1],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'input_weights': array([[0.      ],\n",
       "         [1.      ],\n",
       "         [1.115361]])},\n",
       " 3: {'nodes': {5: {'depth': 3,\n",
       "    'output_ids': [3],\n",
       "    'input_ids': [-1, 4, -2],\n",
       "    'output_layers': [4],\n",
       "    'needs_skip': False,\n",
       "    'id': 5,\n",
       "    'input_layers': [0, 2, 0],\n",
       "    'skip_layer_input': True,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0]],\n",
       "  'bias': [-0.41877374337595313],\n",
       "  'out_tensor': tensor([[1.]]),\n",
       "  'out_tensor_shape': torch.Size([1, 1]),\n",
       "  'in_tensor': tensor([[-0.4668]]),\n",
       "  'in_tensor_shape': torch.Size([1, 1]),\n",
       "  'input_layers': [0, 2],\n",
       "  'input_shape': 3,\n",
       "  'weights_shape': (3, 1),\n",
       "  'input_weights': array([[ 1.        ],\n",
       "         [ 0.77962923],\n",
       "         [-0.46683779]])},\n",
       " 1: {'nodes': {6: {'depth': 1,\n",
       "    'output_ids': [3, 4],\n",
       "    'input_ids': [-1],\n",
       "    'output_layers': [4, 2],\n",
       "    'needs_skip': True,\n",
       "    'id': 6,\n",
       "    'input_layers': [0],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0}},\n",
       "  'is_output_layer': False,\n",
       "  'is_input_layer': False,\n",
       "  'out_weights': [[0]],\n",
       "  'in_weights': [[0, 0]],\n",
       "  'bias': [-0.6640235819833576],\n",
       "  'out_tensor': tensor([[1.1154]]),\n",
       "  'out_tensor_shape': torch.Size([1, 1]),\n",
       "  'in_tensor': tensor([[1., 0.]]),\n",
       "  'in_tensor_shape': torch.Size([1, 2]),\n",
       "  'input_layers': [0],\n",
       "  'input_shape': 2,\n",
       "  'weights_shape': (2, 1),\n",
       "  'input_weights': array([[1.],\n",
       "         [0.]])},\n",
       " 0: {'nodes': {-1: {'depth': 0,\n",
       "    'output_ids': [0, 3, 5, 6],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 4, 3, 1],\n",
       "    'needs_skip': True,\n",
       "    'id': -1,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 0},\n",
       "   -2: {'depth': 0,\n",
       "    'output_ids': [0, 4, 5],\n",
       "    'input_ids': [],\n",
       "    'output_layers': [5, 2, 3],\n",
       "    'needs_skip': True,\n",
       "    'id': -2,\n",
       "    'input_layers': [],\n",
       "    'skip_layer_input': False,\n",
       "    'layer_index': 1}},\n",
       "  'is_input_layer': True,\n",
       "  'is_output_layer': False,\n",
       "  'in_weights': [],\n",
       "  'bias': [],\n",
       "  'out_weights': [[0], [0]],\n",
       "  'out_tensor': tensor([[1.],\n",
       "          [0.]]),\n",
       "  'out_tensor_shape': torch.Size([2, 1]),\n",
       "  'in_tensor': tensor([]),\n",
       "  'in_tensor_shape': torch.Size([0]),\n",
       "  'input_layers': [],\n",
       "  'input_shape': 0,\n",
       "  'weights_shape': (0, 2),\n",
       "  'input_weights': array([], shape=(0, 2), dtype=float64)}}"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = nn.Parameter(torch.tensor([0.3, 0.4], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Net, self).__init__()  # just run the init of parent class (nn.Module)\n",
    "        self.weights = {layer_id: self._tt(layer['input_weights'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.biases = {layer_id: self._tt(layer['bias'].copy()) for layer_id, layer in layers.items()}\n",
    "        self.layers = {layer_id: layer['layer_type'] for layer_id, layer in layers.items()}\n",
    "        self.layer_inputs = {layer_id: layer['input_layers'] for layer_id, layer in layers.items()}\n",
    "        self.n_layers = len(layers)\n",
    "\n",
    "        self._outputs = None\n",
    "\n",
    "        # x = F.relu(self.fc1(x))\n",
    "\n",
    "        # self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tt(mat):\n",
    "        return torch.tensor(mat, requires_grad=True, dtype=torch.float64)\n",
    "    def forward(self, x):\n",
    "        self._outputs = {}\n",
    "        for layer_id in range(self.n_layers):\n",
    "            layer_input = None\n",
    "            layer_type = self.layers[layer_id]\n",
    "            if layer_type == LAYER_TYPE_INPUT:\n",
    "                self._outputs[layer_id] = x\n",
    "                continue\n",
    "            if layer_type == LAYER_TYPE_CONNECTED:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                layer_input = torch.cat([self._outputs[ii] for ii in self.layer_inputs[layer_id]])\n",
    "\n",
    "            print(layer_input)\n",
    "            print(self.weights[layer_id])\n",
    "            print(self.biases[layer_id])\n",
    "\n",
    "            self._outputs[layer_id] = torch.relu( torch.matmul(layer_input, self.weights[layer_id]) + self.biases[layer_id] )\n",
    "\n",
    "            if layer_type == LAYER_TYPE_OUTPUT:\n",
    "                return self._outputs[layer_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "net._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-a603b1e669d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-133-588acf26c213>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLAYER_TYPE_CONNECTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mlayer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLAYER_TYPE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mlayer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-588acf26c213>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLAYER_TYPE_CONNECTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mlayer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLAYER_TYPE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mlayer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "net.forward(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'outputs'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-acf366ad9aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/phd-neat/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    576\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'outputs'"
     ]
    }
   ],
   "source": [
    "net.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I.e., `output = f(cat(inputs) + bias)` for a given activation function f\n",
    "\n",
    "def forward(layers, x):\n",
    "    layer_outputs = {}\n",
    "    curr_value = x\n",
    "    for ii in range(len(layers)):\n",
    "        print(ii)\n",
    "        layer = layers[ii]\n",
    "        if layer['is_output_layer']:\n",
    "            # return curr_value\n",
    "            return(layer_outputs)\n",
    "        input_layers = [layer_outputs[layer_id] for layer_id in layer['input_layers']]\n",
    "    return(layer_outputs)\n",
    "        # layer_outputs[ii] = torch.relu(\n",
    "        #     torch.add(\n",
    "        #         torch.matmul(\n",
    "        #             torch.cat(layer['input_layers']),\n",
    "        #             layer['weights']\n",
    "\n",
    "        #         ),\n",
    "        #         layer['bias']\n",
    "        #     )\n",
    "        # )\n",
    "        # curr_value = torch.sigmoid(torch.matmul(curr_value + layers[ii]['bias'], layers[ii]['out_tensor']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'input_layers'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-a7040ab36164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-70493be52dd1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(layers, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# return curr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0minput_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# layer_outputs[ii] = torch.relu(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_layers'"
     ]
    }
   ],
   "source": [
    "forward(layers, x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.nodes[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}